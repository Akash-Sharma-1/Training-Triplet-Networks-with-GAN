{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EndSemAssignmentDL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f45691a48ec44cbfa77ca714a836a496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e42e4dfe6d341f8b9d51dc9d8b577e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b982e6f103f248ec9746df735342af3a",
              "IPY_MODEL_4247a3fe9fcc4866b2818b6dc0aba196"
            ]
          }
        },
        "9e42e4dfe6d341f8b9d51dc9d8b577e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b982e6f103f248ec9746df735342af3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a885397aab9c4f598648752c0cddca8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85c229ae58c9472d83811fcabccf9bee"
          }
        },
        "4247a3fe9fcc4866b2818b6dc0aba196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a4c45022e9a478fbfdf2a99f997a2ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:21&lt;00:00, 1252183.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1574c6faf5de40d0b194d28a8e345f8c"
          }
        },
        "a885397aab9c4f598648752c0cddca8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85c229ae58c9472d83811fcabccf9bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a4c45022e9a478fbfdf2a99f997a2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1574c6faf5de40d0b194d28a8e345f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e4394de3aae4429a08eed79b5659bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09a42676906942ccb74c448e2cc81fe7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c42c8abcce3d4e6c9b30cb9c22d3df7e",
              "IPY_MODEL_10ef3f48bbbc44a6bd62867a92b5a640"
            ]
          }
        },
        "09a42676906942ccb74c448e2cc81fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c42c8abcce3d4e6c9b30cb9c22d3df7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_caf9f6f472744a7cb2bb3c3de984fb91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8e28dd5ee924811842f2838cc75a88b"
          }
        },
        "10ef3f48bbbc44a6bd62867a92b5a640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8913d6017378480f82cecf8d29f5c0f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:03&lt;00:00, 9679.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9a5a80809624dcfa8969e65b8ec7d6b"
          }
        },
        "caf9f6f472744a7cb2bb3c3de984fb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8e28dd5ee924811842f2838cc75a88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8913d6017378480f82cecf8d29f5c0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9a5a80809624dcfa8969e65b8ec7d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c322731455a4cef8409dabae6cc1d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d6b20e3ea124511993cb26c677133cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97059eb7a3744139adc3f319eda38d9b",
              "IPY_MODEL_c25f5c795b0d46cba3156453f7d231b2"
            ]
          }
        },
        "7d6b20e3ea124511993cb26c677133cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97059eb7a3744139adc3f319eda38d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b60717ad3d14b01a42ca5077b527916",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5df583edbba45c59f68674dc6dea58e"
          }
        },
        "c25f5c795b0d46cba3156453f7d231b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df9a4e2a6300404d953f7aac98a03350",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:02&lt;00:00, 668096.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41cf6984b557448c84ce189c3a58368f"
          }
        },
        "9b60717ad3d14b01a42ca5077b527916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5df583edbba45c59f68674dc6dea58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df9a4e2a6300404d953f7aac98a03350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41cf6984b557448c84ce189c3a58368f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6089052b777945f9bee7f71fbb16e3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_96eeab9d28ae41f6a197182c3454c9fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bed0768d6b3496e8cb64b0b4138950e",
              "IPY_MODEL_27d07332d9f2428b9d2fb6985503500f"
            ]
          }
        },
        "96eeab9d28ae41f6a197182c3454c9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bed0768d6b3496e8cb64b0b4138950e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12ba391da663486db1f787468871576f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3b8100a759941eca94c3be286c7139b"
          }
        },
        "27d07332d9f2428b9d2fb6985503500f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44990668e91b412789604fee4ef2e57d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:01&lt;00:00, 6192.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19571b099b1248c58bb53d36d8c9a9f1"
          }
        },
        "12ba391da663486db1f787468871576f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3b8100a759941eca94c3be286c7139b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44990668e91b412789604fee4ef2e57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19571b099b1248c58bb53d36d8c9a9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f84a24b26f1a4f2a90faaafdb0da9e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc9a644d9ae44b7a985f5c4ad0a55dea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fa8789b5f0341e1927fe43917babf96",
              "IPY_MODEL_74e34c7136b1460cbf805cc111e9c07d"
            ]
          }
        },
        "dc9a644d9ae44b7a985f5c4ad0a55dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fa8789b5f0341e1927fe43917babf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ae97abfd38f4a3db83a98d2e0bd7b63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_922ac5f91d61419484bdaf2f26484eea"
          }
        },
        "74e34c7136b1460cbf805cc111e9c07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ced81162c63b43738e037bb3cca72424",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:17&lt;00:00, 2588777.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ec6ca7ce74146eb978dfa244c81b285"
          }
        },
        "6ae97abfd38f4a3db83a98d2e0bd7b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "922ac5f91d61419484bdaf2f26484eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ced81162c63b43738e037bb3cca72424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ec6ca7ce74146eb978dfa244c81b285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6333474d87124a5dbe60a128769beb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e68321809f649b6bfc65db99c148cb4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a3a4cba86d4346c5b2407154217a1fcc",
              "IPY_MODEL_58c14e4aacd64cf5bd405c917104337c"
            ]
          }
        },
        "2e68321809f649b6bfc65db99c148cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3a4cba86d4346c5b2407154217a1fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3076332c11849f0a7d55d6a97c530b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56429fc04da842c89a85983911e10240"
          }
        },
        "58c14e4aacd64cf5bd405c917104337c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6eebce61385416d8d4f6af7005d9012",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:12&lt;00:00, 57312.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b8f7d4835114068902b874165232e6c"
          }
        },
        "c3076332c11849f0a7d55d6a97c530b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56429fc04da842c89a85983911e10240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6eebce61385416d8d4f6af7005d9012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b8f7d4835114068902b874165232e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee86454c3b66477a842333973294056d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88315fa0bfe54da982c3531344b2d9a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a40b28b9dabf4f399c42b1ae64200237",
              "IPY_MODEL_b8c5ff5f99b743c28d50bb727334a4b0"
            ]
          }
        },
        "88315fa0bfe54da982c3531344b2d9a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a40b28b9dabf4f399c42b1ae64200237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_987acf2a049b48eaba0f3a72176b1bab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b05f5072eef9449e9a947b99cddb17d1"
          }
        },
        "b8c5ff5f99b743c28d50bb727334a4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a274f19eefc482e9f6f21f003e3c6d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:22&lt;00:00, 199309.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65639ba8b05c485fa8a3c03c2722786b"
          }
        },
        "987acf2a049b48eaba0f3a72176b1bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b05f5072eef9449e9a947b99cddb17d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a274f19eefc482e9f6f21f003e3c6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65639ba8b05c485fa8a3c03c2722786b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa08b144a8464078906aa3a9a23b6474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_efa997b23f3f4dacbe644416f004a3ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b85ed24b1f9e4d6d8b671243c159db4b",
              "IPY_MODEL_2f2cc8fedbd343c189ecdadf67b6c02d"
            ]
          }
        },
        "efa997b23f3f4dacbe644416f004a3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b85ed24b1f9e4d6d8b671243c159db4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8946326c20e3452ba00890c15ffe3e49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_070ff03244694399b65cd7ce8e232ddc"
          }
        },
        "2f2cc8fedbd343c189ecdadf67b6c02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fcef2f9c10448229bda1d4908845b66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:01&lt;00:00, 7626.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd1ada90441441c0bf8ed4ed11bfa331"
          }
        },
        "8946326c20e3452ba00890c15ffe3e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "070ff03244694399b65cd7ce8e232ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fcef2f9c10448229bda1d4908845b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd1ada90441441c0bf8ed4ed11bfa331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvCFHWywmumr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZBd52yp_zPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3fd91ee-219b-44b6-e198-f9e2b549cb3a"
      },
      "source": [
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/DL/Akash-Sharma_2017327_EndSem/weights_pr')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqsz8NYERRDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import pdb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLOVnXPCABbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from itertools import cycle\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import pdb\n",
        "\n",
        "from __future__ import print_function \n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import sys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m68BH5IhRWsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_sum_exp(x, axis = 1):\n",
        "    m = torch.max(x, dim = 1)[0]\n",
        "    return m + torch.log(torch.sum(torch.exp(x - m.unsqueeze(1)), dim = axis))\n",
        "def reset_normal_param(L, stdv, weight_scale = 1.):\n",
        "    assert type(L) == torch.nn.Linear\n",
        "    torch.nn.init.normal(L.weight, std=weight_scale / math.sqrt(L.weight.size()[0]))\n",
        "    \n",
        "class LinearWeightNorm(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True, weight_scale=None, weight_init_stdv=0.1):\n",
        "        super(LinearWeightNorm, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.randn(out_features, in_features) * weight_init_stdv)\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        if weight_scale is not None:\n",
        "            assert type(weight_scale) == int\n",
        "            self.weight_scale = Parameter(torch.ones(out_features, 1) * weight_scale)\n",
        "        else:\n",
        "            self.weight_scale = 1 \n",
        "    def forward(self, x):\n",
        "        W = self.weight * self.weight_scale / torch.sqrt(torch.sum(self.weight ** 2, dim = 1, keepdim = True))\n",
        "        return F.linear(x, W, self.bias)\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_features=' + str(self.in_features) \\\n",
        "            + ', out_features=' + str(self.out_features) \\\n",
        "            + ', weight_scale=' + str(self.weight_scale) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_czxDsDBQ3BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATALOADER \n",
        "import random\n",
        "def MNISTunlab():\n",
        "    dmnist = datasets.MNIST( root='mnist', download=True, train=True,  transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                ]))\n",
        "\n",
        "    return dmnist\n",
        "\n",
        "def MnistLabel(class_num, perimg):\n",
        "    raw_dataset = datasets.MNIST(root='mnist', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "    class_tot = [0] * class_num\n",
        "    data = []\n",
        "    labels = []\n",
        "    tot = 0\n",
        "    perm = np.random.permutation(raw_dataset.__len__())\n",
        "    for i in range(raw_dataset.__len__()):\n",
        "        datum, label = raw_dataset.__getitem__(perm[i])\n",
        "        if class_tot[label] < perimg:  \n",
        "            data.append(datum.numpy())\n",
        "            labels.append(label)\n",
        "            class_tot[label] += 1\n",
        "            tot += 1\n",
        "            if tot >= perimg * class_num:\n",
        "                break\n",
        "    return TensorDataset(torch.FloatTensor(np.array(data)), torch.LongTensor(np.array(labels)))\n",
        "        \n",
        "class MNIST_triplet():\n",
        "    def __init__(self, root='mnist', download=True, train=True,sampleSize=100):\n",
        "        self.mnist = datasets.MNIST( root='mnist', download=True, train=True,  transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "        self.data_dict = {}\n",
        "\n",
        "        for i in range(self.__len__()):\n",
        "            image, label = self.mnist.__getitem__(i)\n",
        "            try:\n",
        "                self.data_dict[label]\n",
        "            except KeyError:\n",
        "                self.data_dict[label] = []\n",
        "            self.data_dict[label].append(image)\n",
        "        \n",
        "        sampleImages={}\n",
        "        triplets=[]\n",
        "        numberofimgs=int(sampleSize/10)\n",
        "        for i in range(10):\n",
        "          siz=len(self.data_dict[i])\n",
        "          x=random.sample(range(siz), numberofimgs)##index\n",
        "          for j in range(len(x)):\n",
        "            try:\n",
        "                sampleImages[i]\n",
        "            except KeyError:\n",
        "                sampleImages[i] = []\n",
        "\n",
        "            sampleImages[i].append(self.data_dict[i][x[j]])\n",
        "\n",
        "        for i in range(10):\n",
        "          for j in range(numberofimgs):\n",
        "            for k in range(numberofimgs):\n",
        "              for l in range(10):\n",
        "                if i!=l:\n",
        "                  for p in range(numberofimgs):\n",
        "                    ob=[]\n",
        "                    ob.append(sampleImages[i][j])\n",
        "                    ob.append(sampleImages[i][k])\n",
        "                    ob.append(sampleImages[l][p])\n",
        "                    triplets.append(ob)\n",
        "\n",
        "        # print(len(triplets))\n",
        "        random.shuffle(triplets)\n",
        "        self.triplets=triplets[:60000]\n",
        "        # print(len(self.mnist[0]))\n",
        "        # print(len(self.triplets[0]))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.mnist.__len__() \n",
        "\n",
        "    def __getitem__(self,index):\n",
        "      return self.triplets[index]\n",
        "\n",
        "def MnistTest():\n",
        "    return datasets.MNIST('mnist', train=False, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ]))\n",
        "#---------------------------------------------------\n",
        "x=MNIST_triplet()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvCzqgi0Rpzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Models\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim = 28 ** 2, output_dim = 32):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            LinearWeightNorm(input_dim, 1000),\n",
        "            LinearWeightNorm(1000, 500),\n",
        "            LinearWeightNorm(500, 250),\n",
        "            LinearWeightNorm(250, 250),\n",
        "            LinearWeightNorm(250, 250)]\n",
        "        )\n",
        "        self.final = LinearWeightNorm(250, output_dim, weight_scale=1)\n",
        "        self.fc = LinearWeightNorm(output_dim,1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, feature = False, cuda = False, pretrain=False):\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        noise = torch.randn(x.size()) * 0.3 if self.training else torch.Tensor([0])\n",
        "        if cuda:\n",
        "            noise = noise.cuda()\n",
        "        x = x + Variable(noise, requires_grad = False)\n",
        "        for i in range(len(self.layers)):\n",
        "            m = self.layers[i]\n",
        "            x_f = F.relu(m(x))\n",
        "            noise = torch.randn(x_f.size()) * 0.5 if self.training else torch.Tensor([0])\n",
        "            if cuda:\n",
        "                noise = noise.cuda()\n",
        "            x = (x_f + Variable(noise, requires_grad = False))\n",
        "\n",
        "        if  pretrain==True:\n",
        "          fina=self.final(x)\n",
        "          xxx=self.fc(fina)\n",
        "          yyy=self.sig(xxx)\n",
        "          return yyy\n",
        "        else:\n",
        "          if feature:\n",
        "              return x_f, self.final(x)\n",
        "          return self.final(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, output_dim = 28 ** 2):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.fc1 = nn.Linear(z_dim, 500, bias = False)\n",
        "        self.bn1 = nn.BatchNorm1d(500, affine = False, eps=1e-6, momentum = 0.5)\n",
        "        self.fc2 = nn.Linear(500, 500, bias = False)\n",
        "        self.bn2 = nn.BatchNorm1d(500, affine = False, eps=1e-6, momentum = 0.5)\n",
        "        self.fc3 = LinearWeightNorm(500, output_dim, weight_scale = 1)\n",
        "        self.bn1_b = Parameter(torch.zeros(500))\n",
        "        self.bn2_b = Parameter(torch.zeros(500))\n",
        "        nn.init.xavier_uniform(self.fc1.weight)\n",
        "        nn.init.xavier_uniform(self.fc2.weight)\n",
        "\n",
        "    def forward(self, batch_size, cuda = False):\n",
        "        x = Variable(torch.rand(batch_size, self.z_dim), requires_grad = False, volatile = not self.training)\n",
        "        if cuda:\n",
        "            x = x.cuda()\n",
        "        x = F.softplus(self.bn1(self.fc1(x)) + self.bn1_b)\n",
        "        x = F.softplus(self.bn2(self.fc2(x)) + self.bn2_b)\n",
        "        x = F.softplus(self.fc3(x))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uakd5vivSdYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "#hyperparameters\n",
        "savedir=False\n",
        "cuda=True\n",
        "lr = 0.003\n",
        "batch_size=100\n",
        "momentum=0.5\n",
        "loginterval=100\n",
        "epochs=10\n",
        "unlabelweight=1\n",
        "def loss_labeled(a,b,c):\n",
        "      n_plus = torch.sqrt(torch.sum((a - b)**2, axis=1));\n",
        "      n_minus = torch.sqrt(torch.sum((a - c)**2, axis=1));\n",
        "      z = torch.cat([n_minus.unsqueeze(1),n_plus.unsqueeze(1)],axis=1)\n",
        "      z = log_sum_exp(z,axis=1)\n",
        "      return n_plus,n_minus,z\n",
        "\n",
        "class ImprovedGAN(object):\n",
        "    def __init__(self, G, D, triplets,labeled, unlabeled, test):\n",
        "        # if os.path.exists(savedir):\n",
        "        #     # print('Loading model from ' + savedir)\n",
        "        #     # self.G = torch.load(os.path.join(args.savedir, 'G.pkl'))\n",
        "        #     # self.D = torch.load(os.path.join(args.savedir, 'D.pkl'))\n",
        "        # else:\n",
        "            # os.makedirs(savedir)\n",
        "        \n",
        "        \n",
        "        G=G.cuda()\n",
        "        D=D.cuda()\n",
        "        G=torch.load('/content/drive/My Drive/DL/EndSem/pretrained_32/pretrained_32_G49.pkl')\n",
        "        D=torch.load('/content/drive/My Drive/DL/EndSem/pretrained_32/pretrained_32_D49.pkl')\n",
        "        self.G=G\n",
        "        self.D=D\n",
        "        self.triplets = triplets\n",
        "        self.unlabeled = unlabeled\n",
        "        self.labeled = labeled\n",
        "        self.test = test\n",
        "        self.Doptim = optim.Adam(self.D.parameters(), lr=lr, betas= (momentum, 0.999))\n",
        "        self.Goptim = optim.Adam(self.G.parameters(), lr=lr, betas = (momentum,0.999))\n",
        "        # self.args = args\n",
        "\n",
        "    def trainD(self, a, b,c,x_label,y, x_unlabel): ## repalce x_label,y and give triplet iteself\n",
        "        x_label,x_unlabel,y,a,b,c = Variable(x_label), Variable(x_unlabel), Variable(y, requires_grad = False), Variable(a), Variable(b), Variable(c)\n",
        "        x_label=x_label.cuda()\n",
        "        y=y.cuda()\n",
        "        x_unlabel=x_unlabel.cuda()\n",
        "        a=a.cuda()\n",
        "        b=b.cuda()\n",
        "        c=c.cuda()\n",
        "        output_label,output_unlabel, output_fake = self.D(x_label, cuda=True), self.D(x_unlabel, cuda=True), self.D(self.G(x_unlabel.size()[0], cuda =True).view(x_unlabel.size()).detach(), cuda=True)\n",
        "        logz_unlabel, logz_fake = log_sum_exp(output_unlabel), log_sum_exp(output_fake) # log âˆ‘e^x_i\n",
        "        a_lab,b_lab,c_lab = self.D(a, cuda=True),self.D(b, cuda=True),self.D(c, cuda=True)\n",
        "        ##### TRIPLET LOSS\n",
        "        n_plus_lab,n_minus_lab,z_lab = loss_labeled(a_lab,b_lab,c_lab)\n",
        "        loss_supervised =  -torch.mean(n_minus_lab) + torch.mean(z_lab)\n",
        "        loss_unsupervised = 0.5 * (-torch.mean(logz_unlabel) + torch.mean(F.softplus(logz_unlabel))  + # real_data: log Z/(1+Z)\n",
        "                            torch.mean(F.softplus(logz_fake)) ) # fake_data: log 1/(1+Z)\n",
        "        loss = loss_supervised + unlabelweight * loss_unsupervised\n",
        "        acc = torch.mean((output_label.max(1)[1] == y).float())\n",
        "        self.Doptim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.Doptim.step()\n",
        "        return loss_supervised.data.cpu().numpy(), loss_unsupervised.data.cpu().numpy(),acc\n",
        "    \n",
        "    def trainG(self, x_unlabel):\n",
        "        fake = self.G(x_unlabel.size()[0], cuda = True).view(x_unlabel.size())\n",
        "        mom_gen, output_fake = self.D(fake, feature=True, cuda=True)\n",
        "        mom_unlabel, _ = self.D(Variable(x_unlabel), feature=True, cuda=True)\n",
        "        mom_gen = torch.mean(mom_gen, dim = 0)\n",
        "        mom_unlabel = torch.mean(mom_unlabel, dim = 0)\n",
        "        loss_fm = torch.mean((mom_gen - mom_unlabel) ** 2)\n",
        "        loss = loss_fm \n",
        "        self.Goptim.zero_grad()\n",
        "        self.Doptim.ztero_grad()\n",
        "        loss.backward()\n",
        "        self.Goptim.step()\n",
        "        return loss.data.cpu().numpy()\n",
        "\n",
        "\n",
        "    def train_real(self):\n",
        "      tripLosses=[]\n",
        "      unsupervisedLosses=[]\n",
        "      genLosses=[]\n",
        "      accuracytrain=[]\n",
        "      accuracyval=[]\n",
        "      times = int(np.ceil(self.unlabeled.__len__() * 1. / self.labeled.__len__()))\n",
        "      t1 = self.labeled.tensors[0].clone()\n",
        "      t2 = self.labeled.tensors[1].clone()\n",
        "      tile_labeled = TensorDataset(t1.repeat(times,1,1,1),t2.repeat(times))\n",
        "      for epoch in range(10):\n",
        "        print(epoch)\n",
        "        loss_supervised = loss_unsupervised = loss_gen = accuracy = 0.\n",
        "        self.G.train()\n",
        "        self.D.train()\n",
        "        unlabel_loader1 = DataLoader(self.unlabeled, batch_size = 100, shuffle=True, drop_last=True, num_workers = 4)\n",
        "        unlabel_loader2 = DataLoader(self.unlabeled, batch_size = 100, shuffle=True, drop_last=True, num_workers = 4).__iter__()\n",
        "        label_loader = DataLoader(tile_labeled, batch_size = 100, shuffle=True, drop_last=True, num_workers = 4).__iter__()\n",
        "        triplet_loader = DataLoader(self.triplets, batch_size = 100, shuffle=True, drop_last=True, num_workers = 4).__iter__()\n",
        "\n",
        "        begin = time.time()\n",
        "        batch_num=0\n",
        "        for (unlabel1, _label1) in unlabel_loader1:\n",
        "          batch_num += 1\n",
        "          unlabel2, _label2 = unlabel_loader2.next()\n",
        "          a,b,c= triplet_loader.next()\n",
        "          x, y = label_loader.next()\n",
        "          unlabel2=unlabel2.cuda()\n",
        "          unlabel1=unlabel1.cuda()\n",
        "          a=a.cuda()\n",
        "          b=b.cuda()\n",
        "          c=c.cuda()\n",
        "          x=x.cuda()\n",
        "          y=y.cuda()\n",
        "          ll, lu, acc = self.trainD(a, b,c,x,y,unlabel1)\n",
        "          loss_supervised+=ll\n",
        "          loss_unsupervised+=lu\n",
        "          accuracy+=acc\n",
        "          lg = self.trainG(unlabel2)\n",
        "          if epoch > 1 and lg > 1:\n",
        "              lg = self.trainG(unlabel2)\n",
        "          loss_gen += lg\n",
        "          if (batch_num + 1) % 100 == 0:\n",
        "            print('Training: %d / %d' % (batch_num + 1, len(unlabel_loader1)))      \n",
        "        loss_supervised /= batch_num\n",
        "        loss_unsupervised /= batch_num\n",
        "        loss_gen /= batch_num\n",
        "        accuracy /= batch_num\n",
        "        print(\"Iteration %d, loss_supervised = %.4f, loss_unsupervised = %.4f, loss_gen = %.4f train acc = %.4f \" % (epoch, loss_supervised, loss_unsupervised, loss_gen,accuracy))\n",
        "        tripLosses.append(loss_supervised)\n",
        "        unsupervisedLosses.append(loss_unsupervised)\n",
        "        genLosses.append(loss_gen)\n",
        "        accuracytrain.append(accuracy)\n",
        "\n",
        "        accval=self.eval()\n",
        "        print(\"Eval: correct %d / %d\"  % (accval, self.test.__len__()))\n",
        "        torch.save(self.G, os.path.join('G_pr_32_100'+str(epoch)+'.pkl'))\n",
        "        torch.save(self.D, os.path.join('D_pr_32_100'+str(epoch)+'.pkl'))\n",
        "        accuracyval.append(accval) \n",
        "\n",
        "      import matplotlib.pyplot as plt \n",
        "      ep=list(range(0,10))\n",
        "      plt.plot(ep,tripLosses) \n",
        "      # naming the x axis \n",
        "      plt.xlabel('Epochs') \n",
        "      # naming the y axis \n",
        "      plt.ylabel('Triplet Loss') \n",
        "      # giving a title to my graph \n",
        "      plt.title('Triplet Loss Plot') \n",
        "      # function to show the plot \n",
        "      plt.show() \n",
        "      plt.plot(ep,unsupervisedLosses) \n",
        "      # naming the x axis \n",
        "      plt.xlabel('Epochs') \n",
        "      # naming the y axis \n",
        "      plt.ylabel('Unsupervised Loss') \n",
        "      # giving a title to my graph \n",
        "      plt.title('Unsupervised Loss Plot') \n",
        "      plt.figure()\n",
        "      plt.show() \n",
        "      plt.plot(ep,genLosses) \n",
        "      # naming the x axis \n",
        "      plt.xlabel('Epochs') \n",
        "      # naming the y axis \n",
        "      plt.ylabel('Generator Loss') \n",
        "      # giving a title to my graph \n",
        "      plt.title('Generator Loss Plot') \n",
        "      plt.figure()\n",
        "      plt.show()  \n",
        "\n",
        "    def predict(self, x):\n",
        "        with torch.no_grad():\n",
        "            ret = torch.max(self.D(Variable(x), cuda=True), 1)[1].data\n",
        "        return ret\n",
        "\n",
        "    def eval(self):\n",
        "        self.G.eval()\n",
        "        self.D.eval()\n",
        "        d, l = [], []\n",
        "        for (datum, label) in self.test:\n",
        "            d.append(datum)\n",
        "            l.append(label)\n",
        "        x, y = torch.stack(d), torch.LongTensor(l)\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        pred = self.predict(x)\n",
        "        return torch.sum(pred == y)\n",
        "        \n",
        "    def draw(self, batch_size):\n",
        "        self.G.eval()\n",
        "        return self.G(batch_size, cuda=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOxtjHxsTXno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f45691a48ec44cbfa77ca714a836a496",
            "9e42e4dfe6d341f8b9d51dc9d8b577e6",
            "b982e6f103f248ec9746df735342af3a",
            "4247a3fe9fcc4866b2818b6dc0aba196",
            "a885397aab9c4f598648752c0cddca8a",
            "85c229ae58c9472d83811fcabccf9bee",
            "7a4c45022e9a478fbfdf2a99f997a2ef",
            "1574c6faf5de40d0b194d28a8e345f8c",
            "0e4394de3aae4429a08eed79b5659bcd",
            "09a42676906942ccb74c448e2cc81fe7",
            "c42c8abcce3d4e6c9b30cb9c22d3df7e",
            "10ef3f48bbbc44a6bd62867a92b5a640",
            "caf9f6f472744a7cb2bb3c3de984fb91",
            "c8e28dd5ee924811842f2838cc75a88b",
            "8913d6017378480f82cecf8d29f5c0f9",
            "d9a5a80809624dcfa8969e65b8ec7d6b",
            "0c322731455a4cef8409dabae6cc1d65",
            "7d6b20e3ea124511993cb26c677133cd",
            "97059eb7a3744139adc3f319eda38d9b",
            "c25f5c795b0d46cba3156453f7d231b2",
            "9b60717ad3d14b01a42ca5077b527916",
            "b5df583edbba45c59f68674dc6dea58e",
            "df9a4e2a6300404d953f7aac98a03350",
            "41cf6984b557448c84ce189c3a58368f",
            "6089052b777945f9bee7f71fbb16e3b9",
            "96eeab9d28ae41f6a197182c3454c9fa",
            "0bed0768d6b3496e8cb64b0b4138950e",
            "27d07332d9f2428b9d2fb6985503500f",
            "12ba391da663486db1f787468871576f",
            "c3b8100a759941eca94c3be286c7139b",
            "44990668e91b412789604fee4ef2e57d",
            "19571b099b1248c58bb53d36d8c9a9f1"
          ]
        },
        "outputId": "0c365823-84cc-48e3-e0ed-f13ebe9d61c6"
      },
      "source": [
        "\n",
        "    # parser = argparse.ArgumentParser(description='PyTorch Improved GAN')\n",
        "    # parser.add_argument('--batch-size', type=int, default=100, metavar='N',\n",
        "    #                     help='input batch size for training (default: 64)')\n",
        "    # parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
        "    #                     help='number of epochs to train (default: 10)')\n",
        "    # parser.add_argument('--lr', type=float, default=0.003, metavar='LR',\n",
        "    #                     help='learning rate (default: 0.003)')\n",
        "    # parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
        "    #                     help='SGD momentum (default: 0.5)')\n",
        "    # parser.add_argument('--cuda', action='store_true', default=False,\n",
        "    #                     help='CUDA training')\n",
        "    # parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "    #                     help='random seed (default: 1)')\n",
        "    # parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
        "    #                     help='how many batches to wait before logging training status')\n",
        "    # parser.add_argument('--eval-interval', type=int, default=1, metavar='N',\n",
        "    #                     help='how many epochs to wait before evaling training status')\n",
        "    # parser.add_argument('--unlabel-weight', type=float, default=1, metavar='N',\n",
        "    #                     help='scale factor between labeled and unlabeled data')\n",
        "    # parser.add_argument('--logdir', type=str, default='./logfile', metavar='LOG_PATH', help='logfile path, tensorboard format')\n",
        "    # parser.add_argument('--savedir', type=str, default='./models', metavar='SAVE_PATH', help = 'saving path, pickle format')\n",
        "    # args = parser.parse_args()\n",
        "    # args.cuda = args.cuda and torch.cuda.is_available()\n",
        "    # seed=1\n",
        "    # np.random.seed(seed)\n",
        "\n",
        "mnisttrip=MNIST_triplet()\n",
        "gan = ImprovedGAN(Generator(100), Discriminator(),mnisttrip, MnistLabel(10,10), MNISTunlab(), MnistTest())\n",
        "gan.train_real()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f45691a48ec44cbfa77ca714a836a496",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e4394de3aae4429a08eed79b5659bcd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c322731455a4cef8409dabae6cc1d65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6089052b777945f9bee7f71fbb16e3b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 0, loss_supervised = 0.0695, loss_unsupervised = 0.4575, loss_gen = 2.4415 train acc = 0.0006 \n",
            "Eval: correct 0 / 10000\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LinearWeightNorm. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 1, loss_supervised = 0.0061, loss_unsupervised = 0.3844, loss_gen = 2.3018 train acc = 0.0001 \n",
            "Eval: correct 0 / 10000\n",
            "2\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 2, loss_supervised = 0.0041, loss_unsupervised = 0.4068, loss_gen = 1.9728 train acc = 0.0001 \n",
            "Eval: correct 0 / 10000\n",
            "3\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 3, loss_supervised = 0.0028, loss_unsupervised = 0.4108, loss_gen = 1.8407 train acc = 0.0000 \n",
            "Eval: correct 0 / 10000\n",
            "4\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 4, loss_supervised = 0.0024, loss_unsupervised = 0.4199, loss_gen = 1.7350 train acc = 0.0000 \n",
            "Eval: correct 0 / 10000\n",
            "5\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 5, loss_supervised = 0.0026, loss_unsupervised = 0.4221, loss_gen = 1.6850 train acc = 0.0000 \n",
            "Eval: correct 0 / 10000\n",
            "6\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 6, loss_supervised = 0.0015, loss_unsupervised = 0.4297, loss_gen = 1.6403 train acc = 0.0000 \n",
            "Eval: correct 0 / 10000\n",
            "7\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 7, loss_supervised = 0.0014, loss_unsupervised = 0.4341, loss_gen = 1.6043 train acc = 0.0000 \n",
            "Eval: correct 0 / 10000\n",
            "8\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 8, loss_supervised = 0.0009, loss_unsupervised = 0.4315, loss_gen = 1.5903 train acc = 0.0000 \n",
            "Eval: correct 0 / 10000\n",
            "9\n",
            "Training: 100 / 600\n",
            "Training: 200 / 600\n",
            "Training: 300 / 600\n",
            "Training: 400 / 600\n",
            "Training: 500 / 600\n",
            "Training: 600 / 600\n",
            "Iteration 9, loss_supervised = 0.0018, loss_unsupervised = 0.4401, loss_gen = 1.5415 train acc = 0.0001 \n",
            "Eval: correct 0 / 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6K2KA_-NYIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5301a53e-d9f5-4cef-abc7-b8e1a80ae037"
      },
      "source": [
        "train_features=[]\n",
        "test_features=[]\n",
        "train_labels=[]\n",
        "test_labels=[]\n",
        "\n",
        "disc=Discriminator()\n",
        "disc=torch.load('D_pr_16_1009.pkl')\n",
        "\n",
        "# tr=MNISTunlab()\n",
        "# for (i,j) in tr:\n",
        "#   train_labels.append(j)\n",
        "#   train_features.append(disc(i.cuda(),cuda=True))\n",
        "\n",
        "unlabel_loader1 = DataLoader(MNISTunlab(), batch_size = 600,  drop_last=True, num_workers = 4)\n",
        "for (i,j) in unlabel_loader1:\n",
        "  train_labels+=j.tolist()\n",
        "  train_features+=((disc(i.cuda(),cuda=True)).tolist())\n",
        "\n",
        "\n",
        "\n",
        "# print(train_labels)\n",
        "# print(len(train_labels)) \n",
        "# print(len(train_features[0]))\n",
        "# print(len(train_features)) \n",
        "\n",
        "\n",
        "\n",
        "unlabel_loader1 = DataLoader(MnistTest(), batch_size = 200, drop_last=True, num_workers = 4)\n",
        "for (i,j) in unlabel_loader1:\n",
        "  test_labels+=j.tolist()\n",
        "  test_features+=((disc(i.cuda(),cuda=True)).tolist())\n",
        "\n",
        "print(test_labels)\n",
        "print(len(test_labels)) \n",
        "print(len(test_features[0]))\n",
        "print(len(test_features)) \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1, 7, 1, 8, 2, 0, 2, 9, 9, 5, 5, 1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5, 1, 4, 4, 7, 2, 3, 2, 7, 1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1, 0, 9, 0, 3, 1, 6, 4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 9, 4, 5, 9, 3, 9, 0, 3, 6, 5, 5, 7, 2, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1, 5, 9, 8, 7, 2, 3, 0, 4, 4, 2, 4, 1, 9, 5, 7, 7, 2, 8, 2, 6, 8, 5, 7, 7, 9, 1, 8, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2, 6, 4, 1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2, 4, 0, 2, 7, 4, 3, 3, 0, 0, 3, 1, 9, 6, 5, 2, 5, 9, 2, 9, 3, 0, 4, 2, 0, 7, 1, 1, 2, 1, 5, 3, 3, 9, 7, 8, 6, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5, 5, 6, 1, 8, 5, 1, 7, 9, 4, 6, 2, 2, 5, 0, 6, 5, 6, 3, 7, 2, 0, 8, 8, 5, 4, 1, 1, 4, 0, 3, 3, 7, 6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5, 2, 5, 4, 4, 2, 8, 3, 8, 2, 4, 5, 0, 3, 1, 7, 7, 5, 7, 9, 7, 1, 9, 2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8, 4, 5, 9, 8, 8, 3, 7, 6, 0, 0, 3, 0, 2, 6, 6, 4, 9, 3, 3, 3, 2, 3, 9, 1, 2, 6, 8, 0, 5, 6, 6, 6, 3, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9, 1, 9, 7, 5, 4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 8, 9, 4, 0, 6, 3, 9, 5, 2, 1, 3, 1, 3, 6, 5, 7, 4, 2, 2, 6, 3, 2, 6, 5, 4, 8, 9, 7, 1, 3, 0, 3, 8, 3, 1, 9, 3, 4, 4, 6, 4, 2, 1, 8, 2, 5, 4, 8, 8, 4, 0, 0, 2, 3, 2, 7, 7, 0, 8, 7, 4, 4, 7, 9, 6, 9, 0, 9, 8, 0, 4, 6, 0, 6, 3, 5, 4, 8, 3, 3, 9, 3, 3, 3, 7, 8, 0, 8, 2, 1, 7, 0, 6, 5, 4, 3, 8, 0, 9, 6, 3, 8, 0, 9, 9, 6, 8, 6, 8, 5, 7, 8, 6, 0, 2, 4, 0, 2, 2, 3, 1, 9, 7, 5, 1, 0, 8, 4, 6, 2, 6, 7, 9, 3, 2, 9, 8, 2, 2, 9, 2, 7, 3, 5, 9, 1, 8, 0, 2, 0, 5, 2, 1, 3, 7, 6, 7, 1, 2, 5, 8, 0, 3, 7, 2, 4, 0, 9, 1, 8, 6, 7, 7, 4, 3, 4, 9, 1, 9, 5, 1, 7, 3, 9, 7, 6, 9, 1, 3, 7, 8, 3, 3, 6, 7, 2, 8, 5, 8, 5, 1, 1, 4, 4, 3, 1, 0, 7, 7, 0, 7, 9, 4, 4, 8, 5, 5, 4, 0, 8, 2, 1, 0, 8, 4, 5, 0, 4, 0, 6, 1, 7, 3, 2, 6, 7, 2, 6, 9, 3, 1, 4, 6, 2, 5, 4, 2, 0, 6, 2, 1, 7, 3, 4, 1, 0, 5, 4, 3, 1, 1, 7, 4, 9, 9, 4, 8, 4, 0, 2, 4, 5, 1, 1, 6, 4, 7, 1, 9, 4, 2, 4, 1, 5, 5, 3, 8, 3, 1, 4, 5, 6, 8, 9, 4, 1, 5, 3, 8, 0, 3, 2, 5, 1, 2, 8, 3, 4, 4, 0, 8, 8, 3, 3, 1, 7, 3, 5, 9, 6, 3, 2, 6, 1, 3, 6, 0, 7, 2, 1, 7, 1, 4, 2, 4, 2, 1, 7, 9, 6, 1, 1, 2, 4, 8, 1, 7, 7, 4, 8, 0, 7, 3, 1, 3, 1, 0, 7, 7, 0, 3, 5, 5, 2, 7, 6, 6, 9, 2, 8, 3, 5, 2, 2, 5, 6, 0, 8, 2, 9, 2, 8, 8, 8, 8, 7, 4, 9, 3, 0, 6, 6, 3, 2, 1, 3, 2, 2, 9, 3, 0, 0, 5, 7, 8, 1, 4, 4, 6, 0, 2, 9, 1, 4, 7, 4, 7, 3, 9, 8, 8, 4, 7, 1, 2, 1, 2, 2, 3, 2, 3, 2, 3, 9, 1, 7, 4, 0, 3, 5, 5, 8, 6, 3, 2, 6, 7, 6, 6, 3, 2, 7, 8, 1, 1, 7, 5, 6, 4, 9, 5, 1, 3, 3, 4, 7, 8, 9, 1, 1, 6, 9, 1, 4, 4, 5, 4, 0, 6, 2, 2, 3, 1, 5, 1, 2, 0, 3, 8, 1, 2, 6, 7, 1, 6, 2, 3, 9, 0, 1, 2, 2, 0, 8, 9, 9, 0, 2, 5, 1, 9, 7, 8, 1, 0, 4, 1, 7, 9, 6, 4, 2, 6, 8, 1, 3, 7, 5, 4, 4, 1, 8, 1, 3, 8, 1, 2, 5, 8, 0, 6, 2, 1, 1, 7, 1, 5, 3, 4, 6, 9, 5, 0, 9, 2, 2, 4, 8, 2, 1, 7, 2, 4, 9, 4, 4, 0, 3, 9, 2, 2, 3, 3, 8, 3, 5, 7, 3, 5, 8, 1, 2, 4, 4, 6, 4, 9, 5, 1, 0, 6, 9, 5, 9, 5, 9, 7, 3, 8, 0, 3, 7, 1, 3, 6, 7, 8, 5, 9, 7, 9, 6, 9, 6, 3, 7, 4, 4, 5, 3, 5, 4, 7, 8, 7, 8, 0, 7, 6, 8, 8, 7, 3, 3, 1, 9, 5, 2, 7, 3, 5, 1, 1, 2, 1, 4, 7, 4, 7, 5, 4, 5, 4, 0, 8, 3, 6, 9, 6, 0, 2, 7, 4, 4, 4, 4, 6, 6, 4, 7, 9, 3, 4, 5, 5, 8, 7, 3, 7, 2, 7, 0, 2, 4, 1, 1, 6, 6, 9, 2, 8, 7, 2, 0, 1, 5, 0, 9, 1, 7, 0, 6, 0, 8, 6, 8, 1, 8, 0, 3, 3, 7, 2, 3, 6, 2, 1, 6, 1, 1, 3, 7, 9, 0, 8, 0, 5, 4, 0, 2, 8, 7, 2, 9, 8, 4, 0, 9, 5, 8, 5, 1, 2, 1, 3, 1, 7, 4, 5, 7, 2, 0, 9, 8, 8, 6, 2, 5, 4, 1, 9, 2, 1, 5, 8, 7, 0, 2, 4, 4, 3, 6, 8, 8, 2, 4, 0, 5, 0, 4, 4, 7, 9, 3, 4, 1, 5, 9, 7, 3, 5, 8, 8, 0, 5, 3, 3, 6, 6, 0, 1, 6, 0, 3, 5, 4, 4, 1, 2, 9, 1, 4, 6, 9, 9, 3, 9, 8, 4, 4, 3, 1, 3, 1, 8, 8, 7, 9, 4, 8, 8, 7, 9, 7, 1, 4, 5, 6, 0, 5, 2, 2, 2, 1, 5, 5, 2, 4, 9, 6, 2, 7, 7, 2, 2, 1, 1, 2, 8, 3, 7, 2, 4, 1, 7, 1, 7, 6, 7, 8, 2, 7, 3, 1, 7, 5, 8, 2, 6, 2, 2, 5, 6, 5, 0, 9, 2, 4, 3, 3, 9, 7, 6, 6, 8, 0, 4, 1, 5, 8, 2, 9, 1, 8, 0, 6, 7, 2, 1, 0, 5, 5, 2, 0, 2, 2, 0, 2, 4, 9, 8, 0, 9, 9, 4, 6, 5, 4, 9, 1, 8, 3, 4, 9, 9, 1, 2, 2, 8, 1, 9, 6, 4, 0, 9, 4, 8, 3, 8, 6, 0, 2, 5, 1, 9, 6, 2, 9, 4, 0, 9, 6, 0, 6, 2, 5, 4, 2, 3, 8, 4, 5, 5, 0, 3, 8, 5, 3, 5, 8, 6, 5, 7, 6, 3, 3, 9, 6, 1, 1, 2, 9, 0, 4, 3, 3, 6, 9, 5, 7, 3, 7, 7, 7, 8, 7, 9, 8, 3, 0, 7, 2, 7, 9, 4, 5, 4, 9, 3, 2, 1, 4, 0, 2, 3, 7, 5, 7, 8, 8, 5, 0, 1, 1, 4, 8, 3, 9, 0, 0, 0, 6, 6, 2, 3, 7, 8, 4, 7, 7, 9, 2, 4, 1, 4, 5, 2, 4, 9, 9, 1, 8, 4, 0, 9, 8, 4, 8, 7, 7, 0, 7, 8, 8, 6, 0, 4, 8, 8, 2, 4, 7, 6, 6, 6, 4, 7, 1, 8, 8, 2, 3, 6, 3, 0, 0, 3, 7, 6, 9, 7, 9, 9, 5, 4, 3, 3, 6, 1, 2, 3, 7, 3, 3, 2, 0, 3, 3, 8, 4, 3, 6, 3, 5, 0, 2, 0, 9, 0, 7, 4, 6, 9, 3, 5, 1, 9, 6, 1, 4, 5, 4, 5, 0, 5, 9, 5, 2, 1, 2, 9, 1, 9, 9, 4, 0, 8, 4, 5, 2, 9, 2, 1, 2, 1, 7, 3, 6, 8, 8, 4, 9, 1, 9, 8, 5, 7, 5, 1, 1, 8, 6, 5, 2, 4, 4, 3, 2, 3, 5, 6, 8, 8, 6, 2, 3, 1, 0, 5, 8, 9, 2, 9, 6, 7, 0, 4, 8, 7, 1, 7, 4, 1, 0, 9, 7, 2, 0, 0, 9, 1, 7, 8, 7, 8, 4, 7, 2, 0, 4, 6, 0, 3, 1, 1, 3, 3, 9, 6, 7, 4, 1, 5, 3, 0, 8, 7, 3, 9, 6, 9, 3, 5, 0, 2, 7, 4, 5, 1, 7, 5, 8, 0, 8, 8, 1, 5, 0, 3, 0, 3, 1, 4, 0, 3, 7, 2, 7, 1, 8, 0, 7, 0, 4, 3, 1, 9, 8, 7, 7, 1, 4, 9, 9, 3, 2, 1, 7, 9, 0, 2, 0, 3, 3, 7, 6, 9, 2, 3, 3, 7, 7, 0, 0, 7, 5, 2, 9, 8, 7, 4, 4, 2, 6, 6, 1, 9, 6, 8, 2, 9, 0, 8, 3, 1, 1, 6, 3, 5, 1, 1, 1, 3, 1, 2, 3, 0, 2, 0, 1, 3, 5, 5, 7, 4, 8, 9, 6, 9, 6, 8, 3, 6, 6, 8, 5, 1, 4, 2, 4, 4, 5, 1, 1, 9, 0, 2, 4, 9, 5, 7, 1, 8, 8, 5, 6, 9, 8, 7, 1, 1, 6, 7, 6, 3, 2, 2, 0, 8, 9, 2, 5, 1, 0, 8, 1, 9, 5, 7, 9, 6, 9, 0, 6, 1, 5, 5, 8, 3, 8, 2, 6, 5, 0, 7, 4, 6, 1, 3, 4, 7, 3, 2, 3, 4, 2, 5, 2, 7, 1, 7, 2, 6, 4, 1, 5, 7, 8, 6, 0, 1, 8, 2, 5, 7, 7, 6, 9, 3, 5, 8, 4, 2, 4, 0, 8, 8, 3, 4, 9, 2, 7, 5, 8, 6, 5, 6, 0, 8, 6, 7, 3, 6, 4, 9, 4, 6, 6, 3, 2, 4, 1, 0, 1, 4, 6, 2, 9, 1, 1, 0, 6, 3, 9, 5, 6, 5, 6, 5, 8, 4, 6, 4, 3, 9, 1, 3, 4, 1, 9, 1, 7, 1, 1, 9, 3, 5, 4, 0, 7, 3, 6, 1, 7, 5, 5, 3, 3, 0, 1, 5, 7, 5, 8, 6, 5, 1, 0, 4, 2, 3, 4, 6, 7, 9, 8, 1, 8, 4, 9, 2, 8, 6, 2, 7, 0, 0, 6, 7, 5, 8, 6, 0, 9, 3, 7, 1, 3, 5, 4, 3, 3, 5, 5, 6, 3, 0, 2, 3, 4, 2, 3, 0, 9, 9, 4, 7, 2, 8, 4, 7, 0, 6, 2, 8, 5, 2, 8, 5, 7, 3, 0, 8, 2, 3, 2, 8, 2, 5, 5, 7, 6, 4, 6, 8, 4, 8, 2, 7, 4, 5, 2, 0, 3, 9, 4, 6, 7, 2, 5, 6, 1, 1, 2, 3, 6, 7, 8, 7, 6, 4, 8, 9, 4, 8, 6, 3, 8, 3, 1, 0, 6, 2, 2, 5, 6, 9, 5, 8, 1, 4, 1, 7, 8, 4, 6, 1, 8, 4, 3, 1, 2, 8, 0, 8, 5, 9, 1, 4, 2, 0, 2, 7, 0, 9, 0, 2, 5, 7, 6, 7, 9, 4, 2, 6, 2, 4, 4, 8, 0, 4, 4, 5, 8, 0, 6, 8, 9, 8, 5, 6, 9, 0, 4, 8, 7, 1, 3, 4, 5, 8, 0, 9, 1, 3, 3, 6, 9, 8, 7, 1, 0, 5, 7, 1, 7, 5, 2, 7, 9, 1, 8, 5, 2, 4, 9, 4, 7, 2, 2, 3, 4, 9, 1, 9, 2, 1, 7, 9, 4, 4, 1, 6, 7, 2, 7, 8, 8, 1, 9, 7, 1, 1, 7, 5, 3, 3, 5, 1, 3, 7, 6, 1, 3, 8, 7, 5, 9, 9, 0, 0, 2, 8, 8, 2, 3, 7, 1, 3, 0, 3, 4, 4, 3, 8, 9, 2, 3, 9, 7, 1, 1, 7, 0, 4, 9, 6, 5, 9, 1, 7, 0, 2, 0, 0, 4, 6, 7, 0, 7, 1, 4, 6, 4, 5, 4, 9, 9, 1, 7, 9, 5, 3, 3, 8, 2, 3, 6, 2, 2, 1, 1, 1, 1, 1, 6, 9, 8, 4, 3, 7, 1, 6, 4, 5, 0, 4, 7, 4, 2, 4, 0, 7, 0, 1, 9, 8, 8, 6, 0, 0, 4, 9, 6, 8, 2, 2, 3, 8, 4, 8, 2, 2, 1, 7, 5, 4, 4, 0, 4, 3, 9, 7, 3, 1, 0, 1, 2, 5, 9, 2, 1, 0, 1, 8, 9, 1, 6, 8, 3, 8, 9, 3, 6, 2, 8, 3, 2, 2, 1, 0, 4, 2, 9, 2, 4, 3, 7, 9, 1, 5, 2, 4, 9, 0, 3, 8, 5, 3, 6, 0, 9, 4, 6, 2, 5, 0, 2, 7, 4, 6, 6, 8, 6, 6, 8, 6, 9, 1, 7, 2, 5, 9, 9, 0, 7, 2, 7, 6, 7, 0, 6, 5, 2, 4, 7, 2, 0, 9, 9, 2, 2, 9, 4, 4, 2, 3, 3, 2, 1, 7, 0, 7, 6, 4, 1, 3, 8, 7, 4, 5, 9, 2, 5, 1, 8, 7, 3, 7, 1, 5, 5, 0, 9, 1, 4, 0, 6, 3, 3, 6, 0, 4, 9, 7, 5, 1, 6, 8, 9, 5, 5, 7, 9, 3, 8, 3, 8, 1, 5, 3, 5, 0, 5, 5, 3, 8, 6, 7, 7, 7, 3, 7, 0, 5, 9, 0, 2, 5, 5, 3, 1, 7, 7, 8, 6, 5, 9, 3, 8, 9, 5, 3, 7, 9, 1, 7, 0, 0, 3, 7, 2, 5, 8, 1, 8, 6, 2, 9, 5, 7, 5, 7, 8, 6, 2, 5, 1, 4, 8, 4, 5, 8, 3, 0, 6, 2, 7, 3, 3, 2, 1, 0, 7, 3, 4, 0, 3, 9, 3, 2, 8, 9, 0, 3, 8, 0, 7, 6, 5, 4, 7, 3, 9, 0, 8, 6, 2, 5, 6, 1, 0, 0, 4, 4, 0, 1, 2, 3, 2, 7, 7, 8, 5, 2, 5, 7, 6, 9, 1, 4, 1, 6, 4, 2, 4, 3, 5, 4, 3, 9, 5, 0, 1, 5, 3, 8, 9, 1, 9, 7, 9, 5, 5, 2, 7, 4, 6, 0, 1, 1, 1, 0, 4, 4, 7, 6, 3, 0, 0, 4, 3, 0, 6, 1, 9, 6, 1, 3, 8, 1, 2, 5, 6, 2, 7, 3, 6, 0, 1, 9, 7, 6, 6, 8, 9, 2, 9, 5, 8, 3, 1, 0, 0, 7, 6, 6, 2, 1, 6, 9, 3, 1, 8, 6, 9, 0, 6, 0, 0, 0, 6, 3, 5, 9, 3, 4, 5, 5, 8, 5, 3, 0, 4, 0, 2, 9, 6, 8, 2, 3, 1, 2, 1, 1, 5, 6, 9, 8, 0, 6, 6, 5, 5, 3, 8, 6, 2, 1, 4, 5, 4, 3, 7, 8, 5, 0, 9, 3, 5, 1, 1, 0, 4, 4, 7, 0, 1, 7, 0, 1, 6, 1, 4, 5, 6, 6, 5, 7, 8, 4, 4, 7, 2, 5, 3, 7, 0, 7, 7, 9, 6, 4, 2, 8, 5, 7, 8, 3, 9, 5, 8, 9, 9, 8, 6, 2, 8, 9, 2, 3, 6, 1, 1, 8, 9, 3, 4, 0, 7, 9, 6, 4, 1, 4, 1, 3, 4, 9, 3, 1, 4, 7, 7, 4, 7, 2, 9, 3, 0, 8, 8, 8, 4, 0, 4, 4, 1, 5, 2, 8, 3, 4, 9, 5, 2, 8, 1, 5, 3, 7, 9, 4, 2, 5, 6, 3, 5, 9, 3, 5, 9, 3, 1, 9, 5, 3, 0, 6, 9, 8, 4, 0, 4, 9, 2, 9, 0, 1, 0, 3, 1, 6, 5, 8, 1, 5, 3, 3, 0, 3, 5, 5, 9, 2, 8, 7, 0, 4, 9, 1, 9, 7, 7, 5, 5, 2, 0, 9, 1, 8, 6, 2, 3, 9, 6, 2, 1, 9, 1, 3, 5, 5, 0, 3, 8, 3, 3, 7, 6, 6, 0, 1, 4, 0, 6, 9, 8, 1, 2, 9, 9, 5, 9, 7, 3, 7, 8, 0, 1, 3, 0, 4, 6, 1, 0, 2, 5, 8, 4, 4, 1, 1, 5, 4, 6, 6, 0, 6, 9, 2, 6, 2, 7, 1, 7, 9, 4, 0, 0, 3, 8, 2, 2, 3, 1, 6, 0, 5, 7, 7, 9, 2, 6, 7, 9, 7, 8, 6, 8, 8, 4, 6, 8, 4, 1, 2, 8, 1, 3, 9, 4, 0, 3, 7, 3, 2, 3, 3, 7, 3, 4, 0, 6, 2, 0, 8, 1, 5, 3, 5, 4, 1, 7, 1, 5, 7, 5, 7, 3, 2, 2, 7, 3, 7, 3, 7, 8, 5, 4, 5, 2, 5, 6, 5, 3, 6, 7, 4, 1, 7, 1, 5, 2, 3, 6, 3, 1, 4, 2, 6, 7, 4, 3, 8, 0, 6, 2, 1, 6, 5, 3, 9, 1, 9, 3, 2, 1, 8, 4, 4, 6, 5, 8, 6, 9, 7, 7, 8, 6, 9, 7, 3, 9, 4, 0, 5, 4, 6, 4, 1, 2, 3, 0, 0, 2, 6, 6, 5, 7, 0, 8, 6, 4, 7, 9, 0, 7, 3, 4, 2, 1, 8, 8, 5, 9, 2, 7, 1, 8, 8, 8, 2, 7, 6, 0, 1, 2, 7, 1, 0, 8, 3, 6, 0, 5, 3, 6, 2, 8, 7, 0, 1, 4, 2, 1, 1, 4, 4, 4, 4, 7, 1, 6, 2, 9, 9, 0, 0, 1, 8, 8, 4, 3, 4, 2, 0, 6, 1, 6, 1, 2, 2, 2, 1, 2, 3, 7, 8, 1, 0, 0, 2, 1, 6, 6, 0, 1, 6, 2, 5, 1, 7, 4, 8, 2, 1, 4, 3, 8, 3, 9, 9, 4, 8, 3, 4, 7, 2, 7, 5, 7, 0, 4, 3, 3, 2, 6, 7, 6, 0, 0, 6, 7, 7, 0, 5, 5, 8, 1, 0, 7, 0, 2, 8, 1, 5, 0, 8, 8, 0, 3, 2, 7, 7, 2, 6, 4, 7, 5, 5, 5, 2, 9, 2, 8, 4, 6, 8, 6, 5, 0, 0, 8, 7, 6, 1, 7, 1, 1, 2, 7, 4, 0, 0, 7, 7, 6, 3, 8, 6, 4, 2, 0, 9, 4, 0, 5, 7, 8, 2, 7, 4, 7, 1, 1, 3, 6, 6, 2, 9, 1, 9, 4, 8, 3, 6, 9, 5, 9, 6, 2, 4, 6, 7, 7, 0, 6, 6, 9, 4, 8, 3, 5, 3, 4, 9, 0, 0, 5, 2, 5, 0, 7, 1, 1, 1, 6, 7, 6, 7, 9, 6, 6, 4, 1, 4, 3, 1, 1, 2, 2, 4, 1, 0, 8, 7, 6, 3, 4, 0, 0, 6, 3, 3, 0, 7, 1, 7, 1, 1, 3, 1, 0, 9, 9, 7, 5, 4, 1, 4, 8, 9, 5, 3, 5, 1, 9, 8, 2, 3, 3, 9, 9, 0, 1, 0, 2, 9, 3, 9, 3, 3, 6, 2, 4, 9, 8, 3, 7, 4, 0, 4, 7, 8, 4, 9, 8, 9, 9, 7, 5, 9, 2, 8, 2, 2, 0, 2, 2, 3, 8, 4, 6, 8, 6, 8, 2, 4, 6, 7, 9, 3, 3, 9, 4, 3, 1, 4, 4, 7, 0, 5, 9, 6, 0, 4, 4, 4, 4, 6, 1, 2, 3, 3, 6, 4, 5, 9, 6, 8, 5, 6, 5, 8, 6, 4, 1, 8, 6, 5, 2, 8, 4, 5, 5, 4, 7, 7, 0, 7, 8, 2, 2, 3, 7, 0, 1, 8, 0, 7, 1, 9, 8, 7, 5, 5, 9, 1, 7, 5, 4, 9, 1, 2, 2, 1, 6, 6, 7, 1, 1, 4, 0, 7, 4, 2, 4, 0, 6, 4, 7, 6, 9, 5, 3, 4, 6, 5, 0, 1, 8, 8, 2, 8, 3, 5, 7, 8, 0, 8, 5, 7, 1, 1, 0, 1, 3, 7, 8, 5, 0, 7, 1, 1, 0, 1, 1, 4, 5, 2, 7, 6, 2, 3, 0, 2, 8, 5, 9, 6, 9, 7, 2, 1, 3, 6, 4, 1, 8, 2, 4, 0, 5, 1, 0, 2, 2, 6, 4, 4, 3, 9, 6, 1, 6, 5, 7, 9, 2, 0, 2, 6, 0, 1, 4, 3, 5, 2, 8, 8, 0, 8, 8, 9, 0, 9, 6, 7, 6, 3, 9, 3, 4, 7, 7, 7, 4, 9, 0, 6, 4, 8, 4, 2, 7, 2, 8, 1, 0, 0, 7, 8, 3, 3, 3, 1, 3, 7, 6, 1, 3, 1, 6, 6, 5, 7, 4, 7, 5, 9, 5, 8, 4, 9, 9, 1, 6, 5, 0, 1, 3, 7, 0, 3, 4, 8, 2, 2, 0, 2, 5, 1, 5, 1, 4, 8, 8, 9, 1, 2, 1, 3, 5, 1, 0, 9, 4, 4, 8, 3, 2, 5, 9, 7, 6, 6, 2, 0, 0, 0, 5, 8, 7, 1, 5, 2, 3, 8, 5, 1, 8, 2, 0, 4, 9, 9, 6, 2, 3, 3, 5, 6, 4, 8, 0, 9, 2, 8, 3, 6, 7, 5, 7, 2, 9, 4, 9, 1, 2, 8, 6, 0, 7, 0, 9, 1, 1, 6, 7, 5, 9, 9, 1, 9, 5, 9, 2, 5, 0, 4, 1, 0, 8, 9, 0, 8, 9, 8, 9, 4, 2, 5, 7, 9, 8, 9, 8, 0, 9, 9, 6, 8, 9, 9, 5, 9, 8, 5, 1, 0, 3, 3, 5, 2, 1, 6, 5, 0, 2, 8, 1, 5, 6, 2, 3, 0, 2, 2, 6, 4, 3, 5, 5, 1, 7, 2, 1, 6, 9, 1, 9, 9, 5, 5, 1, 6, 2, 2, 8, 6, 7, 1, 4, 6, 0, 4, 0, 3, 3, 2, 2, 3, 6, 8, 9, 8, 5, 3, 8, 5, 4, 5, 2, 0, 5, 6, 3, 2, 8, 3, 9, 9, 5, 7, 9, 4, 6, 7, 1, 3, 7, 3, 6, 6, 0, 9, 0, 1, 9, 9, 2, 8, 8, 0, 1, 6, 9, 7, 5, 3, 4, 7, 4, 9, 9, 4, 3, 6, 3, 1, 1, 7, 6, 9, 1, 8, 4, 1, 1, 9, 9, 4, 3, 6, 8, 1, 6, 0, 4, 1, 3, 7, 7, 4, 9, 5, 1, 0, 0, 1, 1, 6, 2, 1, 9, 8, 4, 0, 3, 6, 4, 9, 0, 7, 1, 6, 5, 7, 5, 2, 5, 1, 8, 5, 4, 7, 0, 6, 7, 0, 2, 5, 8, 1, 0, 4, 5, 7, 1, 8, 5, 1, 9, 0, 0, 6, 0, 7, 3, 1, 8, 3, 9, 7, 0, 0, 8, 9, 5, 9, 8, 3, 2, 7, 2, 9, 7, 2, 1, 1, 3, 7, 5, 3, 1, 9, 8, 2, 2, 2, 8, 8, 5, 7, 3, 8, 9, 8, 8, 6, 8, 2, 3, 9, 7, 5, 6, 2, 9, 2, 8, 8, 1, 6, 8, 8, 7, 9, 1, 8, 0, 1, 7, 2, 0, 7, 5, 1, 9, 0, 2, 0, 9, 8, 6, 2, 3, 9, 3, 8, 0, 2, 1, 1, 1, 1, 4, 2, 9, 7, 2, 5, 1, 1, 2, 1, 9, 9, 9, 1, 0, 2, 0, 2, 1, 1, 4, 6, 4, 1, 5, 4, 9, 7, 7, 1, 5, 6, 2, 2, 2, 8, 0, 6, 9, 6, 1, 9, 7, 7, 1, 4, 8, 5, 3, 4, 3, 4, 9, 7, 5, 0, 7, 4, 8, 8, 1, 5, 3, 9, 5, 9, 7, 6, 9, 0, 3, 6, 3, 9, 8, 2, 2, 1, 2, 8, 6, 8, 5, 5, 3, 9, 4, 9, 2, 5, 1, 5, 1, 4, 4, 1, 4, 4, 3, 5, 9, 1, 2, 2, 3, 3, 0, 2, 9, 0, 0, 9, 9, 6, 0, 9, 3, 2, 8, 4, 1, 9, 9, 7, 2, 7, 9, 9, 5, 9, 5, 1, 1, 8, 3, 5, 1, 9, 5, 3, 5, 4, 9, 5, 9, 3, 1, 9, 0, 9, 7, 5, 4, 9, 2, 0, 1, 0, 5, 1, 4, 9, 3, 3, 6, 1, 5, 2, 5, 2, 2, 0, 9, 2, 6, 6, 0, 1, 2, 0, 3, 0, 2, 5, 5, 7, 9, 5, 5, 0, 8, 9, 5, 0, 3, 2, 5, 9, 0, 8, 8, 4, 5, 8, 8, 4, 5, 4, 8, 5, 4, 9, 2, 2, 1, 2, 6, 8, 8, 7, 0, 3, 6, 6, 4, 3, 8, 8, 7, 2, 2, 0, 0, 9, 3, 9, 9, 1, 9, 8, 6, 6, 4, 2, 6, 9, 2, 8, 5, 4, 5, 7, 9, 9, 9, 2, 1, 8, 3, 4, 0, 7, 8, 3, 9, 3, 4, 6, 5, 6, 2, 3, 9, 2, 6, 0, 0, 6, 1, 2, 8, 7, 9, 8, 2, 0, 4, 7, 7, 5, 0, 5, 6, 4, 6, 7, 4, 3, 0, 7, 5, 0, 7, 4, 2, 0, 8, 9, 9, 4, 2, 4, 6, 7, 8, 7, 6, 9, 4, 1, 3, 7, 3, 0, 8, 8, 7, 6, 9, 3, 9, 2, 2, 9, 2, 1, 8, 3, 2, 9, 6, 8, 4, 0, 1, 2, 8, 4, 5, 2, 7, 8, 1, 1, 3, 0, 3, 5, 7, 0, 3, 1, 9, 3, 6, 3, 1, 7, 7, 3, 0, 8, 4, 8, 2, 6, 5, 2, 9, 7, 3, 9, 0, 9, 9, 6, 4, 2, 9, 7, 2, 1, 1, 6, 7, 4, 7, 5, 9, 6, 8, 2, 1, 4, 4, 5, 7, 6, 1, 3, 2, 5, 9, 9, 3, 6, 1, 1, 4, 6, 9, 7, 2, 1, 5, 1, 4, 6, 3, 8, 1, 1, 0, 3, 1, 6, 8, 4, 9, 0, 7, 3, 0, 2, 9, 0, 6, 6, 6, 3, 6, 7, 7, 2, 8, 6, 0, 8, 3, 0, 2, 9, 8, 3, 2, 5, 3, 8, 8, 0, 0, 1, 9, 5, 1, 3, 9, 6, 0, 1, 4, 1, 7, 1, 2, 3, 7, 9, 7, 4, 9, 9, 3, 9, 2, 8, 2, 7, 1, 8, 0, 9, 1, 0, 1, 7, 7, 9, 6, 9, 9, 9, 2, 1, 6, 1, 3, 5, 7, 1, 9, 7, 6, 4, 5, 7, 6, 6, 9, 9, 6, 3, 6, 2, 9, 8, 1, 2, 2, 5, 5, 2, 3, 7, 2, 1, 0, 1, 0, 4, 5, 2, 8, 2, 8, 3, 5, 1, 7, 8, 1, 1, 2, 9, 7, 8, 4, 0, 3, 0, 7, 8, 8, 4, 7, 7, 8, 5, 8, 4, 9, 8, 1, 3, 8, 0, 3, 1, 7, 9, 5, 5, 1, 6, 5, 7, 4, 9, 3, 5, 4, 7, 1, 2, 0, 8, 1, 6, 0, 7, 3, 4, 7, 3, 9, 6, 0, 8, 6, 4, 8, 7, 7, 9, 3, 8, 6, 9, 7, 2, 3, 4, 0, 2, 1, 8, 3, 5, 5, 7, 2, 4, 6, 7, 2, 8, 3, 0, 8, 7, 8, 9, 0, 8, 4, 4, 5, 8, 5, 6, 6, 3, 0, 9, 3, 7, 6, 8, 9, 3, 4, 9, 5, 8, 9, 1, 2, 8, 8, 6, 8, 1, 3, 7, 9, 0, 1, 1, 4, 7, 0, 8, 1, 7, 4, 5, 7, 1, 2, 1, 1, 3, 9, 6, 2, 1, 2, 8, 0, 7, 6, 6, 9, 3, 7, 0, 5, 2, 8, 0, 5, 4, 3, 8, 4, 6, 6, 2, 7, 9, 5, 1, 3, 2, 4, 3, 6, 1, 9, 4, 4, 7, 6, 5, 4, 1, 9, 9, 2, 7, 8, 0, 1, 3, 6, 1, 3, 4, 1, 1, 1, 5, 6, 0, 7, 0, 7, 2, 3, 2, 5, 2, 2, 9, 4, 9, 8, 1, 2, 1, 6, 1, 2, 7, 8, 0, 0, 0, 8, 2, 2, 9, 2, 2, 7, 9, 9, 2, 7, 5, 1, 3, 4, 9, 4, 1, 8, 5, 6, 2, 8, 3, 1, 2, 8, 4, 9, 9, 3, 7, 0, 7, 7, 2, 3, 2, 4, 0, 3, 9, 9, 8, 4, 1, 0, 6, 0, 9, 6, 8, 6, 1, 1, 9, 8, 9, 2, 3, 5, 5, 9, 4, 2, 1, 9, 4, 3, 9, 6, 0, 4, 0, 6, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 3, 4, 7, 8, 6, 3, 4, 0, 9, 7, 1, 9, 3, 8, 4, 7, 3, 0, 9, 1, 4, 5, 4, 6, 2, 0, 6, 2, 1, 1, 1, 1, 7, 2, 4, 7, 5, 2, 9, 4, 5, 8, 4, 2, 9, 7, 0, 0, 7, 5, 1, 1, 7, 6, 6, 6, 8, 2, 2, 7, 7, 4, 0, 2, 4, 2, 1, 8, 9, 6, 1, 0, 5, 9, 6, 9, 8, 0, 3, 0, 8, 3, 9, 6, 3, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 5, 4, 8, 7, 4, 7, 7, 3, 9, 8, 8, 3, 1, 5, 8, 2, 7, 4, 2, 1, 5, 4, 5, 5, 8, 6, 4, 4, 4, 1, 8, 7, 5, 5, 1, 8, 9, 1, 3, 6, 3, 3, 2, 2, 6, 9, 9, 6, 5, 5, 3, 3, 8, 1, 6, 5, 6, 8, 1, 9, 7, 6, 8, 3, 7, 4, 7, 0, 9, 0, 0, 3, 7, 9, 3, 0, 2, 0, 1, 0, 1, 0, 4, 0, 1, 0, 4, 7, 9, 6, 2, 6, 2, 2, 9, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 0, 5, 6, 6, 0, 8, 0, 2, 3, 7, 9, 4, 7, 1, 9, 1, 7, 1, 4, 0, 0, 4, 1, 7, 5, 7, 1, 3, 3, 3, 1, 6, 9, 7, 4, 3, 0, 2, 5, 2, 6, 0, 8, 9, 4, 3, 5, 4, 8, 1, 5, 9, 0, 6, 4, 3, 6, 3, 3, 8, 1, 4, 7, 5, 7, 2, 2, 0, 0, 1, 7, 7, 9, 5, 9, 8, 9, 6, 8, 8, 2, 3, 6, 1, 2, 9, 8, 9, 5, 2, 6, 2, 4, 8, 4, 6, 5, 0, 1, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 4, 2, 0, 9, 0, 1, 5, 8, 8, 0, 2, 7, 8, 4, 4, 6, 1, 0, 4, 5, 3, 9, 4, 2, 0, 5, 0, 1, 3, 2, 9, 1, 6, 0, 1, 1, 8, 0, 4, 7, 7, 6, 3, 6, 0, 7, 3, 5, 4, 2, 4, 1, 8, 3, 5, 6, 7, 0, 6, 7, 1, 2, 5, 8, 1, 9, 3, 8, 2, 8, 7, 6, 7, 1, 4, 6, 2, 9, 3, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 0, 1, 2, 8, 9, 1, 4, 0, 9, 5, 0, 8, 0, 7, 7, 1, 1, 2, 9, 3, 6, 7, 2, 3, 8, 1, 2, 9, 8, 8, 7, 1, 7, 1, 1, 0, 3, 4, 2, 6, 4, 7, 4, 2, 7, 4, 9, 1, 0, 6, 8, 5, 5, 5, 3, 5, 9, 7, 4, 8, 5, 9, 6, 9, 3, 0, 3, 8, 9, 1, 8, 1, 6, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 3, 2, 9, 3, 2, 1, 4, 5, 5, 2, 3, 2, 1, 3, 9, 7, 2, 1, 2, 8, 9, 1, 8, 8, 7, 8, 1, 0, 0, 7, 7, 8, 7, 5, 0, 6, 1, 5, 7, 4, 6, 1, 2, 5, 0, 7, 9, 9, 0, 3, 8, 4, 4, 8, 1, 8, 6, 5, 9, 0, 0, 0, 3, 7, 1, 6, 4, 2, 6, 6, 0, 4, 5, 4, 1, 3, 8, 6, 3, 9, 9, 5, 9, 3, 7, 8, 5, 6, 4, 7, 6, 2, 2, 0, 9, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 5, 6, 0, 1, 2, 3, 4, 5, 6, 8, 7, 1, 3, 2, 8, 0, 7, 5, 9, 9, 6, 0, 9, 4, 1, 3, 2, 1, 2, 3, 8, 3, 2, 6, 5, 6, 8, 2, 7, 4, 8, 1, 8, 0, 5, 3, 9, 4, 1, 9, 2, 1, 9, 6, 7, 9, 0, 4, 6, 1, 7, 3, 8, 7, 2, 9, 6, 5, 8, 3, 9, 0, 5, 7, 1, 6, 1, 0, 9, 3, 3, 4, 4, 0, 6, 2, 5, 4, 2, 3, 4, 6, 0, 0, 2, 0, 1, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 7, 1, 3, 7, 5, 2, 8, 0, 7, 5, 9, 9, 0, 9, 1, 1, 5, 8, 8, 6, 3, 2, 1, 8, 3, 2, 6, 5, 6, 7, 4, 1, 0, 5, 3, 1, 9, 2, 1, 9, 6, 0, 4, 6, 1, 7, 3, 8, 7, 2, 9, 6, 5, 8, 3, 5, 7, 1, 6, 1, 0, 9, 6, 2, 5, 4, 2, 3, 4, 4, 6, 0, 0, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 6, 5, 0, 6, 8, 9, 4, 1, 9, 5, 3, 0, 4, 8, 9, 1, 4, 0, 5, 5, 2, 1, 5, 4, 0, 7, 6, 0, 1, 7, 0, 6, 8, 9, 5, 1, 7, 9, 8, 6, 0, 8, 1, 7, 7, 1, 3, 2, 3, 1, 4, 2, 0, 0, 7, 8, 4, 6, 4, 9, 3, 8, 4, 7, 2, 5, 6, 3, 6, 9, 6, 3, 2, 2, 4, 6, 9, 0, 2, 5, 5, 1, 3, 3, 9, 7, 8, 7, 2, 2, 5, 7, 9, 8, 2, 1, 3, 1, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 6, 5, 3, 0, 7, 0, 4, 1, 4, 3, 6, 7, 2, 3, 1, 2, 1, 2, 9, 6, 0, 1, 3, 0, 2, 7, 5, 7, 6, 2, 9, 1, 9, 0, 6, 0, 6, 0, 2, 0, 6, 1, 5, 8, 4, 3, 0, 1, 5, 4, 4, 8, 5, 7, 5, 7, 8, 3, 4, 8, 8, 5, 2, 9, 7, 1, 3, 8, 1, 0, 7, 5, 9, 6, 9, 4, 7, 7, 9, 9, 3, 4, 4, 3, 8, 6, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 8, 3, 9, 5, 5, 2, 6, 8, 4, 9, 1, 7, 1, 2, 3, 5, 9, 6, 9, 1, 1, 1, 2, 9, 5, 6, 8, 1, 2, 0, 7, 7, 5, 8, 2, 9, 8, 9, 0, 4, 6, 7, 1, 3, 4, 5, 6, 0, 3, 6, 8, 7, 0, 4, 2, 7, 4, 7, 5, 4, 3, 4, 2, 8, 1, 5, 1, 2, 0, 2, 5, 6, 4, 3, 0, 0, 0, 3, 3, 5, 7, 0, 6, 4, 8, 8, 6, 3, 4, 6, 9, 9, 8, 2, 7, 7, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 2, 1, 7, 2, 5, 0, 8, 0, 2, 7, 8, 8, 3, 6, 0, 2, 7, 6, 6, 1, 2, 8, 8, 7, 7, 4, 7, 7, 3, 7, 4, 5, 4, 3, 3, 8, 4, 1, 1, 9, 7, 4, 3, 7, 3, 3, 0, 2, 5, 5, 6, 6, 3, 5, 2, 5, 9, 9, 8, 4, 1, 0, 6, 0, 9, 6, 8, 8, 5, 6, 1, 1, 9, 8, 9, 2, 3, 5, 5, 9, 4, 2, 1, 9, 3, 9, 2, 0, 6, 0, 4, 0, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 7, 3, 0, 3, 1, 8, 7, 6, 4, 0, 2, 6, 8, 3, 2, 8, 1, 2, 0, 7, 1, 0, 4, 4, 5, 8, 0, 6, 2, 3, 1, 5, 1, 8, 5, 9, 4, 0, 7, 5, 8, 8, 3, 8, 9, 2, 6, 2, 5, 3, 1, 7, 3, 9, 1, 9, 9, 6, 0, 3, 9, 2, 8, 1, 4, 3, 5, 2, 9, 2, 5, 8, 9, 5, 0, 1, 2, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 0, 4, 5, 6, 6, 3, 4, 4, 2, 8, 1, 0, 6, 4, 9, 7, 2, 3, 3, 9, 2, 0, 9, 3, 3, 9, 1, 5, 2, 3, 7, 7, 8, 4, 0, 2, 4, 0, 2, 4, 7, 8, 0, 7, 0, 6, 9, 3, 2, 8, 6, 0, 5, 7, 5, 1, 0, 8, 1, 6, 7, 2, 9, 7, 9, 5, 8, 6, 2, 6, 2, 8, 1, 7, 5, 0, 1, 1, 3, 8, 4, 9, 1, 8, 6, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 7, 8, 9, 9, 8, 9, 8, 4, 1, 7, 7, 3, 3, 7, 6, 6, 6, 1, 9, 0, 1, 7, 6, 3, 2, 1, 7, 1, 3, 9, 1, 7, 6, 8, 4, 1, 4, 3, 6, 9, 6, 1, 4, 4, 7, 2, 4, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 9, 0, 1, 2, 3, 4, 7, 8, 1, 3, 5, 1, 7, 7, 2, 1, 4, 8, 3, 4, 4, 3, 9, 7, 4, 1, 2, 3, 5, 9, 1, 6, 0, 1, 0, 0, 2, 8, 7, 1, 1, 4, 0, 4, 7, 3, 6, 8, 0, 3, 7, 4, 0, 6, 9, 2, 6, 5, 8, 6, 9, 0, 4, 0, 6, 1, 9, 2, 0, 9, 5, 1, 3, 7, 6, 9, 3, 0, 2, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 7, 2, 5, 0, 8, 0, 2, 7, 8, 8, 3, 0, 6, 0, 2, 7, 6, 6, 1, 2, 8, 8, 7, 7, 4, 7, 7, 3, 7, 4, 5, 4, 3, 3, 8, 4, 5, 4, 1, 1, 9, 7, 4, 3, 7, 3, 3, 0, 2, 5, 5, 6, 3, 1, 5, 2, 5, 9, 9, 8, 4, 1, 0, 6, 0, 9, 6, 8, 8, 5, 6, 1, 1, 9, 8, 9, 2, 3, 5, 5, 9, 4, 2, 1, 9, 4, 9, 1, 3, 9, 2, 0, 6, 0, 4, 0, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 8, 0, 7, 1, 0, 7, 5, 5, 6, 9, 0, 1, 0, 0, 8, 3, 4, 3, 1, 5, 0, 0, 9, 5, 3, 4, 9, 3, 7, 6, 9, 2, 4, 5, 7, 2, 6, 4, 9, 4, 9, 4, 1, 2, 2, 5, 8, 1, 3, 2, 9, 4, 3, 8, 2, 2, 1, 2, 8, 6, 5, 1, 6, 7, 2, 1, 3, 9, 3, 8, 7, 5, 7, 0, 7, 4, 8, 8, 5, 0, 6, 6, 3, 7, 6, 9, 9, 4, 8, 4, 1, 0, 6, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 4, 0, 4, 0, 1, 7, 9, 5, 1, 4, 2, 8, 9, 4, 3, 7, 8, 2, 4, 4, 3, 3, 6, 9, 9, 5, 8, 6, 7, 0, 6, 8, 2, 6, 3, 9, 3, 2, 8, 6, 1, 7, 4, 8, 8, 9, 0, 3, 3, 9, 0, 5, 2, 9, 4, 1, 0, 3, 7, 5, 8, 7, 7, 8, 2, 9, 7, 1, 2, 6, 4, 2, 5, 2, 3, 6, 6, 5, 0, 0, 2, 8, 1, 6, 1, 0, 4, 3, 1, 6, 1, 9, 0, 1, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 4, 0, 0, 7, 2, 4, 3, 8, 6, 6, 3, 2, 6, 3, 3, 0, 1, 4, 7, 8, 0, 3, 1, 9, 0, 1, 9, 1, 2, 7, 0, 1, 3, 8, 2, 9, 2, 7, 6, 5, 5, 9, 9, 8, 2, 9, 1, 3, 2, 3, 4, 3, 1, 9, 0, 9, 3, 6, 8, 7, 0, 1, 0, 5, 8, 2, 7, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 7, 4, 8, 1, 5, 6, 5, 7, 2, 8, 6, 3, 3, 8, 6, 5, 4, 0, 9, 1, 7, 2, 9, 1, 5, 1, 3, 2, 2, 3, 0, 6, 4, 3, 7, 6, 9, 0, 4, 8, 1, 4, 0, 6, 1, 2, 6, 9, 2, 2, 3, 5, 5, 1, 0, 7, 7, 9, 6, 2, 9, 4, 7, 0, 2, 3, 4, 0, 0, 8, 8, 8, 5, 1, 3, 7, 4, 9, 8, 8, 9, 0, 9, 8, 9, 0, 2, 6, 5, 6, 7, 4, 7, 5, 4, 1, 3, 5, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 0, 1, 2, 4, 5, 6, 7, 8, 1, 7, 2, 4, 1, 4, 1, 4, 9, 6, 8, 4, 5, 3, 7, 8, 4, 3, 3, 5, 6, 7, 0, 6, 1, 6, 8, 7, 0, 1, 5, 0, 8, 5, 0, 1, 5, 8, 4, 2, 3, 9, 7, 6, 9, 1, 9, 0, 6, 7, 1, 2, 3, 9, 2, 4, 5, 5, 3, 7, 5, 3, 1, 8, 2, 2, 3, 0, 2, 9, 4, 9, 7, 0, 2, 7, 4, 9, 9, 2, 5, 9, 8, 3, 8, 6, 7, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 7, 2, 6, 5, 5, 3, 7, 8, 6, 6, 6, 6, 4, 3, 8, 8, 3, 0, 1, 9, 0, 5, 4, 1, 9, 1, 2, 7, 0, 1, 3, 8, 2, 9, 2, 7, 4, 2, 6, 5, 5, 9, 9, 1, 1, 5, 7, 6, 8, 2, 9, 4, 3, 1, 9, 0, 9, 3, 6, 8, 7, 0, 1, 0, 5, 8, 2, 7, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 2, 1, 3, 9, 9, 8, 5, 3, 7, 0, 7, 7, 5, 7, 9, 9, 4, 7, 0, 3, 4, 1, 5, 8, 1, 4, 8, 4, 1, 8, 6, 6, 4, 6, 0, 5, 5, 3, 3, 5, 7, 2, 5, 9, 6, 9, 2, 6, 2, 1, 2, 0, 8, 3, 8, 3, 0, 8, 7, 4, 9, 5, 0, 9, 7, 0, 0, 4, 6, 0, 9, 1, 6, 2, 7, 6, 8, 3, 5, 2, 1, 8, 3, 8, 6, 1, 0, 2, 1, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 6, 4, 7, 6, 2, 3, 4, 8, 7, 8, 6, 9, 8, 3, 2, 2, 8, 4, 8, 5, 6, 5, 0, 2, 0, 1, 1, 2, 9, 6, 8, 2, 1, 0, 6, 5, 2, 9, 7, 5, 3, 9, 3, 7, 1, 8, 3, 8, 1, 9, 5, 5, 0, 1, 1, 9, 8, 2, 6, 0, 4, 5, 0, 3, 1, 8, 6, 7, 5, 9, 9, 3, 0, 3, 1, 4, 4, 0, 4, 9, 0, 1, 2, 3, 5, 6, 7, 8, 0, 1, 2, 3, 5, 6, 7, 8, 9, 0, 1, 2, 3, 5, 6, 7, 8, 9, 9, 7, 0, 9, 0, 1, 5, 8, 8, 0, 9, 3, 2, 7, 8, 4, 6, 1, 0, 4, 9, 4, 2, 0, 5, 0, 1, 6, 9, 3, 2, 9, 1, 6, 0, 1, 1, 8, 7, 7, 6, 3, 6, 0, 7, 2, 4, 1, 7, 0, 6, 7, 1, 2, 5, 8, 1, 8, 2, 8, 7, 6, 8, 7, 1, 6, 2, 9, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 9, 5, 7, 0, 3, 1, 6, 8, 4, 1, 5, 6, 4, 2, 7, 8, 1, 3, 4, 3, 4, 7, 2, 0, 5, 0, 1, 9, 2, 3, 2, 3, 5, 5, 7, 8, 4, 9, 9, 7, 1, 1, 9, 0, 7, 8, 3, 4, 8, 6, 3, 8, 0, 9, 6, 2, 1, 0, 1, 0, 6, 2, 3, 8, 9, 0, 7, 2, 3, 4, 5, 5, 2, 8, 5, 4, 6, 6, 6, 7, 9, 1, 8, 2, 1, 5, 3, 4, 7, 9, 4, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 9, 0, 1, 3, 1, 5, 1, 2, 4, 9, 2, 4, 6, 8, 0, 1, 1, 9, 2, 6, 6, 8, 7, 4, 2, 9, 7, 0, 2, 1, 0, 3, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 6, 5, 9, 7, 0, 2, 3, 4, 3, 8, 5, 1, 5, 2, 3, 0, 1, 2, 1, 3, 2, 6, 5, 3, 0, 7, 2, 7, 4, 6, 4, 0, 5, 9, 9, 8, 9, 5, 3, 1, 7, 4, 7, 6, 5, 4, 0, 0, 6, 6, 2, 0, 6, 3, 7, 7, 4, 4, 3, 9, 2, 8, 9, 6, 0, 9, 5, 3, 8, 8, 7, 1, 4, 0, 4, 8, 5, 2, 3, 9, 0, 1, 9, 1, 5, 1, 7, 4, 8, 6, 2, 1, 6, 8, 8, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 6, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 1, 4, 5, 3, 3, 0, 9, 5, 4, 3, 0, 8, 4, 6, 7, 0, 7, 7, 1, 6, 9, 1, 3, 6, 2, 3, 8, 2, 3, 8, 9, 5, 8, 8, 7, 1, 7, 1, 1, 0, 3, 4, 2, 6, 4, 7, 4, 2, 7, 4, 2, 9, 2, 7, 9, 2, 1, 0, 6, 5, 3, 4, 8, 5, 9, 6, 9, 0, 6, 3, 0, 8, 1, 6, 0, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 7, 2, 5, 1, 6, 4, 3, 9, 9, 0, 9, 7, 1, 6, 4, 3, 6, 2, 0, 9, 8, 6, 5, 7, 0, 0, 1, 7, 4, 3, 2, 4, 1, 3, 7, 6, 4, 7, 7, 7, 9, 8, 4, 3, 8, 2, 8, 3, 5, 8, 0, 5, 4, 7, 1, 3, 1, 7, 9, 6, 2, 0, 9, 1, 7, 3, 3, 9, 1, 6, 4, 3, 9, 8, 2, 1, 8, 6, 4, 1, 5, 5, 6, 5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 9, 7, 0, 2, 3, 4, 3, 8, 5, 1, 3, 0, 1, 2, 1, 3, 2, 0, 7, 2, 6, 4, 0, 5, 9, 9, 8, 9, 5, 3, 1, 7, 4, 7, 0, 0, 6, 6, 6, 3, 7, 4, 2, 8, 9, 8, 7, 1, 4, 0, 4, 8, 5, 2, 3, 9, 0, 1, 9, 1, 5, 1, 7, 6, 1, 2, 1, 6, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 5, 6, 7, 8, 1, 0, 4, 5, 6, 6, 3, 4, 4, 2, 8, 1, 0, 6, 4, 9, 7, 2, 9, 2, 0, 9, 3, 3, 9, 1, 5, 2, 3, 1, 6, 7, 3, 7, 8, 4, 0, 2, 4, 0, 2, 4, 7, 8, 0, 7, 0, 6, 9, 3, 2, 4, 8, 6, 0, 5, 7, 5, 1, 0, 8, 1, 6, 7, 2, 9, 7, 9, 5, 6, 5, 2, 6, 2, 8, 1, 7, 5, 5, 7, 3, 5, 0, 1, 1, 3, 8, 4, 9, 4, 5, 1, 8, 6, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 3, 2, 9, 3, 2, 1, 4, 5, 5, 2, 3, 2, 1, 3, 9, 7, 2, 1, 2, 8, 9, 1, 8, 8, 7, 8, 1, 0, 0, 6, 7, 7, 8, 7, 5, 0, 6, 1, 5, 7, 4, 6, 1, 2, 5, 0, 7, 9, 9, 0, 3, 4, 4, 8, 4, 1, 8, 6, 5, 9, 0, 0, 0, 3, 7, 1, 6, 4, 6, 0, 4, 5, 4, 1, 3, 8, 6, 3, 9, 9, 5, 9, 3, 7, 8, 5, 6, 4, 7, 6, 2, 2, 0, 9, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 4, 2, 6, 4, 7, 5, 5, 4, 7, 2, 9, 3, 9, 3, 8, 2, 0, 9, 5, 6, 0, 1, 0, 6, 5, 3, 5, 3, 8, 0, 0, 3, 4, 1, 5, 3, 0, 8, 3, 0, 6, 2, 7, 8, 1, 7, 1, 3, 8, 5, 4, 2, 0, 9, 7, 6, 7, 4, 1, 6, 2, 6, 7, 1, 9, 8, 0, 6, 9, 4, 9, 9, 6, 2, 3, 7, 1, 9, 2, 2, 5, 3, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 7, 8, 9, 8, 9, 2, 6, 1, 3, 5, 4, 8, 2, 6, 4, 3, 4, 5, 9, 2, 0, 3, 9, 4, 9, 7, 3, 8, 7, 4, 4, 9, 8, 5, 8, 2, 6, 6, 2, 3, 1, 3, 2, 7, 3, 1, 9, 0, 1, 1, 3, 5, 0, 7, 8, 1, 5, 1, 4, 6, 0, 0, 4, 9, 1, 6, 6, 9, 0, 7, 6, 1, 1, 0, 1, 2, 3, 4, 7, 2, 3, 4, 5, 6, 7, 0, 1, 2, 7, 8, 6, 3, 9, 7, 1, 9, 3, 9, 6, 1, 7, 2, 4, 4, 5, 7, 0, 0, 1, 6, 6, 8, 2, 7, 7, 2, 4, 2, 1, 6, 1, 0, 6, 9, 8, 3, 9, 6, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 6, 8, 9, 9, 0, 1, 2, 4, 4, 3, 7, 4, 4, 4, 0, 3, 8, 7, 5, 8, 2, 1, 7, 5, 3, 8, 5, 2, 5, 1, 1, 6, 2, 1, 3, 8, 6, 4, 2, 6, 2, 5, 5, 0, 2, 8, 0, 6, 8, 1, 7, 9, 1, 9, 2, 6, 7, 6, 6, 8, 7, 4, 9, 2, 1, 3, 3, 0, 5, 5, 8, 0, 3, 7, 9, 7, 0, 2, 7, 9, 1, 7, 8, 0, 3, 5, 3, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 6, 4, 2, 6, 4, 7, 8, 9, 2, 9, 3, 9, 3, 0, 0, 1, 0, 4, 2, 6, 3, 5, 3, 0, 3, 4, 1, 5, 3, 0, 8, 3, 0, 6, 1, 7, 8, 0, 9, 2, 6, 7, 1, 9, 6, 9, 4, 9, 9, 6, 7, 1, 2, 5, 3, 7, 8, 0, 1, 2, 4, 5, 6, 7, 8, 9, 0, 1, 3, 4, 5, 6, 7, 8, 0, 1, 3, 4, 7, 8, 9, 7, 5, 5, 1, 9, 9, 7, 1, 0, 0, 5, 9, 7, 1, 7, 2, 2, 3, 6, 8, 3, 2, 0, 0, 6, 1, 7, 5, 8, 6, 2, 9, 4, 8, 8, 7, 1, 0, 8, 7, 7, 5, 8, 5, 3, 4, 6, 1, 1, 5, 5, 0, 7, 2, 3, 6, 4, 1, 2, 4, 1, 5, 4, 2, 0, 4, 8, 6, 1, 9, 0, 2, 5, 6, 9, 3, 6, 3, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 5, 6, 7, 8, 1, 0, 9, 5, 7, 5, 1, 8, 6, 9, 0, 4, 1, 9, 3, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 5, 9, 6, 0, 6, 5, 5, 3, 3, 3, 9, 8, 1, 1, 0, 6, 1, 0, 0, 6, 2, 1, 1, 3, 2, 7, 7, 8, 8, 7, 8, 4, 6, 0, 2, 0, 7, 0, 3, 6, 8, 7, 1, 5, 9, 9, 3, 7, 2, 4, 9, 4, 3, 6, 2, 2, 5, 3, 2, 5, 5, 9, 4, 1, 7, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 0, 1, 2, 7, 5, 3, 4, 4, 0, 0, 6, 9, 6, 6, 5, 7, 2, 3, 4, 4, 9, 1, 4, 0, 7, 9, 5, 7, 2, 3, 1, 4, 4, 0, 9, 9, 6, 1, 8, 3, 3, 7, 3, 9, 8, 8, 4, 7, 7, 6, 2, 1, 9, 8, 7, 8, 8, 7, 2, 2, 3, 9, 3, 3, 5, 5, 0, 7, 9, 5, 6, 5, 1, 4, 1, 1, 2, 8, 2, 6, 1, 5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 0, 6, 0, 0, 2, 3, 7, 9, 4, 7, 1, 9, 1, 7, 1, 4, 0, 0, 1, 7, 5, 7, 1, 3, 3, 3, 1, 6, 9, 7, 1, 3, 0, 2, 6, 0, 8, 9, 4, 3, 5, 4, 8, 1, 5, 9, 0, 6, 6, 3, 8, 1, 4, 7, 5, 2, 0, 0, 1, 7, 8, 9, 6, 8, 8, 2, 3, 6, 1, 2, 9, 5, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 4, 6, 1, 4, 0, 9, 9, 3, 7, 8, 4, 7, 5, 8, 5, 3, 2, 2, 0, 5, 8, 6, 0, 3, 8, 1, 0, 3, 0, 4, 7, 4, 9, 2, 9, 5, 7, 1, 7, 1, 6, 6, 5, 6, 2, 8, 7, 6, 4, 9, 9, 5, 3, 7, 4, 3, 0, 4, 6, 6, 1, 1, 3, 2, 1, 0, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 0, 8, 3, 9, 5, 5, 2, 6, 8, 4, 1, 7, 1, 2, 3, 5, 6, 9, 1, 1, 1, 2, 1, 2, 0, 7, 7, 5, 8, 2, 9, 8, 6, 7, 3, 4, 6, 8, 7, 0, 4, 2, 7, 7, 5, 4, 3, 4, 2, 8, 1, 5, 1, 0, 2, 3, 3, 5, 7, 0, 6, 8, 6, 3, 9, 9, 8, 2, 7, 7, 1, 0, 1, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 7, 8, 6, 4, 1, 9, 3, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 6, 0, 6, 5, 3, 3, 3, 9, 1, 4, 0, 6, 1, 0, 0, 6, 2, 1, 1, 7, 7, 8, 4, 6, 0, 7, 0, 3, 6, 8, 7, 1, 5, 2, 4, 9, 4, 3, 6, 4, 1, 7, 2, 6, 5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6]\n",
            "10000\n",
            "16\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSIUyjdNlpu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1866c273-380a-420c-c2e5-38bf03dfdcb3"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn= KNeighborsClassifier(n_neighbors=9)\n",
        "knn.fit(train_features,train_labels)\n",
        "res=knn.predict(test_features)\n",
        "correct=(res==test_labels).sum()\n",
        "print(correct)\n",
        "print(len(test_labels))\n",
        "print(correct/len(test_labels))\n",
        "\n",
        "train_labels=np.asarray(train_labels)\n",
        "test_labels=np.asarray(test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9716\n",
            "10000\n",
            "0.9716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07yjNu1gRcNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ce89203f-7fe1-48d6-95d7-e6f151224f02"
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from scipy.spatial.distance import cdist\n",
        "Y = cdist(test_features[:5000],train_features)\n",
        "ind = np.argsort(Y,axis=1)\n",
        "prec = 0.0;\n",
        "acc = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0];\n",
        "# calculating statistics\n",
        "\n",
        "# print(len(np.shape(test_features)[0]):))\n",
        "for k in range(np.shape(test_features[:5000])[0]):\n",
        "    class_values = train_labels[ind[k,:]]\n",
        "    y_true = (test_labels[:5000][k] == class_values)\n",
        "    y_scores = np.arange(y_true.shape[0],0,-1)\n",
        "    ap = average_precision_score(y_true, y_scores)\n",
        "    prec = prec + ap\n",
        "    for n in range(len(acc)):\n",
        "        a = class_values[0:(n+1)]\n",
        "        counts = np.bincount(a)\n",
        "        b = np.where(counts==np.max(counts))[0]\n",
        "        if test_labels[:5000][k] in b:\n",
        "            acc[n] = acc[n] + (1.0/float(len(b)))\n",
        "\n",
        "prec = prec/float(np.shape(test_features[:5000])[0])\n",
        "acc= [x / float(np.shape(test_features[:5000])[0]) for x in acc]\n",
        "print(\"Final results: \")\n",
        "print(\"mAP value: %.4f \"% prec)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final results: \n",
            "mAP value: 0.8953 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OLrRXe-0stg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "666d5f9c-b004-4895-8fdd-b46c46753e69"
      },
      "source": [
        "prec1=prec\n",
        "Y = cdist(test_features[5000:],train_features)\n",
        "ind = np.argsort(Y,axis=1)\n",
        "prec = 0.0;\n",
        "acc = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0];\n",
        "# calculating statistics\n",
        "\n",
        "# print(len(np.shape(test_features)[0]):))\n",
        "for k in range(np.shape(test_features[5000:])[0]):\n",
        "    class_values = train_labels[ind[k,:]]\n",
        "    y_true = (test_labels[5000:][k] == class_values)\n",
        "    y_scores = np.arange(y_true.shape[0],0,-1)\n",
        "    ap = average_precision_score(y_true, y_scores)\n",
        "    prec = prec + ap\n",
        "    for n in range(len(acc)):\n",
        "        a = class_values[0:(n+1)]\n",
        "        counts = np.bincount(a)\n",
        "        b = np.where(counts==np.max(counts))[0]\n",
        "        if test_labels[5000:][k] in b:\n",
        "            acc[n] = acc[n] + (1.0/float(len(b)))\n",
        "\n",
        "prec = prec/float(np.shape(test_features[5000:])[0])\n",
        "acc= [x / float(np.shape(test_features[5000:])[0]) for x in acc]\n",
        "print(\"Final results: \")\n",
        "print(\"mAP value: %.4f \"% prec)\n",
        "prec2=prec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final results: \n",
            "mAP value: 0.9530 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjw7Q0PIrGn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "35b27e45-868f-42b9-db61-b308df311147"
      },
      "source": [
        "print(\"Final avg mAP\")\n",
        "print((prec1+prec2)/2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final avg mAP\n",
            "0.9241671653744923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ-gZgPY3QIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f84a24b26f1a4f2a90faaafdb0da9e5a",
            "dc9a644d9ae44b7a985f5c4ad0a55dea",
            "2fa8789b5f0341e1927fe43917babf96",
            "74e34c7136b1460cbf805cc111e9c07d",
            "6ae97abfd38f4a3db83a98d2e0bd7b63",
            "922ac5f91d61419484bdaf2f26484eea",
            "ced81162c63b43738e037bb3cca72424",
            "1ec6ca7ce74146eb978dfa244c81b285",
            "6333474d87124a5dbe60a128769beb7f",
            "2e68321809f649b6bfc65db99c148cb4",
            "a3a4cba86d4346c5b2407154217a1fcc",
            "58c14e4aacd64cf5bd405c917104337c",
            "c3076332c11849f0a7d55d6a97c530b0",
            "56429fc04da842c89a85983911e10240",
            "e6eebce61385416d8d4f6af7005d9012",
            "0b8f7d4835114068902b874165232e6c",
            "ee86454c3b66477a842333973294056d",
            "88315fa0bfe54da982c3531344b2d9a0",
            "a40b28b9dabf4f399c42b1ae64200237",
            "b8c5ff5f99b743c28d50bb727334a4b0",
            "987acf2a049b48eaba0f3a72176b1bab",
            "b05f5072eef9449e9a947b99cddb17d1",
            "1a274f19eefc482e9f6f21f003e3c6d0",
            "65639ba8b05c485fa8a3c03c2722786b",
            "aa08b144a8464078906aa3a9a23b6474",
            "efa997b23f3f4dacbe644416f004a3ac",
            "b85ed24b1f9e4d6d8b671243c159db4b",
            "2f2cc8fedbd343c189ecdadf67b6c02d",
            "8946326c20e3452ba00890c15ffe3e49",
            "070ff03244694399b65cd7ce8e232ddc",
            "1fcef2f9c10448229bda1d4908845b66",
            "fd1ada90441441c0bf8ed4ed11bfa331"
          ]
        },
        "outputId": "5ddbe9c1-107d-42b8-c209-593419d4d8e2"
      },
      "source": [
        "##pretraining\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/DL/EndSem/pretrained_32')\n",
        "\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "cuda=True\n",
        "# Initialize generator and discriminator\n",
        "discriminator = Discriminator()\n",
        "generator = Generator(100)\n",
        "\n",
        "generator=generator.cuda()\n",
        "discriminator=discriminator.cuda()\n",
        "adversarial_loss=adversarial_loss.cuda()\n",
        "\n",
        "dataloader = DataLoader(MNISTunlab(), batch_size = 100)\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.003, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.003, betas=(0.5, 0.999))\n",
        "\n",
        "for epoch in range(50):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        \n",
        "        # print(imgs)\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0).cuda()\n",
        "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0).cuda()\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = imgs.cuda()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        # z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(100,cuda=True)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        # print(discriminator(gen_imgs,pretrain=True,cuda=True))\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs,pretrain=True,cuda=True), valid)\n",
        "        # optimizer_G.zero_grad()\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs,pretrain=True,cuda=True), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(),pretrain=True,cuda=True), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        # optimizer_D.zero_grad()\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, 50, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "    torch.save(discriminator,'pretrained_32_D'+str(epoch)+\".pkl\")\n",
        "    torch.save(generator,'pretrained_32_G'+str(epoch)+\".pkl\")\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f84a24b26f1a4f2a90faaafdb0da9e5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6333474d87124a5dbe60a128769beb7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee86454c3b66477a842333973294056d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa08b144a8464078906aa3a9a23b6474",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "[Epoch 0/50] [Batch 0/600] [D loss: 0.751488] [G loss: 0.600828]\n",
            "\n",
            "[Epoch 0/50] [Batch 1/600] [D loss: 0.688894] [G loss: 2.447407]\n",
            "[Epoch 0/50] [Batch 2/600] [D loss: 0.457423] [G loss: 1.212205]\n",
            "[Epoch 0/50] [Batch 3/600] [D loss: 0.164125] [G loss: 3.554856]\n",
            "[Epoch 0/50] [Batch 4/600] [D loss: 0.057958] [G loss: 2.926473]\n",
            "[Epoch 0/50] [Batch 5/600] [D loss: 0.012819] [G loss: 6.404612]\n",
            "[Epoch 0/50] [Batch 6/600] [D loss: 0.154545] [G loss: 3.303911]\n",
            "[Epoch 0/50] [Batch 7/600] [D loss: 2.859488] [G loss: 18.813271]\n",
            "[Epoch 0/50] [Batch 8/600] [D loss: 0.094208] [G loss: 2.427182]\n",
            "[Epoch 0/50] [Batch 9/600] [D loss: 0.863313] [G loss: 0.362939]\n",
            "[Epoch 0/50] [Batch 10/600] [D loss: 0.106746] [G loss: 3.261362]\n",
            "[Epoch 0/50] [Batch 11/600] [D loss: 0.181455] [G loss: 4.158714]\n",
            "[Epoch 0/50] [Batch 12/600] [D loss: 0.129990] [G loss: 3.239583]\n",
            "[Epoch 0/50] [Batch 13/600] [D loss: 0.235793] [G loss: 1.386136]\n",
            "[Epoch 0/50] [Batch 14/600] [D loss: 0.163297] [G loss: 2.714527]\n",
            "[Epoch 0/50] [Batch 15/600] [D loss: 0.091244] [G loss: 3.893194]\n",
            "[Epoch 0/50] [Batch 16/600] [D loss: 0.343770] [G loss: 1.774923]\n",
            "[Epoch 0/50] [Batch 17/600] [D loss: 0.676020] [G loss: 10.151615]\n",
            "[Epoch 0/50] [Batch 18/600] [D loss: 0.207515] [G loss: 6.081929]\n",
            "[Epoch 0/50] [Batch 19/600] [D loss: 2.846892] [G loss: 0.129579]\n",
            "[Epoch 0/50] [Batch 20/600] [D loss: 0.682274] [G loss: 6.536081]\n",
            "[Epoch 0/50] [Batch 21/600] [D loss: 0.487934] [G loss: 4.543329]\n",
            "[Epoch 0/50] [Batch 22/600] [D loss: 0.441608] [G loss: 1.301193]\n",
            "[Epoch 0/50] [Batch 23/600] [D loss: 0.455046] [G loss: 1.124488]\n",
            "[Epoch 0/50] [Batch 24/600] [D loss: 0.341503] [G loss: 2.095638]\n",
            "[Epoch 0/50] [Batch 25/600] [D loss: 0.256283] [G loss: 2.438567]\n",
            "[Epoch 0/50] [Batch 26/600] [D loss: 0.186929] [G loss: 2.330927]\n",
            "[Epoch 0/50] [Batch 27/600] [D loss: 0.081638] [G loss: 3.791611]\n",
            "[Epoch 0/50] [Batch 28/600] [D loss: 0.103683] [G loss: 2.398779]\n",
            "[Epoch 0/50] [Batch 29/600] [D loss: 0.069474] [G loss: 7.206854]\n",
            "[Epoch 0/50] [Batch 30/600] [D loss: 0.019633] [G loss: 5.865436]\n",
            "[Epoch 0/50] [Batch 31/600] [D loss: 0.181512] [G loss: 1.559526]\n",
            "[Epoch 0/50] [Batch 32/600] [D loss: 0.181319] [G loss: 12.621534]\n",
            "[Epoch 0/50] [Batch 33/600] [D loss: 0.013633] [G loss: 11.073313]\n",
            "[Epoch 0/50] [Batch 34/600] [D loss: 0.001151] [G loss: 6.647638]\n",
            "[Epoch 0/50] [Batch 35/600] [D loss: 0.089179] [G loss: 2.576817]\n",
            "[Epoch 0/50] [Batch 36/600] [D loss: 0.053084] [G loss: 6.714439]\n",
            "[Epoch 0/50] [Batch 37/600] [D loss: 0.032087] [G loss: 4.627733]\n",
            "[Epoch 0/50] [Batch 38/600] [D loss: 0.072549] [G loss: 2.617750]\n",
            "[Epoch 0/50] [Batch 39/600] [D loss: 0.044005] [G loss: 3.487061]\n",
            "[Epoch 0/50] [Batch 40/600] [D loss: 0.042282] [G loss: 4.070093]\n",
            "[Epoch 0/50] [Batch 41/600] [D loss: 0.700874] [G loss: 2.555968]\n",
            "[Epoch 0/50] [Batch 42/600] [D loss: 2.946647] [G loss: 6.237126]\n",
            "[Epoch 0/50] [Batch 43/600] [D loss: 0.894681] [G loss: 0.604677]\n",
            "[Epoch 0/50] [Batch 44/600] [D loss: 0.616770] [G loss: 0.567600]\n",
            "[Epoch 0/50] [Batch 45/600] [D loss: 0.466017] [G loss: 0.827447]\n",
            "[Epoch 0/50] [Batch 46/600] [D loss: 0.404794] [G loss: 1.088246]\n",
            "[Epoch 0/50] [Batch 47/600] [D loss: 0.334488] [G loss: 1.151739]\n",
            "[Epoch 0/50] [Batch 48/600] [D loss: 0.290114] [G loss: 1.310783]\n",
            "[Epoch 0/50] [Batch 49/600] [D loss: 0.320157] [G loss: 1.707834]\n",
            "[Epoch 0/50] [Batch 50/600] [D loss: 0.312138] [G loss: 1.801435]\n",
            "[Epoch 0/50] [Batch 51/600] [D loss: 0.292887] [G loss: 2.283986]\n",
            "[Epoch 0/50] [Batch 52/600] [D loss: 0.253661] [G loss: 2.316204]\n",
            "[Epoch 0/50] [Batch 53/600] [D loss: 0.179991] [G loss: 3.049342]\n",
            "[Epoch 0/50] [Batch 54/600] [D loss: 0.574110] [G loss: 1.408029]\n",
            "[Epoch 0/50] [Batch 55/600] [D loss: 1.485803] [G loss: 6.471418]\n",
            "[Epoch 0/50] [Batch 56/600] [D loss: 0.577969] [G loss: 0.744695]\n",
            "[Epoch 0/50] [Batch 57/600] [D loss: 0.568243] [G loss: 0.676082]\n",
            "[Epoch 0/50] [Batch 58/600] [D loss: 0.494960] [G loss: 1.082958]\n",
            "[Epoch 0/50] [Batch 59/600] [D loss: 0.371796] [G loss: 1.476049]\n",
            "[Epoch 0/50] [Batch 60/600] [D loss: 0.271017] [G loss: 1.471452]\n",
            "[Epoch 0/50] [Batch 61/600] [D loss: 0.211901] [G loss: 1.769853]\n",
            "[Epoch 0/50] [Batch 62/600] [D loss: 0.160167] [G loss: 2.381171]\n",
            "[Epoch 0/50] [Batch 63/600] [D loss: 0.272271] [G loss: 2.208541]\n",
            "[Epoch 0/50] [Batch 64/600] [D loss: 0.217493] [G loss: 3.208055]\n",
            "[Epoch 0/50] [Batch 65/600] [D loss: 0.936922] [G loss: 1.147229]\n",
            "[Epoch 0/50] [Batch 66/600] [D loss: 1.653173] [G loss: 9.144555]\n",
            "[Epoch 0/50] [Batch 67/600] [D loss: 0.749061] [G loss: 3.659042]\n",
            "[Epoch 0/50] [Batch 68/600] [D loss: 0.535676] [G loss: 1.243563]\n",
            "[Epoch 0/50] [Batch 69/600] [D loss: 0.561397] [G loss: 0.810336]\n",
            "[Epoch 0/50] [Batch 70/600] [D loss: 0.543698] [G loss: 0.856002]\n",
            "[Epoch 0/50] [Batch 71/600] [D loss: 0.436689] [G loss: 0.981371]\n",
            "[Epoch 0/50] [Batch 72/600] [D loss: 0.374161] [G loss: 1.187033]\n",
            "[Epoch 0/50] [Batch 73/600] [D loss: 0.349711] [G loss: 1.284649]\n",
            "[Epoch 0/50] [Batch 74/600] [D loss: 0.265696] [G loss: 1.258941]\n",
            "[Epoch 0/50] [Batch 75/600] [D loss: 0.252700] [G loss: 1.287375]\n",
            "[Epoch 0/50] [Batch 76/600] [D loss: 0.254964] [G loss: 1.711463]\n",
            "[Epoch 0/50] [Batch 77/600] [D loss: 0.249431] [G loss: 1.799925]\n",
            "[Epoch 0/50] [Batch 78/600] [D loss: 0.211170] [G loss: 2.046885]\n",
            "[Epoch 0/50] [Batch 79/600] [D loss: 0.237245] [G loss: 2.818970]\n",
            "[Epoch 0/50] [Batch 80/600] [D loss: 0.698249] [G loss: 1.281812]\n",
            "[Epoch 0/50] [Batch 81/600] [D loss: 1.376221] [G loss: 4.181411]\n",
            "[Epoch 0/50] [Batch 82/600] [D loss: 0.574053] [G loss: 1.076849]\n",
            "[Epoch 0/50] [Batch 83/600] [D loss: 0.552818] [G loss: 0.726287]\n",
            "[Epoch 0/50] [Batch 84/600] [D loss: 0.435471] [G loss: 0.955564]\n",
            "[Epoch 0/50] [Batch 85/600] [D loss: 0.370371] [G loss: 1.332070]\n",
            "[Epoch 0/50] [Batch 86/600] [D loss: 0.313219] [G loss: 1.735547]\n",
            "[Epoch 0/50] [Batch 87/600] [D loss: 0.316624] [G loss: 1.681153]\n",
            "[Epoch 0/50] [Batch 88/600] [D loss: 0.273401] [G loss: 1.554970]\n",
            "[Epoch 0/50] [Batch 89/600] [D loss: 0.340019] [G loss: 1.450326]\n",
            "[Epoch 0/50] [Batch 90/600] [D loss: 0.345239] [G loss: 2.052841]\n",
            "[Epoch 0/50] [Batch 91/600] [D loss: 0.399089] [G loss: 1.884344]\n",
            "[Epoch 0/50] [Batch 92/600] [D loss: 0.409128] [G loss: 2.203858]\n",
            "[Epoch 0/50] [Batch 93/600] [D loss: 0.458351] [G loss: 1.694429]\n",
            "[Epoch 0/50] [Batch 94/600] [D loss: 0.605326] [G loss: 3.795091]\n",
            "[Epoch 0/50] [Batch 95/600] [D loss: 0.559387] [G loss: 1.078083]\n",
            "[Epoch 0/50] [Batch 96/600] [D loss: 0.547206] [G loss: 3.355225]\n",
            "[Epoch 0/50] [Batch 97/600] [D loss: 0.313915] [G loss: 2.441156]\n",
            "[Epoch 0/50] [Batch 98/600] [D loss: 0.360425] [G loss: 1.322812]\n",
            "[Epoch 0/50] [Batch 99/600] [D loss: 0.330420] [G loss: 1.255821]\n",
            "[Epoch 0/50] [Batch 100/600] [D loss: 0.291474] [G loss: 1.645410]\n",
            "[Epoch 0/50] [Batch 101/600] [D loss: 0.395984] [G loss: 1.594988]\n",
            "[Epoch 0/50] [Batch 102/600] [D loss: 0.394809] [G loss: 1.313589]\n",
            "[Epoch 0/50] [Batch 103/600] [D loss: 0.547639] [G loss: 3.234841]\n",
            "[Epoch 0/50] [Batch 104/600] [D loss: 0.290528] [G loss: 1.744732]\n",
            "[Epoch 0/50] [Batch 105/600] [D loss: 0.335352] [G loss: 1.877817]\n",
            "[Epoch 0/50] [Batch 106/600] [D loss: 0.343865] [G loss: 3.334645]\n",
            "[Epoch 0/50] [Batch 107/600] [D loss: 0.216950] [G loss: 2.361063]\n",
            "[Epoch 0/50] [Batch 108/600] [D loss: 0.603264] [G loss: 1.124022]\n",
            "[Epoch 0/50] [Batch 109/600] [D loss: 0.526312] [G loss: 2.454453]\n",
            "[Epoch 0/50] [Batch 110/600] [D loss: 0.527019] [G loss: 1.632640]\n",
            "[Epoch 0/50] [Batch 111/600] [D loss: 0.489032] [G loss: 0.950755]\n",
            "[Epoch 0/50] [Batch 112/600] [D loss: 0.446142] [G loss: 1.123834]\n",
            "[Epoch 0/50] [Batch 113/600] [D loss: 0.394436] [G loss: 1.549443]\n",
            "[Epoch 0/50] [Batch 114/600] [D loss: 0.438095] [G loss: 1.315733]\n",
            "[Epoch 0/50] [Batch 115/600] [D loss: 0.525346] [G loss: 1.094242]\n",
            "[Epoch 0/50] [Batch 116/600] [D loss: 0.457756] [G loss: 1.395785]\n",
            "[Epoch 0/50] [Batch 117/600] [D loss: 0.312729] [G loss: 1.788573]\n",
            "[Epoch 0/50] [Batch 118/600] [D loss: 0.337233] [G loss: 1.565800]\n",
            "[Epoch 0/50] [Batch 119/600] [D loss: 0.452250] [G loss: 1.185901]\n",
            "[Epoch 0/50] [Batch 120/600] [D loss: 0.444373] [G loss: 2.232159]\n",
            "[Epoch 0/50] [Batch 121/600] [D loss: 0.506798] [G loss: 1.331701]\n",
            "[Epoch 0/50] [Batch 122/600] [D loss: 0.333054] [G loss: 2.673847]\n",
            "[Epoch 0/50] [Batch 123/600] [D loss: 0.452418] [G loss: 1.435437]\n",
            "[Epoch 0/50] [Batch 124/600] [D loss: 0.430970] [G loss: 2.787215]\n",
            "[Epoch 0/50] [Batch 125/600] [D loss: 0.456429] [G loss: 1.253794]\n",
            "[Epoch 0/50] [Batch 126/600] [D loss: 0.411708] [G loss: 2.450882]\n",
            "[Epoch 0/50] [Batch 127/600] [D loss: 0.482148] [G loss: 1.769133]\n",
            "[Epoch 0/50] [Batch 128/600] [D loss: 0.373689] [G loss: 1.945577]\n",
            "[Epoch 0/50] [Batch 129/600] [D loss: 0.205953] [G loss: 1.911586]\n",
            "[Epoch 0/50] [Batch 130/600] [D loss: 0.176641] [G loss: 2.249120]\n",
            "[Epoch 0/50] [Batch 131/600] [D loss: 0.336486] [G loss: 3.361407]\n",
            "[Epoch 0/50] [Batch 132/600] [D loss: 1.510253] [G loss: 0.595189]\n",
            "[Epoch 0/50] [Batch 133/600] [D loss: 1.426061] [G loss: 7.713640]\n",
            "[Epoch 0/50] [Batch 134/600] [D loss: 0.696403] [G loss: 2.299168]\n",
            "[Epoch 0/50] [Batch 135/600] [D loss: 0.682688] [G loss: 0.607771]\n",
            "[Epoch 0/50] [Batch 136/600] [D loss: 0.656172] [G loss: 0.688754]\n",
            "[Epoch 0/50] [Batch 137/600] [D loss: 0.637457] [G loss: 0.787584]\n",
            "[Epoch 0/50] [Batch 138/600] [D loss: 0.600313] [G loss: 0.911801]\n",
            "[Epoch 0/50] [Batch 139/600] [D loss: 0.591588] [G loss: 0.991052]\n",
            "[Epoch 0/50] [Batch 140/600] [D loss: 0.571877] [G loss: 1.039812]\n",
            "[Epoch 0/50] [Batch 141/600] [D loss: 0.529726] [G loss: 1.149204]\n",
            "[Epoch 0/50] [Batch 142/600] [D loss: 0.532199] [G loss: 1.134893]\n",
            "[Epoch 0/50] [Batch 143/600] [D loss: 0.475159] [G loss: 1.113160]\n",
            "[Epoch 0/50] [Batch 144/600] [D loss: 0.472991] [G loss: 1.172415]\n",
            "[Epoch 0/50] [Batch 145/600] [D loss: 0.516954] [G loss: 1.088561]\n",
            "[Epoch 0/50] [Batch 146/600] [D loss: 0.563612] [G loss: 1.039156]\n",
            "[Epoch 0/50] [Batch 147/600] [D loss: 0.563207] [G loss: 0.982357]\n",
            "[Epoch 0/50] [Batch 148/600] [D loss: 0.561666] [G loss: 0.919027]\n",
            "[Epoch 0/50] [Batch 149/600] [D loss: 0.509292] [G loss: 1.248222]\n",
            "[Epoch 0/50] [Batch 150/600] [D loss: 0.640285] [G loss: 0.797818]\n",
            "[Epoch 0/50] [Batch 151/600] [D loss: 0.997998] [G loss: 2.457571]\n",
            "[Epoch 0/50] [Batch 152/600] [D loss: 0.588759] [G loss: 0.993552]\n",
            "[Epoch 0/50] [Batch 153/600] [D loss: 0.663590] [G loss: 0.668633]\n",
            "[Epoch 0/50] [Batch 154/600] [D loss: 0.677870] [G loss: 0.524395]\n",
            "[Epoch 0/50] [Batch 155/600] [D loss: 0.596392] [G loss: 0.584305]\n",
            "[Epoch 0/50] [Batch 156/600] [D loss: 0.526731] [G loss: 0.742170]\n",
            "[Epoch 0/50] [Batch 157/600] [D loss: 0.464253] [G loss: 0.914067]\n",
            "[Epoch 0/50] [Batch 158/600] [D loss: 0.376857] [G loss: 0.957244]\n",
            "[Epoch 0/50] [Batch 159/600] [D loss: 0.347039] [G loss: 1.173394]\n",
            "[Epoch 0/50] [Batch 160/600] [D loss: 0.343173] [G loss: 1.750841]\n",
            "[Epoch 0/50] [Batch 161/600] [D loss: 0.386619] [G loss: 1.177014]\n",
            "[Epoch 0/50] [Batch 162/600] [D loss: 0.444013] [G loss: 2.098316]\n",
            "[Epoch 0/50] [Batch 163/600] [D loss: 0.594299] [G loss: 0.874475]\n",
            "[Epoch 0/50] [Batch 164/600] [D loss: 0.571919] [G loss: 1.833613]\n",
            "[Epoch 0/50] [Batch 165/600] [D loss: 0.522839] [G loss: 1.199825]\n",
            "[Epoch 0/50] [Batch 166/600] [D loss: 0.702238] [G loss: 0.633673]\n",
            "[Epoch 0/50] [Batch 167/600] [D loss: 0.669054] [G loss: 0.736079]\n",
            "[Epoch 0/50] [Batch 168/600] [D loss: 0.576608] [G loss: 0.855027]\n",
            "[Epoch 0/50] [Batch 169/600] [D loss: 0.575418] [G loss: 0.887330]\n",
            "[Epoch 0/50] [Batch 170/600] [D loss: 0.543743] [G loss: 0.943744]\n",
            "[Epoch 0/50] [Batch 171/600] [D loss: 0.483429] [G loss: 1.112041]\n",
            "[Epoch 0/50] [Batch 172/600] [D loss: 0.409137] [G loss: 1.182644]\n",
            "[Epoch 0/50] [Batch 173/600] [D loss: 0.357900] [G loss: 1.238475]\n",
            "[Epoch 0/50] [Batch 174/600] [D loss: 0.491315] [G loss: 2.153698]\n",
            "[Epoch 0/50] [Batch 175/600] [D loss: 0.614204] [G loss: 0.910204]\n",
            "[Epoch 0/50] [Batch 176/600] [D loss: 0.779227] [G loss: 2.362734]\n",
            "[Epoch 0/50] [Batch 177/600] [D loss: 0.640083] [G loss: 1.390592]\n",
            "[Epoch 0/50] [Batch 178/600] [D loss: 0.627738] [G loss: 0.770882]\n",
            "[Epoch 0/50] [Batch 179/600] [D loss: 0.543711] [G loss: 0.757120]\n",
            "[Epoch 0/50] [Batch 180/600] [D loss: 0.555288] [G loss: 0.962551]\n",
            "[Epoch 0/50] [Batch 181/600] [D loss: 0.465531] [G loss: 1.171051]\n",
            "[Epoch 0/50] [Batch 182/600] [D loss: 0.418437] [G loss: 1.299527]\n",
            "[Epoch 0/50] [Batch 183/600] [D loss: 0.387510] [G loss: 1.485745]\n",
            "[Epoch 0/50] [Batch 184/600] [D loss: 0.443585] [G loss: 1.479940]\n",
            "[Epoch 0/50] [Batch 185/600] [D loss: 0.567424] [G loss: 1.579135]\n",
            "[Epoch 0/50] [Batch 186/600] [D loss: 0.671294] [G loss: 1.022458]\n",
            "[Epoch 0/50] [Batch 187/600] [D loss: 0.768552] [G loss: 1.800333]\n",
            "[Epoch 0/50] [Batch 188/600] [D loss: 0.871004] [G loss: 0.812376]\n",
            "[Epoch 0/50] [Batch 189/600] [D loss: 0.642434] [G loss: 1.064520]\n",
            "[Epoch 0/50] [Batch 190/600] [D loss: 0.606993] [G loss: 1.047322]\n",
            "[Epoch 0/50] [Batch 191/600] [D loss: 0.564454] [G loss: 1.013793]\n",
            "[Epoch 0/50] [Batch 192/600] [D loss: 0.552393] [G loss: 1.025108]\n",
            "[Epoch 0/50] [Batch 193/600] [D loss: 0.505838] [G loss: 1.102415]\n",
            "[Epoch 0/50] [Batch 194/600] [D loss: 0.470858] [G loss: 1.115845]\n",
            "[Epoch 0/50] [Batch 195/600] [D loss: 0.466647] [G loss: 1.148046]\n",
            "[Epoch 0/50] [Batch 196/600] [D loss: 0.438260] [G loss: 1.482086]\n",
            "[Epoch 0/50] [Batch 197/600] [D loss: 0.418554] [G loss: 1.236403]\n",
            "[Epoch 0/50] [Batch 198/600] [D loss: 0.472213] [G loss: 1.605484]\n",
            "[Epoch 0/50] [Batch 199/600] [D loss: 0.697744] [G loss: 0.810614]\n",
            "[Epoch 0/50] [Batch 200/600] [D loss: 0.869997] [G loss: 3.043726]\n",
            "[Epoch 0/50] [Batch 201/600] [D loss: 0.619078] [G loss: 1.435665]\n",
            "[Epoch 0/50] [Batch 202/600] [D loss: 0.655582] [G loss: 0.705202]\n",
            "[Epoch 0/50] [Batch 203/600] [D loss: 0.679482] [G loss: 0.633619]\n",
            "[Epoch 0/50] [Batch 204/600] [D loss: 0.648990] [G loss: 0.643327]\n",
            "[Epoch 0/50] [Batch 205/600] [D loss: 0.585584] [G loss: 0.797796]\n",
            "[Epoch 0/50] [Batch 206/600] [D loss: 0.552545] [G loss: 0.932931]\n",
            "[Epoch 0/50] [Batch 207/600] [D loss: 0.559965] [G loss: 1.032328]\n",
            "[Epoch 0/50] [Batch 208/600] [D loss: 0.582595] [G loss: 0.973080]\n",
            "[Epoch 0/50] [Batch 209/600] [D loss: 0.539526] [G loss: 1.043216]\n",
            "[Epoch 0/50] [Batch 210/600] [D loss: 0.529596] [G loss: 1.011456]\n",
            "[Epoch 0/50] [Batch 211/600] [D loss: 0.520631] [G loss: 1.092569]\n",
            "[Epoch 0/50] [Batch 212/600] [D loss: 0.493942] [G loss: 1.025939]\n",
            "[Epoch 0/50] [Batch 213/600] [D loss: 0.539832] [G loss: 1.108436]\n",
            "[Epoch 0/50] [Batch 214/600] [D loss: 0.507035] [G loss: 1.090900]\n",
            "[Epoch 0/50] [Batch 215/600] [D loss: 0.588656] [G loss: 0.923479]\n",
            "[Epoch 0/50] [Batch 216/600] [D loss: 0.622989] [G loss: 1.139742]\n",
            "[Epoch 0/50] [Batch 217/600] [D loss: 0.677444] [G loss: 1.105718]\n",
            "[Epoch 0/50] [Batch 218/600] [D loss: 0.568736] [G loss: 0.988678]\n",
            "[Epoch 0/50] [Batch 219/600] [D loss: 0.584623] [G loss: 1.023648]\n",
            "[Epoch 0/50] [Batch 220/600] [D loss: 0.563840] [G loss: 1.263424]\n",
            "[Epoch 0/50] [Batch 221/600] [D loss: 0.548160] [G loss: 1.256430]\n",
            "[Epoch 0/50] [Batch 222/600] [D loss: 0.554661] [G loss: 1.111629]\n",
            "[Epoch 0/50] [Batch 223/600] [D loss: 0.641840] [G loss: 0.947444]\n",
            "[Epoch 0/50] [Batch 224/600] [D loss: 0.646156] [G loss: 1.284750]\n",
            "[Epoch 0/50] [Batch 225/600] [D loss: 0.635958] [G loss: 1.008300]\n",
            "[Epoch 0/50] [Batch 226/600] [D loss: 0.572969] [G loss: 0.809382]\n",
            "[Epoch 0/50] [Batch 227/600] [D loss: 0.549598] [G loss: 1.062909]\n",
            "[Epoch 0/50] [Batch 228/600] [D loss: 0.510781] [G loss: 1.123567]\n",
            "[Epoch 0/50] [Batch 229/600] [D loss: 0.465174] [G loss: 1.125130]\n",
            "[Epoch 0/50] [Batch 230/600] [D loss: 0.392762] [G loss: 1.402567]\n",
            "[Epoch 0/50] [Batch 231/600] [D loss: 0.399949] [G loss: 1.674640]\n",
            "[Epoch 0/50] [Batch 232/600] [D loss: 0.482094] [G loss: 1.322262]\n",
            "[Epoch 0/50] [Batch 233/600] [D loss: 0.644702] [G loss: 2.356287]\n",
            "[Epoch 0/50] [Batch 234/600] [D loss: 0.922083] [G loss: 0.746319]\n",
            "[Epoch 0/50] [Batch 235/600] [D loss: 0.697867] [G loss: 2.232599]\n",
            "[Epoch 0/50] [Batch 236/600] [D loss: 0.623688] [G loss: 1.417053]\n",
            "[Epoch 0/50] [Batch 237/600] [D loss: 0.611204] [G loss: 0.804670]\n",
            "[Epoch 0/50] [Batch 238/600] [D loss: 0.611114] [G loss: 0.928493]\n",
            "[Epoch 0/50] [Batch 239/600] [D loss: 0.589205] [G loss: 1.035358]\n",
            "[Epoch 0/50] [Batch 240/600] [D loss: 0.572781] [G loss: 1.042092]\n",
            "[Epoch 0/50] [Batch 241/600] [D loss: 0.578418] [G loss: 1.021615]\n",
            "[Epoch 0/50] [Batch 242/600] [D loss: 0.588866] [G loss: 1.062483]\n",
            "[Epoch 0/50] [Batch 243/600] [D loss: 0.539480] [G loss: 1.021761]\n",
            "[Epoch 0/50] [Batch 244/600] [D loss: 0.493032] [G loss: 1.079980]\n",
            "[Epoch 0/50] [Batch 245/600] [D loss: 0.508934] [G loss: 1.120560]\n",
            "[Epoch 0/50] [Batch 246/600] [D loss: 0.450519] [G loss: 1.126037]\n",
            "[Epoch 0/50] [Batch 247/600] [D loss: 0.477726] [G loss: 1.357072]\n",
            "[Epoch 0/50] [Batch 248/600] [D loss: 0.343192] [G loss: 1.594594]\n",
            "[Epoch 0/50] [Batch 249/600] [D loss: 0.445225] [G loss: 1.384030]\n",
            "[Epoch 0/50] [Batch 250/600] [D loss: 0.425268] [G loss: 1.942245]\n",
            "[Epoch 0/50] [Batch 251/600] [D loss: 1.544540] [G loss: 0.172132]\n",
            "[Epoch 0/50] [Batch 252/600] [D loss: 1.528947] [G loss: 4.315959]\n",
            "[Epoch 0/50] [Batch 253/600] [D loss: 0.680473] [G loss: 0.993058]\n",
            "[Epoch 0/50] [Batch 254/600] [D loss: 0.619374] [G loss: 0.662091]\n",
            "[Epoch 0/50] [Batch 255/600] [D loss: 0.648529] [G loss: 0.588754]\n",
            "[Epoch 0/50] [Batch 256/600] [D loss: 0.610693] [G loss: 0.661134]\n",
            "[Epoch 0/50] [Batch 257/600] [D loss: 0.585355] [G loss: 0.740217]\n",
            "[Epoch 0/50] [Batch 258/600] [D loss: 0.571441] [G loss: 0.839506]\n",
            "[Epoch 0/50] [Batch 259/600] [D loss: 0.499092] [G loss: 0.983273]\n",
            "[Epoch 0/50] [Batch 260/600] [D loss: 0.447595] [G loss: 1.066910]\n",
            "[Epoch 0/50] [Batch 261/600] [D loss: 0.402037] [G loss: 1.205000]\n",
            "[Epoch 0/50] [Batch 262/600] [D loss: 0.436533] [G loss: 1.221603]\n",
            "[Epoch 0/50] [Batch 263/600] [D loss: 0.435889] [G loss: 1.164034]\n",
            "[Epoch 0/50] [Batch 264/600] [D loss: 0.491778] [G loss: 1.289353]\n",
            "[Epoch 0/50] [Batch 265/600] [D loss: 0.510030] [G loss: 1.397973]\n",
            "[Epoch 0/50] [Batch 266/600] [D loss: 0.670057] [G loss: 1.063491]\n",
            "[Epoch 0/50] [Batch 267/600] [D loss: 0.538827] [G loss: 1.222970]\n",
            "[Epoch 0/50] [Batch 268/600] [D loss: 0.461324] [G loss: 1.325931]\n",
            "[Epoch 0/50] [Batch 269/600] [D loss: 0.584389] [G loss: 1.109853]\n",
            "[Epoch 0/50] [Batch 270/600] [D loss: 0.500798] [G loss: 1.275779]\n",
            "[Epoch 0/50] [Batch 271/600] [D loss: 0.398360] [G loss: 1.348408]\n",
            "[Epoch 0/50] [Batch 272/600] [D loss: 0.394568] [G loss: 1.651105]\n",
            "[Epoch 0/50] [Batch 273/600] [D loss: 0.306076] [G loss: 1.803902]\n",
            "[Epoch 0/50] [Batch 274/600] [D loss: 0.415895] [G loss: 1.562888]\n",
            "[Epoch 0/50] [Batch 275/600] [D loss: 0.582593] [G loss: 1.782804]\n",
            "[Epoch 0/50] [Batch 276/600] [D loss: 0.719571] [G loss: 0.981981]\n",
            "[Epoch 0/50] [Batch 277/600] [D loss: 0.633950] [G loss: 1.346815]\n",
            "[Epoch 0/50] [Batch 278/600] [D loss: 0.565754] [G loss: 1.207173]\n",
            "[Epoch 0/50] [Batch 279/600] [D loss: 0.525172] [G loss: 1.030675]\n",
            "[Epoch 0/50] [Batch 280/600] [D loss: 0.415676] [G loss: 1.242592]\n",
            "[Epoch 0/50] [Batch 281/600] [D loss: 0.348129] [G loss: 1.734236]\n",
            "[Epoch 0/50] [Batch 282/600] [D loss: 0.288089] [G loss: 1.607725]\n",
            "[Epoch 0/50] [Batch 283/600] [D loss: 0.446262] [G loss: 1.247713]\n",
            "[Epoch 0/50] [Batch 284/600] [D loss: 0.681205] [G loss: 2.946477]\n",
            "[Epoch 0/50] [Batch 285/600] [D loss: 0.809764] [G loss: 0.563181]\n",
            "[Epoch 0/50] [Batch 286/600] [D loss: 0.392761] [G loss: 1.290590]\n",
            "[Epoch 0/50] [Batch 287/600] [D loss: 0.445542] [G loss: 1.537406]\n",
            "[Epoch 0/50] [Batch 288/600] [D loss: 0.361621] [G loss: 1.599557]\n",
            "[Epoch 0/50] [Batch 289/600] [D loss: 0.320791] [G loss: 1.651186]\n",
            "[Epoch 0/50] [Batch 290/600] [D loss: 0.294216] [G loss: 1.495579]\n",
            "[Epoch 0/50] [Batch 291/600] [D loss: 0.363155] [G loss: 1.399053]\n",
            "[Epoch 0/50] [Batch 292/600] [D loss: 0.278613] [G loss: 2.130068]\n",
            "[Epoch 0/50] [Batch 293/600] [D loss: 0.392249] [G loss: 1.915511]\n",
            "[Epoch 0/50] [Batch 294/600] [D loss: 0.436029] [G loss: 1.391375]\n",
            "[Epoch 0/50] [Batch 295/600] [D loss: 0.475565] [G loss: 2.528538]\n",
            "[Epoch 0/50] [Batch 296/600] [D loss: 0.456467] [G loss: 1.614344]\n",
            "[Epoch 0/50] [Batch 297/600] [D loss: 0.439899] [G loss: 1.771456]\n",
            "[Epoch 0/50] [Batch 298/600] [D loss: 0.523125] [G loss: 1.364716]\n",
            "[Epoch 0/50] [Batch 299/600] [D loss: 0.521642] [G loss: 1.297450]\n",
            "[Epoch 0/50] [Batch 300/600] [D loss: 0.466740] [G loss: 1.697495]\n",
            "[Epoch 0/50] [Batch 301/600] [D loss: 0.407560] [G loss: 1.678609]\n",
            "[Epoch 0/50] [Batch 302/600] [D loss: 0.456434] [G loss: 1.558546]\n",
            "[Epoch 0/50] [Batch 303/600] [D loss: 0.465728] [G loss: 1.583210]\n",
            "[Epoch 0/50] [Batch 304/600] [D loss: 0.438945] [G loss: 2.220458]\n",
            "[Epoch 0/50] [Batch 305/600] [D loss: 0.451794] [G loss: 1.732631]\n",
            "[Epoch 0/50] [Batch 306/600] [D loss: 0.378052] [G loss: 1.788700]\n",
            "[Epoch 0/50] [Batch 307/600] [D loss: 0.361698] [G loss: 2.515380]\n",
            "[Epoch 0/50] [Batch 308/600] [D loss: 0.304322] [G loss: 2.199953]\n",
            "[Epoch 0/50] [Batch 309/600] [D loss: 0.242663] [G loss: 2.448239]\n",
            "[Epoch 0/50] [Batch 310/600] [D loss: 0.364208] [G loss: 1.991036]\n",
            "[Epoch 0/50] [Batch 311/600] [D loss: 0.200107] [G loss: 3.030690]\n",
            "[Epoch 0/50] [Batch 312/600] [D loss: 0.385597] [G loss: 2.872392]\n",
            "[Epoch 0/50] [Batch 313/600] [D loss: 0.561414] [G loss: 1.288652]\n",
            "[Epoch 0/50] [Batch 314/600] [D loss: 0.410814] [G loss: 2.953125]\n",
            "[Epoch 0/50] [Batch 315/600] [D loss: 0.390471] [G loss: 2.074937]\n",
            "[Epoch 0/50] [Batch 316/600] [D loss: 0.353519] [G loss: 1.239346]\n",
            "[Epoch 0/50] [Batch 317/600] [D loss: 0.308352] [G loss: 1.783614]\n",
            "[Epoch 0/50] [Batch 318/600] [D loss: 0.210637] [G loss: 2.150355]\n",
            "[Epoch 0/50] [Batch 319/600] [D loss: 0.237525] [G loss: 2.094500]\n",
            "[Epoch 0/50] [Batch 320/600] [D loss: 0.388784] [G loss: 1.572239]\n",
            "[Epoch 0/50] [Batch 321/600] [D loss: 0.493860] [G loss: 1.793050]\n",
            "[Epoch 0/50] [Batch 322/600] [D loss: 0.368213] [G loss: 2.263423]\n",
            "[Epoch 0/50] [Batch 323/600] [D loss: 0.384289] [G loss: 1.358404]\n",
            "[Epoch 0/50] [Batch 324/600] [D loss: 0.402718] [G loss: 2.219882]\n",
            "[Epoch 0/50] [Batch 325/600] [D loss: 0.333047] [G loss: 1.774253]\n",
            "[Epoch 0/50] [Batch 326/600] [D loss: 0.493980] [G loss: 1.625265]\n",
            "[Epoch 0/50] [Batch 327/600] [D loss: 0.422177] [G loss: 1.980737]\n",
            "[Epoch 0/50] [Batch 328/600] [D loss: 0.439266] [G loss: 1.575564]\n",
            "[Epoch 0/50] [Batch 329/600] [D loss: 0.395757] [G loss: 1.695001]\n",
            "[Epoch 0/50] [Batch 330/600] [D loss: 0.436976] [G loss: 2.230826]\n",
            "[Epoch 0/50] [Batch 331/600] [D loss: 0.428196] [G loss: 1.597029]\n",
            "[Epoch 0/50] [Batch 332/600] [D loss: 0.459661] [G loss: 1.345747]\n",
            "[Epoch 0/50] [Batch 333/600] [D loss: 0.354395] [G loss: 1.808588]\n",
            "[Epoch 0/50] [Batch 334/600] [D loss: 0.354393] [G loss: 2.172242]\n",
            "[Epoch 0/50] [Batch 335/600] [D loss: 0.437334] [G loss: 1.711661]\n",
            "[Epoch 0/50] [Batch 336/600] [D loss: 0.528059] [G loss: 1.520433]\n",
            "[Epoch 0/50] [Batch 337/600] [D loss: 0.387849] [G loss: 1.498516]\n",
            "[Epoch 0/50] [Batch 338/600] [D loss: 0.365364] [G loss: 1.790149]\n",
            "[Epoch 0/50] [Batch 339/600] [D loss: 0.349283] [G loss: 1.493626]\n",
            "[Epoch 0/50] [Batch 340/600] [D loss: 0.426016] [G loss: 1.613212]\n",
            "[Epoch 0/50] [Batch 341/600] [D loss: 0.462704] [G loss: 1.537587]\n",
            "[Epoch 0/50] [Batch 342/600] [D loss: 0.376027] [G loss: 1.843068]\n",
            "[Epoch 0/50] [Batch 343/600] [D loss: 0.288594] [G loss: 1.951865]\n",
            "[Epoch 0/50] [Batch 344/600] [D loss: 0.459779] [G loss: 1.359530]\n",
            "[Epoch 0/50] [Batch 345/600] [D loss: 0.318438] [G loss: 2.442303]\n",
            "[Epoch 0/50] [Batch 346/600] [D loss: 0.314888] [G loss: 2.851724]\n",
            "[Epoch 0/50] [Batch 347/600] [D loss: 0.301824] [G loss: 2.073335]\n",
            "[Epoch 0/50] [Batch 348/600] [D loss: 0.281998] [G loss: 2.745434]\n",
            "[Epoch 0/50] [Batch 349/600] [D loss: 0.278417] [G loss: 2.432823]\n",
            "[Epoch 0/50] [Batch 350/600] [D loss: 0.191875] [G loss: 2.903480]\n",
            "[Epoch 0/50] [Batch 351/600] [D loss: 0.269078] [G loss: 2.555356]\n",
            "[Epoch 0/50] [Batch 352/600] [D loss: 0.333506] [G loss: 2.973973]\n",
            "[Epoch 0/50] [Batch 353/600] [D loss: 0.378664] [G loss: 2.106391]\n",
            "[Epoch 0/50] [Batch 354/600] [D loss: 0.224469] [G loss: 3.050333]\n",
            "[Epoch 0/50] [Batch 355/600] [D loss: 0.282365] [G loss: 2.437872]\n",
            "[Epoch 0/50] [Batch 356/600] [D loss: 0.328595] [G loss: 2.825455]\n",
            "[Epoch 0/50] [Batch 357/600] [D loss: 0.392690] [G loss: 3.690440]\n",
            "[Epoch 0/50] [Batch 358/600] [D loss: 0.671243] [G loss: 1.243428]\n",
            "[Epoch 0/50] [Batch 359/600] [D loss: 0.398121] [G loss: 4.647333]\n",
            "[Epoch 0/50] [Batch 360/600] [D loss: 0.366812] [G loss: 3.291369]\n",
            "[Epoch 0/50] [Batch 361/600] [D loss: 0.461444] [G loss: 1.543526]\n",
            "[Epoch 0/50] [Batch 362/600] [D loss: 0.281436] [G loss: 1.823162]\n",
            "[Epoch 0/50] [Batch 363/600] [D loss: 0.242866] [G loss: 2.789772]\n",
            "[Epoch 0/50] [Batch 364/600] [D loss: 0.242642] [G loss: 2.579739]\n",
            "[Epoch 0/50] [Batch 365/600] [D loss: 0.247374] [G loss: 2.354471]\n",
            "[Epoch 0/50] [Batch 366/600] [D loss: 0.224210] [G loss: 3.465981]\n",
            "[Epoch 0/50] [Batch 367/600] [D loss: 0.259416] [G loss: 3.075961]\n",
            "[Epoch 0/50] [Batch 368/600] [D loss: 0.309378] [G loss: 2.652968]\n",
            "[Epoch 0/50] [Batch 369/600] [D loss: 0.270889] [G loss: 2.820445]\n",
            "[Epoch 0/50] [Batch 370/600] [D loss: 0.531902] [G loss: 1.328206]\n",
            "[Epoch 0/50] [Batch 371/600] [D loss: 0.785560] [G loss: 6.237418]\n",
            "[Epoch 0/50] [Batch 372/600] [D loss: 0.274135] [G loss: 1.874730]\n",
            "[Epoch 0/50] [Batch 373/600] [D loss: 0.489685] [G loss: 0.958147]\n",
            "[Epoch 0/50] [Batch 374/600] [D loss: 0.244782] [G loss: 2.486267]\n",
            "[Epoch 0/50] [Batch 375/600] [D loss: 0.248251] [G loss: 3.342463]\n",
            "[Epoch 0/50] [Batch 376/600] [D loss: 0.325742] [G loss: 2.675358]\n",
            "[Epoch 0/50] [Batch 377/600] [D loss: 0.295060] [G loss: 1.910657]\n",
            "[Epoch 0/50] [Batch 378/600] [D loss: 0.340660] [G loss: 1.893157]\n",
            "[Epoch 0/50] [Batch 379/600] [D loss: 0.366672] [G loss: 2.017763]\n",
            "[Epoch 0/50] [Batch 380/600] [D loss: 0.299044] [G loss: 2.218220]\n",
            "[Epoch 0/50] [Batch 381/600] [D loss: 0.270814] [G loss: 1.943682]\n",
            "[Epoch 0/50] [Batch 382/600] [D loss: 0.368734] [G loss: 1.636820]\n",
            "[Epoch 0/50] [Batch 383/600] [D loss: 0.333326] [G loss: 2.461271]\n",
            "[Epoch 0/50] [Batch 384/600] [D loss: 0.398807] [G loss: 2.603000]\n",
            "[Epoch 0/50] [Batch 385/600] [D loss: 0.347967] [G loss: 1.475223]\n",
            "[Epoch 0/50] [Batch 386/600] [D loss: 0.340534] [G loss: 2.823289]\n",
            "[Epoch 0/50] [Batch 387/600] [D loss: 0.293944] [G loss: 1.946841]\n",
            "[Epoch 0/50] [Batch 388/600] [D loss: 0.314580] [G loss: 2.003932]\n",
            "[Epoch 0/50] [Batch 389/600] [D loss: 0.288368] [G loss: 2.982481]\n",
            "[Epoch 0/50] [Batch 390/600] [D loss: 0.336180] [G loss: 1.943415]\n",
            "[Epoch 0/50] [Batch 391/600] [D loss: 0.221964] [G loss: 2.001079]\n",
            "[Epoch 0/50] [Batch 392/600] [D loss: 0.253041] [G loss: 2.646970]\n",
            "[Epoch 0/50] [Batch 393/600] [D loss: 0.291589] [G loss: 1.992143]\n",
            "[Epoch 0/50] [Batch 394/600] [D loss: 0.271682] [G loss: 2.514760]\n",
            "[Epoch 0/50] [Batch 395/600] [D loss: 0.223541] [G loss: 2.265042]\n",
            "[Epoch 0/50] [Batch 396/600] [D loss: 0.342058] [G loss: 2.427727]\n",
            "[Epoch 0/50] [Batch 397/600] [D loss: 0.333708] [G loss: 2.911047]\n",
            "[Epoch 0/50] [Batch 398/600] [D loss: 0.350340] [G loss: 1.851359]\n",
            "[Epoch 0/50] [Batch 399/600] [D loss: 0.343858] [G loss: 1.800936]\n",
            "[Epoch 0/50] [Batch 400/600] [D loss: 0.273204] [G loss: 2.405638]\n",
            "[Epoch 0/50] [Batch 401/600] [D loss: 0.414417] [G loss: 1.771524]\n",
            "[Epoch 0/50] [Batch 402/600] [D loss: 0.409431] [G loss: 2.080327]\n",
            "[Epoch 0/50] [Batch 403/600] [D loss: 0.371209] [G loss: 2.141196]\n",
            "[Epoch 0/50] [Batch 404/600] [D loss: 0.337665] [G loss: 1.433588]\n",
            "[Epoch 0/50] [Batch 405/600] [D loss: 0.367055] [G loss: 1.972646]\n",
            "[Epoch 0/50] [Batch 406/600] [D loss: 0.359091] [G loss: 2.073442]\n",
            "[Epoch 0/50] [Batch 407/600] [D loss: 0.468259] [G loss: 1.778316]\n",
            "[Epoch 0/50] [Batch 408/600] [D loss: 0.475480] [G loss: 1.519902]\n",
            "[Epoch 0/50] [Batch 409/600] [D loss: 0.476286] [G loss: 1.880569]\n",
            "[Epoch 0/50] [Batch 410/600] [D loss: 0.469564] [G loss: 1.310304]\n",
            "[Epoch 0/50] [Batch 411/600] [D loss: 0.361022] [G loss: 1.372324]\n",
            "[Epoch 0/50] [Batch 412/600] [D loss: 0.388798] [G loss: 2.014668]\n",
            "[Epoch 0/50] [Batch 413/600] [D loss: 0.326729] [G loss: 2.427528]\n",
            "[Epoch 0/50] [Batch 414/600] [D loss: 0.475601] [G loss: 1.707307]\n",
            "[Epoch 0/50] [Batch 415/600] [D loss: 0.427045] [G loss: 1.932043]\n",
            "[Epoch 0/50] [Batch 416/600] [D loss: 0.433361] [G loss: 1.994274]\n",
            "[Epoch 0/50] [Batch 417/600] [D loss: 0.538778] [G loss: 1.539052]\n",
            "[Epoch 0/50] [Batch 418/600] [D loss: 0.526724] [G loss: 1.276630]\n",
            "[Epoch 0/50] [Batch 419/600] [D loss: 0.389023] [G loss: 1.795586]\n",
            "[Epoch 0/50] [Batch 420/600] [D loss: 0.329224] [G loss: 1.782411]\n",
            "[Epoch 0/50] [Batch 421/600] [D loss: 0.396078] [G loss: 1.745935]\n",
            "[Epoch 0/50] [Batch 422/600] [D loss: 0.331778] [G loss: 1.860465]\n",
            "[Epoch 0/50] [Batch 423/600] [D loss: 0.371466] [G loss: 1.965185]\n",
            "[Epoch 0/50] [Batch 424/600] [D loss: 0.518832] [G loss: 2.249306]\n",
            "[Epoch 0/50] [Batch 425/600] [D loss: 0.408877] [G loss: 1.371338]\n",
            "[Epoch 0/50] [Batch 426/600] [D loss: 0.302761] [G loss: 2.102226]\n",
            "[Epoch 0/50] [Batch 427/600] [D loss: 0.317904] [G loss: 1.690748]\n",
            "[Epoch 0/50] [Batch 428/600] [D loss: 0.407173] [G loss: 1.962922]\n",
            "[Epoch 0/50] [Batch 429/600] [D loss: 0.275884] [G loss: 2.199345]\n",
            "[Epoch 0/50] [Batch 430/600] [D loss: 0.392207] [G loss: 2.195986]\n",
            "[Epoch 0/50] [Batch 431/600] [D loss: 0.558911] [G loss: 0.786931]\n",
            "[Epoch 0/50] [Batch 432/600] [D loss: 0.401073] [G loss: 3.306608]\n",
            "[Epoch 0/50] [Batch 433/600] [D loss: 0.354740] [G loss: 2.057094]\n",
            "[Epoch 0/50] [Batch 434/600] [D loss: 0.367019] [G loss: 1.458495]\n",
            "[Epoch 0/50] [Batch 435/600] [D loss: 0.390437] [G loss: 1.306692]\n",
            "[Epoch 0/50] [Batch 436/600] [D loss: 0.371248] [G loss: 1.739096]\n",
            "[Epoch 0/50] [Batch 437/600] [D loss: 0.446797] [G loss: 1.957075]\n",
            "[Epoch 0/50] [Batch 438/600] [D loss: 0.335379] [G loss: 1.795292]\n",
            "[Epoch 0/50] [Batch 439/600] [D loss: 0.351254] [G loss: 1.676291]\n",
            "[Epoch 0/50] [Batch 440/600] [D loss: 0.367682] [G loss: 1.624100]\n",
            "[Epoch 0/50] [Batch 441/600] [D loss: 0.338529] [G loss: 1.987948]\n",
            "[Epoch 0/50] [Batch 442/600] [D loss: 0.331068] [G loss: 1.802893]\n",
            "[Epoch 0/50] [Batch 443/600] [D loss: 0.285895] [G loss: 2.169273]\n",
            "[Epoch 0/50] [Batch 444/600] [D loss: 0.338953] [G loss: 2.055017]\n",
            "[Epoch 0/50] [Batch 445/600] [D loss: 0.431773] [G loss: 1.956054]\n",
            "[Epoch 0/50] [Batch 446/600] [D loss: 0.365302] [G loss: 1.514399]\n",
            "[Epoch 0/50] [Batch 447/600] [D loss: 0.269792] [G loss: 2.878171]\n",
            "[Epoch 0/50] [Batch 448/600] [D loss: 0.329933] [G loss: 2.050066]\n",
            "[Epoch 0/50] [Batch 449/600] [D loss: 0.427921] [G loss: 1.615416]\n",
            "[Epoch 0/50] [Batch 450/600] [D loss: 0.425965] [G loss: 2.260015]\n",
            "[Epoch 0/50] [Batch 451/600] [D loss: 0.340083] [G loss: 2.160906]\n",
            "[Epoch 0/50] [Batch 452/600] [D loss: 0.393376] [G loss: 1.631080]\n",
            "[Epoch 0/50] [Batch 453/600] [D loss: 0.424304] [G loss: 1.590637]\n",
            "[Epoch 0/50] [Batch 454/600] [D loss: 0.419283] [G loss: 1.770944]\n",
            "[Epoch 0/50] [Batch 455/600] [D loss: 0.451516] [G loss: 1.584842]\n",
            "[Epoch 0/50] [Batch 456/600] [D loss: 0.388134] [G loss: 1.810885]\n",
            "[Epoch 0/50] [Batch 457/600] [D loss: 0.401971] [G loss: 1.719149]\n",
            "[Epoch 0/50] [Batch 458/600] [D loss: 0.435874] [G loss: 1.513090]\n",
            "[Epoch 0/50] [Batch 459/600] [D loss: 0.429356] [G loss: 1.759585]\n",
            "[Epoch 0/50] [Batch 460/600] [D loss: 0.438472] [G loss: 1.683593]\n",
            "[Epoch 0/50] [Batch 461/600] [D loss: 0.368098] [G loss: 1.605858]\n",
            "[Epoch 0/50] [Batch 462/600] [D loss: 0.420540] [G loss: 1.532086]\n",
            "[Epoch 0/50] [Batch 463/600] [D loss: 0.398412] [G loss: 1.684159]\n",
            "[Epoch 0/50] [Batch 464/600] [D loss: 0.441892] [G loss: 1.446426]\n",
            "[Epoch 0/50] [Batch 465/600] [D loss: 0.407819] [G loss: 1.911291]\n",
            "[Epoch 0/50] [Batch 466/600] [D loss: 0.399784] [G loss: 1.434858]\n",
            "[Epoch 0/50] [Batch 467/600] [D loss: 0.460841] [G loss: 1.355014]\n",
            "[Epoch 0/50] [Batch 468/600] [D loss: 0.443794] [G loss: 1.829627]\n",
            "[Epoch 0/50] [Batch 469/600] [D loss: 0.410374] [G loss: 1.806216]\n",
            "[Epoch 0/50] [Batch 470/600] [D loss: 0.474175] [G loss: 1.520734]\n",
            "[Epoch 0/50] [Batch 471/600] [D loss: 0.436212] [G loss: 1.421154]\n",
            "[Epoch 0/50] [Batch 472/600] [D loss: 0.549257] [G loss: 1.797650]\n",
            "[Epoch 0/50] [Batch 473/600] [D loss: 0.400572] [G loss: 1.611773]\n",
            "[Epoch 0/50] [Batch 474/600] [D loss: 0.293357] [G loss: 1.905626]\n",
            "[Epoch 0/50] [Batch 475/600] [D loss: 0.320751] [G loss: 1.807901]\n",
            "[Epoch 0/50] [Batch 476/600] [D loss: 0.236648] [G loss: 2.217935]\n",
            "[Epoch 0/50] [Batch 477/600] [D loss: 0.305620] [G loss: 2.382980]\n",
            "[Epoch 0/50] [Batch 478/600] [D loss: 0.473445] [G loss: 2.078556]\n",
            "[Epoch 0/50] [Batch 479/600] [D loss: 0.430074] [G loss: 1.668658]\n",
            "[Epoch 0/50] [Batch 480/600] [D loss: 0.347257] [G loss: 2.392131]\n",
            "[Epoch 0/50] [Batch 481/600] [D loss: 0.302267] [G loss: 2.000274]\n",
            "[Epoch 0/50] [Batch 482/600] [D loss: 0.267206] [G loss: 1.386172]\n",
            "[Epoch 0/50] [Batch 483/600] [D loss: 0.505315] [G loss: 1.427351]\n",
            "[Epoch 0/50] [Batch 484/600] [D loss: 0.465236] [G loss: 2.536175]\n",
            "[Epoch 0/50] [Batch 485/600] [D loss: 0.377616] [G loss: 1.655129]\n",
            "[Epoch 0/50] [Batch 486/600] [D loss: 0.381204] [G loss: 1.746656]\n",
            "[Epoch 0/50] [Batch 487/600] [D loss: 0.355402] [G loss: 2.305389]\n",
            "[Epoch 0/50] [Batch 488/600] [D loss: 0.360072] [G loss: 1.846893]\n",
            "[Epoch 0/50] [Batch 489/600] [D loss: 0.446226] [G loss: 1.867507]\n",
            "[Epoch 0/50] [Batch 490/600] [D loss: 0.372109] [G loss: 1.766871]\n",
            "[Epoch 0/50] [Batch 491/600] [D loss: 0.341783] [G loss: 1.954484]\n",
            "[Epoch 0/50] [Batch 492/600] [D loss: 0.325670] [G loss: 2.052976]\n",
            "[Epoch 0/50] [Batch 493/600] [D loss: 0.365635] [G loss: 2.010591]\n",
            "[Epoch 0/50] [Batch 494/600] [D loss: 0.326682] [G loss: 2.267420]\n",
            "[Epoch 0/50] [Batch 495/600] [D loss: 0.361175] [G loss: 1.740270]\n",
            "[Epoch 0/50] [Batch 496/600] [D loss: 0.502260] [G loss: 3.357007]\n",
            "[Epoch 0/50] [Batch 497/600] [D loss: 0.537190] [G loss: 1.203149]\n",
            "[Epoch 0/50] [Batch 498/600] [D loss: 0.415108] [G loss: 2.062971]\n",
            "[Epoch 0/50] [Batch 499/600] [D loss: 0.375287] [G loss: 1.974560]\n",
            "[Epoch 0/50] [Batch 500/600] [D loss: 0.372072] [G loss: 1.404452]\n",
            "[Epoch 0/50] [Batch 501/600] [D loss: 0.253632] [G loss: 1.639672]\n",
            "[Epoch 0/50] [Batch 502/600] [D loss: 0.264970] [G loss: 2.537180]\n",
            "[Epoch 0/50] [Batch 503/600] [D loss: 0.227028] [G loss: 2.495182]\n",
            "[Epoch 0/50] [Batch 504/600] [D loss: 0.386340] [G loss: 1.424113]\n",
            "[Epoch 0/50] [Batch 505/600] [D loss: 0.455685] [G loss: 2.947443]\n",
            "[Epoch 0/50] [Batch 506/600] [D loss: 0.480609] [G loss: 1.524386]\n",
            "[Epoch 0/50] [Batch 507/600] [D loss: 0.580731] [G loss: 1.093281]\n",
            "[Epoch 0/50] [Batch 508/600] [D loss: 0.469999] [G loss: 1.884937]\n",
            "[Epoch 0/50] [Batch 509/600] [D loss: 0.401058] [G loss: 1.390281]\n",
            "[Epoch 0/50] [Batch 510/600] [D loss: 0.289967] [G loss: 2.042736]\n",
            "[Epoch 0/50] [Batch 511/600] [D loss: 0.292250] [G loss: 2.192879]\n",
            "[Epoch 0/50] [Batch 512/600] [D loss: 0.257789] [G loss: 2.161301]\n",
            "[Epoch 0/50] [Batch 513/600] [D loss: 0.318476] [G loss: 2.369877]\n",
            "[Epoch 0/50] [Batch 514/600] [D loss: 0.368761] [G loss: 2.547980]\n",
            "[Epoch 0/50] [Batch 515/600] [D loss: 0.337364] [G loss: 2.122624]\n",
            "[Epoch 0/50] [Batch 516/600] [D loss: 0.229810] [G loss: 1.856714]\n",
            "[Epoch 0/50] [Batch 517/600] [D loss: 0.230633] [G loss: 2.102245]\n",
            "[Epoch 0/50] [Batch 518/600] [D loss: 0.283410] [G loss: 2.644297]\n",
            "[Epoch 0/50] [Batch 519/600] [D loss: 0.457266] [G loss: 1.473440]\n",
            "[Epoch 0/50] [Batch 520/600] [D loss: 0.390566] [G loss: 2.591386]\n",
            "[Epoch 0/50] [Batch 521/600] [D loss: 0.366883] [G loss: 1.953212]\n",
            "[Epoch 0/50] [Batch 522/600] [D loss: 0.480069] [G loss: 1.826271]\n",
            "[Epoch 0/50] [Batch 523/600] [D loss: 0.403282] [G loss: 1.469372]\n",
            "[Epoch 0/50] [Batch 524/600] [D loss: 0.458424] [G loss: 1.565215]\n",
            "[Epoch 0/50] [Batch 525/600] [D loss: 0.362336] [G loss: 1.487995]\n",
            "[Epoch 0/50] [Batch 526/600] [D loss: 0.431077] [G loss: 1.409451]\n",
            "[Epoch 0/50] [Batch 527/600] [D loss: 0.358734] [G loss: 1.982036]\n",
            "[Epoch 0/50] [Batch 528/600] [D loss: 0.395874] [G loss: 1.507846]\n",
            "[Epoch 0/50] [Batch 529/600] [D loss: 0.482191] [G loss: 1.283548]\n",
            "[Epoch 0/50] [Batch 530/600] [D loss: 0.490381] [G loss: 2.009489]\n",
            "[Epoch 0/50] [Batch 531/600] [D loss: 0.512444] [G loss: 1.296270]\n",
            "[Epoch 0/50] [Batch 532/600] [D loss: 0.592631] [G loss: 1.325023]\n",
            "[Epoch 0/50] [Batch 533/600] [D loss: 0.436135] [G loss: 1.632755]\n",
            "[Epoch 0/50] [Batch 534/600] [D loss: 0.431497] [G loss: 1.477243]\n",
            "[Epoch 0/50] [Batch 535/600] [D loss: 0.404477] [G loss: 1.517902]\n",
            "[Epoch 0/50] [Batch 536/600] [D loss: 0.481771] [G loss: 1.360397]\n",
            "[Epoch 0/50] [Batch 537/600] [D loss: 0.495727] [G loss: 1.137284]\n",
            "[Epoch 0/50] [Batch 538/600] [D loss: 0.441395] [G loss: 1.326982]\n",
            "[Epoch 0/50] [Batch 539/600] [D loss: 0.491535] [G loss: 1.400981]\n",
            "[Epoch 0/50] [Batch 540/600] [D loss: 0.466431] [G loss: 1.472397]\n",
            "[Epoch 0/50] [Batch 541/600] [D loss: 0.352658] [G loss: 1.318261]\n",
            "[Epoch 0/50] [Batch 542/600] [D loss: 0.323223] [G loss: 1.801810]\n",
            "[Epoch 0/50] [Batch 543/600] [D loss: 0.309291] [G loss: 2.170009]\n",
            "[Epoch 0/50] [Batch 544/600] [D loss: 0.357374] [G loss: 1.524912]\n",
            "[Epoch 0/50] [Batch 545/600] [D loss: 0.277822] [G loss: 2.338753]\n",
            "[Epoch 0/50] [Batch 546/600] [D loss: 0.293212] [G loss: 1.931507]\n",
            "[Epoch 0/50] [Batch 547/600] [D loss: 0.509788] [G loss: 1.555271]\n",
            "[Epoch 0/50] [Batch 548/600] [D loss: 0.449861] [G loss: 2.746865]\n",
            "[Epoch 0/50] [Batch 549/600] [D loss: 0.673527] [G loss: 1.259730]\n",
            "[Epoch 0/50] [Batch 550/600] [D loss: 0.508725] [G loss: 0.847320]\n",
            "[Epoch 0/50] [Batch 551/600] [D loss: 0.537860] [G loss: 1.316154]\n",
            "[Epoch 0/50] [Batch 552/600] [D loss: 0.560655] [G loss: 1.451109]\n",
            "[Epoch 0/50] [Batch 553/600] [D loss: 0.516960] [G loss: 1.087260]\n",
            "[Epoch 0/50] [Batch 554/600] [D loss: 0.470136] [G loss: 1.033989]\n",
            "[Epoch 0/50] [Batch 555/600] [D loss: 0.354934] [G loss: 1.383390]\n",
            "[Epoch 0/50] [Batch 556/600] [D loss: 0.416124] [G loss: 1.359935]\n",
            "[Epoch 0/50] [Batch 557/600] [D loss: 0.354412] [G loss: 1.950277]\n",
            "[Epoch 0/50] [Batch 558/600] [D loss: 0.345947] [G loss: 1.869480]\n",
            "[Epoch 0/50] [Batch 559/600] [D loss: 0.442726] [G loss: 1.561115]\n",
            "[Epoch 0/50] [Batch 560/600] [D loss: 0.434309] [G loss: 2.228651]\n",
            "[Epoch 0/50] [Batch 561/600] [D loss: 0.312430] [G loss: 1.726677]\n",
            "[Epoch 0/50] [Batch 562/600] [D loss: 0.451927] [G loss: 1.262126]\n",
            "[Epoch 0/50] [Batch 563/600] [D loss: 0.488191] [G loss: 1.928038]\n",
            "[Epoch 0/50] [Batch 564/600] [D loss: 0.487575] [G loss: 1.843348]\n",
            "[Epoch 0/50] [Batch 565/600] [D loss: 0.452773] [G loss: 1.179114]\n",
            "[Epoch 0/50] [Batch 566/600] [D loss: 0.473644] [G loss: 1.561505]\n",
            "[Epoch 0/50] [Batch 567/600] [D loss: 0.582358] [G loss: 1.571181]\n",
            "[Epoch 0/50] [Batch 568/600] [D loss: 0.473807] [G loss: 1.281956]\n",
            "[Epoch 0/50] [Batch 569/600] [D loss: 0.504026] [G loss: 1.466044]\n",
            "[Epoch 0/50] [Batch 570/600] [D loss: 0.616872] [G loss: 1.113714]\n",
            "[Epoch 0/50] [Batch 571/600] [D loss: 0.516987] [G loss: 1.057459]\n",
            "[Epoch 0/50] [Batch 572/600] [D loss: 0.486431] [G loss: 1.162095]\n",
            "[Epoch 0/50] [Batch 573/600] [D loss: 0.477676] [G loss: 1.379871]\n",
            "[Epoch 0/50] [Batch 574/600] [D loss: 0.466260] [G loss: 1.506655]\n",
            "[Epoch 0/50] [Batch 575/600] [D loss: 0.409461] [G loss: 1.357855]\n",
            "[Epoch 0/50] [Batch 576/600] [D loss: 0.463394] [G loss: 1.601903]\n",
            "[Epoch 0/50] [Batch 577/600] [D loss: 0.522443] [G loss: 1.411557]\n",
            "[Epoch 0/50] [Batch 578/600] [D loss: 0.616414] [G loss: 1.031775]\n",
            "[Epoch 0/50] [Batch 579/600] [D loss: 0.561285] [G loss: 1.347970]\n",
            "[Epoch 0/50] [Batch 580/600] [D loss: 0.500448] [G loss: 1.106358]\n",
            "[Epoch 0/50] [Batch 581/600] [D loss: 0.497096] [G loss: 0.991276]\n",
            "[Epoch 0/50] [Batch 582/600] [D loss: 0.411807] [G loss: 1.275266]\n",
            "[Epoch 0/50] [Batch 583/600] [D loss: 0.298332] [G loss: 1.478686]\n",
            "[Epoch 0/50] [Batch 584/600] [D loss: 0.368446] [G loss: 1.635105]\n",
            "[Epoch 0/50] [Batch 585/600] [D loss: 0.420145] [G loss: 1.310322]\n",
            "[Epoch 0/50] [Batch 586/600] [D loss: 0.440142] [G loss: 1.934809]\n",
            "[Epoch 0/50] [Batch 587/600] [D loss: 0.350132] [G loss: 1.569153]\n",
            "[Epoch 0/50] [Batch 588/600] [D loss: 0.508896] [G loss: 1.832028]\n",
            "[Epoch 0/50] [Batch 589/600] [D loss: 0.362471] [G loss: 1.127413]\n",
            "[Epoch 0/50] [Batch 590/600] [D loss: 0.273593] [G loss: 1.504963]\n",
            "[Epoch 0/50] [Batch 591/600] [D loss: 0.259358] [G loss: 2.003301]\n",
            "[Epoch 0/50] [Batch 592/600] [D loss: 0.351015] [G loss: 1.578894]\n",
            "[Epoch 0/50] [Batch 593/600] [D loss: 0.550161] [G loss: 1.675431]\n",
            "[Epoch 0/50] [Batch 594/600] [D loss: 0.537865] [G loss: 1.105571]\n",
            "[Epoch 0/50] [Batch 595/600] [D loss: 0.532994] [G loss: 1.484643]\n",
            "[Epoch 0/50] [Batch 596/600] [D loss: 0.320193] [G loss: 2.139194]\n",
            "[Epoch 0/50] [Batch 597/600] [D loss: 0.314051] [G loss: 1.977012]\n",
            "[Epoch 0/50] [Batch 598/600] [D loss: 0.285365] [G loss: 1.808513]\n",
            "[Epoch 0/50] [Batch 599/600] [D loss: 0.443236] [G loss: 1.691064]\n",
            "[Epoch 1/50] [Batch 0/600] [D loss: 0.570888] [G loss: 1.762123]\n",
            "[Epoch 1/50] [Batch 1/600] [D loss: 0.511072] [G loss: 1.351478]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LinearWeightNorm. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[Epoch 41/50] [Batch 401/600] [D loss: 0.396813] [G loss: 1.487967]\n",
            "[Epoch 41/50] [Batch 402/600] [D loss: 0.457684] [G loss: 1.507758]\n",
            "[Epoch 41/50] [Batch 403/600] [D loss: 0.353937] [G loss: 1.718497]\n",
            "[Epoch 41/50] [Batch 404/600] [D loss: 0.403946] [G loss: 1.806402]\n",
            "[Epoch 41/50] [Batch 405/600] [D loss: 0.382067] [G loss: 1.760317]\n",
            "[Epoch 41/50] [Batch 406/600] [D loss: 0.438784] [G loss: 1.568202]\n",
            "[Epoch 41/50] [Batch 407/600] [D loss: 0.416424] [G loss: 1.760963]\n",
            "[Epoch 41/50] [Batch 408/600] [D loss: 0.398047] [G loss: 1.901767]\n",
            "[Epoch 41/50] [Batch 409/600] [D loss: 0.481770] [G loss: 1.541633]\n",
            "[Epoch 41/50] [Batch 410/600] [D loss: 0.414608] [G loss: 1.808567]\n",
            "[Epoch 41/50] [Batch 411/600] [D loss: 0.434108] [G loss: 1.747283]\n",
            "[Epoch 41/50] [Batch 412/600] [D loss: 0.472369] [G loss: 1.375078]\n",
            "[Epoch 41/50] [Batch 413/600] [D loss: 0.454903] [G loss: 1.499290]\n",
            "[Epoch 41/50] [Batch 414/600] [D loss: 0.380128] [G loss: 1.546701]\n",
            "[Epoch 41/50] [Batch 415/600] [D loss: 0.351365] [G loss: 1.692785]\n",
            "[Epoch 41/50] [Batch 416/600] [D loss: 0.399041] [G loss: 1.872932]\n",
            "[Epoch 41/50] [Batch 417/600] [D loss: 0.523318] [G loss: 1.876189]\n",
            "[Epoch 41/50] [Batch 418/600] [D loss: 0.430684] [G loss: 1.607427]\n",
            "[Epoch 41/50] [Batch 419/600] [D loss: 0.442182] [G loss: 1.775985]\n",
            "[Epoch 41/50] [Batch 420/600] [D loss: 0.416117] [G loss: 1.699110]\n",
            "[Epoch 41/50] [Batch 421/600] [D loss: 0.422457] [G loss: 1.669974]\n",
            "[Epoch 41/50] [Batch 422/600] [D loss: 0.401111] [G loss: 1.545336]\n",
            "[Epoch 41/50] [Batch 423/600] [D loss: 0.329264] [G loss: 1.668159]\n",
            "[Epoch 41/50] [Batch 424/600] [D loss: 0.444180] [G loss: 1.530016]\n",
            "[Epoch 41/50] [Batch 425/600] [D loss: 0.436448] [G loss: 1.595531]\n",
            "[Epoch 41/50] [Batch 426/600] [D loss: 0.423043] [G loss: 1.494798]\n",
            "[Epoch 41/50] [Batch 427/600] [D loss: 0.394063] [G loss: 1.790071]\n",
            "[Epoch 41/50] [Batch 428/600] [D loss: 0.387042] [G loss: 1.919210]\n",
            "[Epoch 41/50] [Batch 429/600] [D loss: 0.408889] [G loss: 1.692005]\n",
            "[Epoch 41/50] [Batch 430/600] [D loss: 0.433989] [G loss: 1.978939]\n",
            "[Epoch 41/50] [Batch 431/600] [D loss: 0.435295] [G loss: 1.639798]\n",
            "[Epoch 41/50] [Batch 432/600] [D loss: 0.394362] [G loss: 1.741976]\n",
            "[Epoch 41/50] [Batch 433/600] [D loss: 0.398054] [G loss: 1.762242]\n",
            "[Epoch 41/50] [Batch 434/600] [D loss: 0.387826] [G loss: 1.652540]\n",
            "[Epoch 41/50] [Batch 435/600] [D loss: 0.412052] [G loss: 1.705039]\n",
            "[Epoch 41/50] [Batch 436/600] [D loss: 0.443531] [G loss: 1.713512]\n",
            "[Epoch 41/50] [Batch 437/600] [D loss: 0.413269] [G loss: 1.863074]\n",
            "[Epoch 41/50] [Batch 438/600] [D loss: 0.441918] [G loss: 1.853771]\n",
            "[Epoch 41/50] [Batch 439/600] [D loss: 0.508912] [G loss: 1.581017]\n",
            "[Epoch 41/50] [Batch 440/600] [D loss: 0.419881] [G loss: 1.676335]\n",
            "[Epoch 41/50] [Batch 441/600] [D loss: 0.375943] [G loss: 1.647473]\n",
            "[Epoch 41/50] [Batch 442/600] [D loss: 0.333188] [G loss: 1.505435]\n",
            "[Epoch 41/50] [Batch 443/600] [D loss: 0.400225] [G loss: 1.882284]\n",
            "[Epoch 41/50] [Batch 444/600] [D loss: 0.396050] [G loss: 1.787482]\n",
            "[Epoch 41/50] [Batch 445/600] [D loss: 0.411663] [G loss: 1.815099]\n",
            "[Epoch 41/50] [Batch 446/600] [D loss: 0.404625] [G loss: 1.706106]\n",
            "[Epoch 41/50] [Batch 447/600] [D loss: 0.380924] [G loss: 1.794010]\n",
            "[Epoch 41/50] [Batch 448/600] [D loss: 0.418019] [G loss: 1.707573]\n",
            "[Epoch 41/50] [Batch 449/600] [D loss: 0.484640] [G loss: 1.610454]\n",
            "[Epoch 41/50] [Batch 450/600] [D loss: 0.468058] [G loss: 1.485047]\n",
            "[Epoch 41/50] [Batch 451/600] [D loss: 0.398645] [G loss: 1.561865]\n",
            "[Epoch 41/50] [Batch 452/600] [D loss: 0.341831] [G loss: 1.762002]\n",
            "[Epoch 41/50] [Batch 453/600] [D loss: 0.451766] [G loss: 1.565617]\n",
            "[Epoch 41/50] [Batch 454/600] [D loss: 0.427350] [G loss: 1.985868]\n",
            "[Epoch 41/50] [Batch 455/600] [D loss: 0.371758] [G loss: 1.658954]\n",
            "[Epoch 41/50] [Batch 456/600] [D loss: 0.439995] [G loss: 1.851376]\n",
            "[Epoch 41/50] [Batch 457/600] [D loss: 0.455002] [G loss: 1.765685]\n",
            "[Epoch 41/50] [Batch 458/600] [D loss: 0.456671] [G loss: 1.657732]\n",
            "[Epoch 41/50] [Batch 459/600] [D loss: 0.487510] [G loss: 1.577597]\n",
            "[Epoch 41/50] [Batch 460/600] [D loss: 0.470953] [G loss: 1.809002]\n",
            "[Epoch 41/50] [Batch 461/600] [D loss: 0.458952] [G loss: 1.757934]\n",
            "[Epoch 41/50] [Batch 462/600] [D loss: 0.428486] [G loss: 1.683039]\n",
            "[Epoch 41/50] [Batch 463/600] [D loss: 0.418449] [G loss: 1.688447]\n",
            "[Epoch 41/50] [Batch 464/600] [D loss: 0.368035] [G loss: 1.762295]\n",
            "[Epoch 41/50] [Batch 465/600] [D loss: 0.407315] [G loss: 1.741438]\n",
            "[Epoch 41/50] [Batch 466/600] [D loss: 0.408222] [G loss: 1.847616]\n",
            "[Epoch 41/50] [Batch 467/600] [D loss: 0.422405] [G loss: 1.673016]\n",
            "[Epoch 41/50] [Batch 468/600] [D loss: 0.387263] [G loss: 1.775403]\n",
            "[Epoch 41/50] [Batch 469/600] [D loss: 0.387048] [G loss: 1.954518]\n",
            "[Epoch 41/50] [Batch 470/600] [D loss: 0.442284] [G loss: 1.855180]\n",
            "[Epoch 41/50] [Batch 471/600] [D loss: 0.439700] [G loss: 1.949456]\n",
            "[Epoch 41/50] [Batch 472/600] [D loss: 0.479235] [G loss: 1.899138]\n",
            "[Epoch 41/50] [Batch 473/600] [D loss: 0.440527] [G loss: 1.843891]\n",
            "[Epoch 41/50] [Batch 474/600] [D loss: 0.462087] [G loss: 1.578832]\n",
            "[Epoch 41/50] [Batch 475/600] [D loss: 0.410460] [G loss: 1.464547]\n",
            "[Epoch 41/50] [Batch 476/600] [D loss: 0.388169] [G loss: 1.738756]\n",
            "[Epoch 41/50] [Batch 477/600] [D loss: 0.308767] [G loss: 1.897012]\n",
            "[Epoch 41/50] [Batch 478/600] [D loss: 0.400951] [G loss: 1.690075]\n",
            "[Epoch 41/50] [Batch 479/600] [D loss: 0.402159] [G loss: 1.818660]\n",
            "[Epoch 41/50] [Batch 480/600] [D loss: 0.482509] [G loss: 2.015211]\n",
            "[Epoch 41/50] [Batch 481/600] [D loss: 0.382170] [G loss: 2.033257]\n",
            "[Epoch 41/50] [Batch 482/600] [D loss: 0.402014] [G loss: 1.731185]\n",
            "[Epoch 41/50] [Batch 483/600] [D loss: 0.391830] [G loss: 1.661476]\n",
            "[Epoch 41/50] [Batch 484/600] [D loss: 0.353594] [G loss: 1.692060]\n",
            "[Epoch 41/50] [Batch 485/600] [D loss: 0.413251] [G loss: 1.627976]\n",
            "[Epoch 41/50] [Batch 486/600] [D loss: 0.371473] [G loss: 2.060376]\n",
            "[Epoch 41/50] [Batch 487/600] [D loss: 0.479989] [G loss: 1.796045]\n",
            "[Epoch 41/50] [Batch 488/600] [D loss: 0.369350] [G loss: 1.832311]\n",
            "[Epoch 41/50] [Batch 489/600] [D loss: 0.433647] [G loss: 2.001436]\n",
            "[Epoch 41/50] [Batch 490/600] [D loss: 0.427124] [G loss: 2.027890]\n",
            "[Epoch 41/50] [Batch 491/600] [D loss: 0.362667] [G loss: 1.672094]\n",
            "[Epoch 41/50] [Batch 492/600] [D loss: 0.428038] [G loss: 1.947713]\n",
            "[Epoch 41/50] [Batch 493/600] [D loss: 0.401864] [G loss: 1.891212]\n",
            "[Epoch 41/50] [Batch 494/600] [D loss: 0.479975] [G loss: 1.784623]\n",
            "[Epoch 41/50] [Batch 495/600] [D loss: 0.382566] [G loss: 1.743547]\n",
            "[Epoch 41/50] [Batch 496/600] [D loss: 0.452623] [G loss: 1.667560]\n",
            "[Epoch 41/50] [Batch 497/600] [D loss: 0.461599] [G loss: 1.484158]\n",
            "[Epoch 41/50] [Batch 498/600] [D loss: 0.366875] [G loss: 1.813662]\n",
            "[Epoch 41/50] [Batch 499/600] [D loss: 0.405254] [G loss: 1.491046]\n",
            "[Epoch 41/50] [Batch 500/600] [D loss: 0.431158] [G loss: 1.645917]\n",
            "[Epoch 41/50] [Batch 501/600] [D loss: 0.427079] [G loss: 1.681791]\n",
            "[Epoch 41/50] [Batch 502/600] [D loss: 0.394669] [G loss: 1.707139]\n",
            "[Epoch 41/50] [Batch 503/600] [D loss: 0.463149] [G loss: 1.692735]\n",
            "[Epoch 41/50] [Batch 504/600] [D loss: 0.454062] [G loss: 1.592108]\n",
            "[Epoch 41/50] [Batch 505/600] [D loss: 0.372726] [G loss: 1.603853]\n",
            "[Epoch 41/50] [Batch 506/600] [D loss: 0.408675] [G loss: 1.847219]\n",
            "[Epoch 41/50] [Batch 507/600] [D loss: 0.541542] [G loss: 1.827225]\n",
            "[Epoch 41/50] [Batch 508/600] [D loss: 0.471120] [G loss: 1.858358]\n",
            "[Epoch 41/50] [Batch 509/600] [D loss: 0.445911] [G loss: 1.370572]\n",
            "[Epoch 41/50] [Batch 510/600] [D loss: 0.406686] [G loss: 1.547211]\n",
            "[Epoch 41/50] [Batch 511/600] [D loss: 0.495435] [G loss: 1.500019]\n",
            "[Epoch 41/50] [Batch 512/600] [D loss: 0.423629] [G loss: 1.609676]\n",
            "[Epoch 41/50] [Batch 513/600] [D loss: 0.396708] [G loss: 1.515581]\n",
            "[Epoch 41/50] [Batch 514/600] [D loss: 0.381787] [G loss: 1.653266]\n",
            "[Epoch 41/50] [Batch 515/600] [D loss: 0.343574] [G loss: 1.918293]\n",
            "[Epoch 41/50] [Batch 516/600] [D loss: 0.407735] [G loss: 2.017662]\n",
            "[Epoch 41/50] [Batch 517/600] [D loss: 0.412845] [G loss: 1.697288]\n",
            "[Epoch 41/50] [Batch 518/600] [D loss: 0.408009] [G loss: 1.807494]\n",
            "[Epoch 41/50] [Batch 519/600] [D loss: 0.489919] [G loss: 1.680501]\n",
            "[Epoch 41/50] [Batch 520/600] [D loss: 0.417786] [G loss: 1.718217]\n",
            "[Epoch 41/50] [Batch 521/600] [D loss: 0.407708] [G loss: 1.664092]\n",
            "[Epoch 41/50] [Batch 522/600] [D loss: 0.459804] [G loss: 1.537228]\n",
            "[Epoch 41/50] [Batch 523/600] [D loss: 0.458992] [G loss: 1.527318]\n",
            "[Epoch 41/50] [Batch 524/600] [D loss: 0.408205] [G loss: 1.466906]\n",
            "[Epoch 41/50] [Batch 525/600] [D loss: 0.423329] [G loss: 1.515385]\n",
            "[Epoch 41/50] [Batch 526/600] [D loss: 0.369599] [G loss: 1.405534]\n",
            "[Epoch 41/50] [Batch 527/600] [D loss: 0.397492] [G loss: 1.659360]\n",
            "[Epoch 41/50] [Batch 528/600] [D loss: 0.387430] [G loss: 1.712776]\n",
            "[Epoch 41/50] [Batch 529/600] [D loss: 0.521679] [G loss: 1.570069]\n",
            "[Epoch 41/50] [Batch 530/600] [D loss: 0.467972] [G loss: 1.476205]\n",
            "[Epoch 41/50] [Batch 531/600] [D loss: 0.394165] [G loss: 1.563131]\n",
            "[Epoch 41/50] [Batch 532/600] [D loss: 0.368741] [G loss: 1.565214]\n",
            "[Epoch 41/50] [Batch 533/600] [D loss: 0.395806] [G loss: 1.663011]\n",
            "[Epoch 41/50] [Batch 534/600] [D loss: 0.404816] [G loss: 1.804641]\n",
            "[Epoch 41/50] [Batch 535/600] [D loss: 0.405333] [G loss: 1.765479]\n",
            "[Epoch 41/50] [Batch 536/600] [D loss: 0.421016] [G loss: 1.576767]\n",
            "[Epoch 41/50] [Batch 537/600] [D loss: 0.484182] [G loss: 1.636145]\n",
            "[Epoch 41/50] [Batch 538/600] [D loss: 0.420793] [G loss: 1.472838]\n",
            "[Epoch 41/50] [Batch 539/600] [D loss: 0.416712] [G loss: 1.550059]\n",
            "[Epoch 41/50] [Batch 540/600] [D loss: 0.472598] [G loss: 1.679754]\n",
            "[Epoch 41/50] [Batch 541/600] [D loss: 0.452076] [G loss: 1.559467]\n",
            "[Epoch 41/50] [Batch 542/600] [D loss: 0.403862] [G loss: 1.537604]\n",
            "[Epoch 41/50] [Batch 543/600] [D loss: 0.459961] [G loss: 1.752485]\n",
            "[Epoch 41/50] [Batch 544/600] [D loss: 0.416044] [G loss: 1.687243]\n",
            "[Epoch 41/50] [Batch 545/600] [D loss: 0.386821] [G loss: 1.762799]\n",
            "[Epoch 41/50] [Batch 546/600] [D loss: 0.383347] [G loss: 1.720122]\n",
            "[Epoch 41/50] [Batch 547/600] [D loss: 0.480018] [G loss: 1.540975]\n",
            "[Epoch 41/50] [Batch 548/600] [D loss: 0.396739] [G loss: 1.918870]\n",
            "[Epoch 41/50] [Batch 549/600] [D loss: 0.441929] [G loss: 1.762715]\n",
            "[Epoch 41/50] [Batch 550/600] [D loss: 0.421567] [G loss: 1.918006]\n",
            "[Epoch 41/50] [Batch 551/600] [D loss: 0.383185] [G loss: 1.693769]\n",
            "[Epoch 41/50] [Batch 552/600] [D loss: 0.452890] [G loss: 1.872927]\n",
            "[Epoch 41/50] [Batch 553/600] [D loss: 0.424934] [G loss: 1.639968]\n",
            "[Epoch 41/50] [Batch 554/600] [D loss: 0.422642] [G loss: 1.764091]\n",
            "[Epoch 41/50] [Batch 555/600] [D loss: 0.357145] [G loss: 1.904859]\n",
            "[Epoch 41/50] [Batch 556/600] [D loss: 0.430113] [G loss: 1.745770]\n",
            "[Epoch 41/50] [Batch 557/600] [D loss: 0.409902] [G loss: 1.829433]\n",
            "[Epoch 41/50] [Batch 558/600] [D loss: 0.455759] [G loss: 1.566976]\n",
            "[Epoch 41/50] [Batch 559/600] [D loss: 0.339935] [G loss: 1.921231]\n",
            "[Epoch 41/50] [Batch 560/600] [D loss: 0.445912] [G loss: 2.055446]\n",
            "[Epoch 41/50] [Batch 561/600] [D loss: 0.420345] [G loss: 1.776291]\n",
            "[Epoch 41/50] [Batch 562/600] [D loss: 0.447699] [G loss: 2.054772]\n",
            "[Epoch 41/50] [Batch 563/600] [D loss: 0.465524] [G loss: 1.714818]\n",
            "[Epoch 41/50] [Batch 564/600] [D loss: 0.507113] [G loss: 1.395177]\n",
            "[Epoch 41/50] [Batch 565/600] [D loss: 0.423662] [G loss: 1.529931]\n",
            "[Epoch 41/50] [Batch 566/600] [D loss: 0.444343] [G loss: 1.648036]\n",
            "[Epoch 41/50] [Batch 567/600] [D loss: 0.338438] [G loss: 1.583319]\n",
            "[Epoch 41/50] [Batch 568/600] [D loss: 0.404708] [G loss: 1.708257]\n",
            "[Epoch 41/50] [Batch 569/600] [D loss: 0.410065] [G loss: 1.690260]\n",
            "[Epoch 41/50] [Batch 570/600] [D loss: 0.514352] [G loss: 1.682767]\n",
            "[Epoch 41/50] [Batch 571/600] [D loss: 0.415722] [G loss: 1.881938]\n",
            "[Epoch 41/50] [Batch 572/600] [D loss: 0.405785] [G loss: 1.843270]\n",
            "[Epoch 41/50] [Batch 573/600] [D loss: 0.414792] [G loss: 1.702702]\n",
            "[Epoch 41/50] [Batch 574/600] [D loss: 0.427898] [G loss: 1.644326]\n",
            "[Epoch 41/50] [Batch 575/600] [D loss: 0.409470] [G loss: 1.857048]\n",
            "[Epoch 41/50] [Batch 576/600] [D loss: 0.413519] [G loss: 1.882084]\n",
            "[Epoch 41/50] [Batch 577/600] [D loss: 0.427779] [G loss: 1.776883]\n",
            "[Epoch 41/50] [Batch 578/600] [D loss: 0.479419] [G loss: 1.646711]\n",
            "[Epoch 41/50] [Batch 579/600] [D loss: 0.419900] [G loss: 1.649131]\n",
            "[Epoch 41/50] [Batch 580/600] [D loss: 0.357998] [G loss: 1.631620]\n",
            "[Epoch 41/50] [Batch 581/600] [D loss: 0.397553] [G loss: 1.779689]\n",
            "[Epoch 41/50] [Batch 582/600] [D loss: 0.361827] [G loss: 1.798286]\n",
            "[Epoch 41/50] [Batch 583/600] [D loss: 0.385660] [G loss: 1.908216]\n",
            "[Epoch 41/50] [Batch 584/600] [D loss: 0.396736] [G loss: 1.982967]\n",
            "[Epoch 41/50] [Batch 585/600] [D loss: 0.430476] [G loss: 1.622858]\n",
            "[Epoch 41/50] [Batch 586/600] [D loss: 0.504613] [G loss: 1.637417]\n",
            "[Epoch 41/50] [Batch 587/600] [D loss: 0.464702] [G loss: 1.731931]\n",
            "[Epoch 41/50] [Batch 588/600] [D loss: 0.369979] [G loss: 1.638967]\n",
            "[Epoch 41/50] [Batch 589/600] [D loss: 0.332117] [G loss: 1.781935]\n",
            "[Epoch 41/50] [Batch 590/600] [D loss: 0.425879] [G loss: 1.541685]\n",
            "[Epoch 41/50] [Batch 591/600] [D loss: 0.303054] [G loss: 1.756724]\n",
            "[Epoch 41/50] [Batch 592/600] [D loss: 0.391890] [G loss: 1.860857]\n",
            "[Epoch 41/50] [Batch 593/600] [D loss: 0.504621] [G loss: 1.992231]\n",
            "[Epoch 41/50] [Batch 594/600] [D loss: 0.409779] [G loss: 1.511353]\n",
            "[Epoch 41/50] [Batch 595/600] [D loss: 0.441258] [G loss: 1.475871]\n",
            "[Epoch 41/50] [Batch 596/600] [D loss: 0.351430] [G loss: 1.741602]\n",
            "[Epoch 41/50] [Batch 597/600] [D loss: 0.405206] [G loss: 1.895429]\n",
            "[Epoch 41/50] [Batch 598/600] [D loss: 0.367292] [G loss: 2.201083]\n",
            "[Epoch 41/50] [Batch 599/600] [D loss: 0.359670] [G loss: 1.799386]\n",
            "[Epoch 42/50] [Batch 0/600] [D loss: 0.402528] [G loss: 2.108263]\n",
            "[Epoch 42/50] [Batch 1/600] [D loss: 0.429365] [G loss: 1.847584]\n",
            "[Epoch 42/50] [Batch 2/600] [D loss: 0.386228] [G loss: 2.005153]\n",
            "[Epoch 42/50] [Batch 3/600] [D loss: 0.404975] [G loss: 1.992831]\n",
            "[Epoch 42/50] [Batch 4/600] [D loss: 0.461322] [G loss: 1.824799]\n",
            "[Epoch 42/50] [Batch 5/600] [D loss: 0.402405] [G loss: 1.775441]\n",
            "[Epoch 42/50] [Batch 6/600] [D loss: 0.454918] [G loss: 1.608517]\n",
            "[Epoch 42/50] [Batch 7/600] [D loss: 0.339630] [G loss: 1.854498]\n",
            "[Epoch 42/50] [Batch 8/600] [D loss: 0.371227] [G loss: 1.817461]\n",
            "[Epoch 42/50] [Batch 9/600] [D loss: 0.318805] [G loss: 1.750461]\n",
            "[Epoch 42/50] [Batch 10/600] [D loss: 0.501825] [G loss: 1.901910]\n",
            "[Epoch 42/50] [Batch 11/600] [D loss: 0.459603] [G loss: 1.614430]\n",
            "[Epoch 42/50] [Batch 12/600] [D loss: 0.406694] [G loss: 2.047539]\n",
            "[Epoch 42/50] [Batch 13/600] [D loss: 0.394985] [G loss: 1.535305]\n",
            "[Epoch 42/50] [Batch 14/600] [D loss: 0.414379] [G loss: 1.406979]\n",
            "[Epoch 42/50] [Batch 15/600] [D loss: 0.356161] [G loss: 1.752845]\n",
            "[Epoch 42/50] [Batch 16/600] [D loss: 0.424580] [G loss: 1.802066]\n",
            "[Epoch 42/50] [Batch 17/600] [D loss: 0.447609] [G loss: 1.677201]\n",
            "[Epoch 42/50] [Batch 18/600] [D loss: 0.433369] [G loss: 1.919365]\n",
            "[Epoch 42/50] [Batch 19/600] [D loss: 0.472847] [G loss: 1.690534]\n",
            "[Epoch 42/50] [Batch 20/600] [D loss: 0.425024] [G loss: 1.715462]\n",
            "[Epoch 42/50] [Batch 21/600] [D loss: 0.444408] [G loss: 1.562110]\n",
            "[Epoch 42/50] [Batch 22/600] [D loss: 0.491975] [G loss: 1.391302]\n",
            "[Epoch 42/50] [Batch 23/600] [D loss: 0.393118] [G loss: 1.800147]\n",
            "[Epoch 42/50] [Batch 24/600] [D loss: 0.342804] [G loss: 1.647195]\n",
            "[Epoch 42/50] [Batch 25/600] [D loss: 0.355866] [G loss: 1.836354]\n",
            "[Epoch 42/50] [Batch 26/600] [D loss: 0.373701] [G loss: 2.071799]\n",
            "[Epoch 42/50] [Batch 27/600] [D loss: 0.411095] [G loss: 1.978266]\n",
            "[Epoch 42/50] [Batch 28/600] [D loss: 0.371459] [G loss: 1.825657]\n",
            "[Epoch 42/50] [Batch 29/600] [D loss: 0.420770] [G loss: 1.856266]\n",
            "[Epoch 42/50] [Batch 30/600] [D loss: 0.420422] [G loss: 1.943359]\n",
            "[Epoch 42/50] [Batch 31/600] [D loss: 0.400195] [G loss: 1.892397]\n",
            "[Epoch 42/50] [Batch 32/600] [D loss: 0.471750] [G loss: 1.611658]\n",
            "[Epoch 42/50] [Batch 33/600] [D loss: 0.394376] [G loss: 1.749744]\n",
            "[Epoch 42/50] [Batch 34/600] [D loss: 0.414978] [G loss: 1.808202]\n",
            "[Epoch 42/50] [Batch 35/600] [D loss: 0.425461] [G loss: 1.659658]\n",
            "[Epoch 42/50] [Batch 36/600] [D loss: 0.365817] [G loss: 1.993158]\n",
            "[Epoch 42/50] [Batch 37/600] [D loss: 0.419622] [G loss: 2.003182]\n",
            "[Epoch 42/50] [Batch 38/600] [D loss: 0.462320] [G loss: 1.810315]\n",
            "[Epoch 42/50] [Batch 39/600] [D loss: 0.392761] [G loss: 1.992268]\n",
            "[Epoch 42/50] [Batch 40/600] [D loss: 0.425804] [G loss: 1.778200]\n",
            "[Epoch 42/50] [Batch 41/600] [D loss: 0.394859] [G loss: 1.782252]\n",
            "[Epoch 42/50] [Batch 42/600] [D loss: 0.419610] [G loss: 1.860578]\n",
            "[Epoch 42/50] [Batch 43/600] [D loss: 0.401186] [G loss: 1.693661]\n",
            "[Epoch 42/50] [Batch 44/600] [D loss: 0.319299] [G loss: 1.502876]\n",
            "[Epoch 42/50] [Batch 45/600] [D loss: 0.414511] [G loss: 1.685306]\n",
            "[Epoch 42/50] [Batch 46/600] [D loss: 0.386535] [G loss: 1.864570]\n",
            "[Epoch 42/50] [Batch 47/600] [D loss: 0.377447] [G loss: 1.944578]\n",
            "[Epoch 42/50] [Batch 48/600] [D loss: 0.397120] [G loss: 1.965128]\n",
            "[Epoch 42/50] [Batch 49/600] [D loss: 0.440357] [G loss: 1.798717]\n",
            "[Epoch 42/50] [Batch 50/600] [D loss: 0.426604] [G loss: 1.882466]\n",
            "[Epoch 42/50] [Batch 51/600] [D loss: 0.363396] [G loss: 1.856364]\n",
            "[Epoch 42/50] [Batch 52/600] [D loss: 0.404464] [G loss: 1.774520]\n",
            "[Epoch 42/50] [Batch 53/600] [D loss: 0.361011] [G loss: 1.746507]\n",
            "[Epoch 42/50] [Batch 54/600] [D loss: 0.394591] [G loss: 1.874573]\n",
            "[Epoch 42/50] [Batch 55/600] [D loss: 0.394949] [G loss: 2.048550]\n",
            "[Epoch 42/50] [Batch 56/600] [D loss: 0.358767] [G loss: 1.788569]\n",
            "[Epoch 42/50] [Batch 57/600] [D loss: 0.457755] [G loss: 1.714159]\n",
            "[Epoch 42/50] [Batch 58/600] [D loss: 0.401375] [G loss: 1.857148]\n",
            "[Epoch 42/50] [Batch 59/600] [D loss: 0.411653] [G loss: 1.725985]\n",
            "[Epoch 42/50] [Batch 60/600] [D loss: 0.443881] [G loss: 1.876524]\n",
            "[Epoch 42/50] [Batch 61/600] [D loss: 0.384822] [G loss: 1.755344]\n",
            "[Epoch 42/50] [Batch 62/600] [D loss: 0.407368] [G loss: 1.670896]\n",
            "[Epoch 42/50] [Batch 63/600] [D loss: 0.369228] [G loss: 1.882043]\n",
            "[Epoch 42/50] [Batch 64/600] [D loss: 0.404923] [G loss: 1.774635]\n",
            "[Epoch 42/50] [Batch 65/600] [D loss: 0.374206] [G loss: 1.839911]\n",
            "[Epoch 42/50] [Batch 66/600] [D loss: 0.497320] [G loss: 1.981013]\n",
            "[Epoch 42/50] [Batch 67/600] [D loss: 0.454046] [G loss: 1.847143]\n",
            "[Epoch 42/50] [Batch 68/600] [D loss: 0.493780] [G loss: 1.689014]\n",
            "[Epoch 42/50] [Batch 69/600] [D loss: 0.366575] [G loss: 1.691536]\n",
            "[Epoch 42/50] [Batch 70/600] [D loss: 0.436240] [G loss: 1.663936]\n",
            "[Epoch 42/50] [Batch 71/600] [D loss: 0.448228] [G loss: 1.766626]\n",
            "[Epoch 42/50] [Batch 72/600] [D loss: 0.492480] [G loss: 1.596269]\n",
            "[Epoch 42/50] [Batch 73/600] [D loss: 0.480110] [G loss: 1.621197]\n",
            "[Epoch 42/50] [Batch 74/600] [D loss: 0.455564] [G loss: 1.718771]\n",
            "[Epoch 42/50] [Batch 75/600] [D loss: 0.488684] [G loss: 1.519321]\n",
            "[Epoch 42/50] [Batch 76/600] [D loss: 0.446952] [G loss: 1.888669]\n",
            "[Epoch 42/50] [Batch 77/600] [D loss: 0.424382] [G loss: 1.679006]\n",
            "[Epoch 42/50] [Batch 78/600] [D loss: 0.394715] [G loss: 1.638811]\n",
            "[Epoch 42/50] [Batch 79/600] [D loss: 0.405152] [G loss: 1.657285]\n",
            "[Epoch 42/50] [Batch 80/600] [D loss: 0.338240] [G loss: 1.841256]\n",
            "[Epoch 42/50] [Batch 81/600] [D loss: 0.374639] [G loss: 1.821473]\n",
            "[Epoch 42/50] [Batch 82/600] [D loss: 0.378920] [G loss: 1.812216]\n",
            "[Epoch 42/50] [Batch 83/600] [D loss: 0.344201] [G loss: 1.880175]\n",
            "[Epoch 42/50] [Batch 84/600] [D loss: 0.426571] [G loss: 1.986709]\n",
            "[Epoch 42/50] [Batch 85/600] [D loss: 0.472209] [G loss: 1.909191]\n",
            "[Epoch 42/50] [Batch 86/600] [D loss: 0.368653] [G loss: 1.888124]\n",
            "[Epoch 42/50] [Batch 87/600] [D loss: 0.457619] [G loss: 1.710870]\n",
            "[Epoch 42/50] [Batch 88/600] [D loss: 0.364786] [G loss: 1.833724]\n",
            "[Epoch 42/50] [Batch 89/600] [D loss: 0.430713] [G loss: 1.919456]\n",
            "[Epoch 42/50] [Batch 90/600] [D loss: 0.477281] [G loss: 1.829954]\n",
            "[Epoch 42/50] [Batch 91/600] [D loss: 0.495266] [G loss: 1.696773]\n",
            "[Epoch 42/50] [Batch 92/600] [D loss: 0.480592] [G loss: 1.682986]\n",
            "[Epoch 42/50] [Batch 93/600] [D loss: 0.423370] [G loss: 1.538268]\n",
            "[Epoch 42/50] [Batch 94/600] [D loss: 0.423000] [G loss: 1.686848]\n",
            "[Epoch 42/50] [Batch 95/600] [D loss: 0.388589] [G loss: 1.707612]\n",
            "[Epoch 42/50] [Batch 96/600] [D loss: 0.378581] [G loss: 1.526742]\n",
            "[Epoch 42/50] [Batch 97/600] [D loss: 0.400108] [G loss: 1.831032]\n",
            "[Epoch 42/50] [Batch 98/600] [D loss: 0.377099] [G loss: 1.608968]\n",
            "[Epoch 42/50] [Batch 99/600] [D loss: 0.394743] [G loss: 1.705240]\n",
            "[Epoch 42/50] [Batch 100/600] [D loss: 0.457047] [G loss: 1.794131]\n",
            "[Epoch 42/50] [Batch 101/600] [D loss: 0.440621] [G loss: 1.814456]\n",
            "[Epoch 42/50] [Batch 102/600] [D loss: 0.430901] [G loss: 1.793470]\n",
            "[Epoch 42/50] [Batch 103/600] [D loss: 0.410040] [G loss: 1.830929]\n",
            "[Epoch 42/50] [Batch 104/600] [D loss: 0.456644] [G loss: 1.612763]\n",
            "[Epoch 42/50] [Batch 105/600] [D loss: 0.403241] [G loss: 1.830537]\n",
            "[Epoch 42/50] [Batch 106/600] [D loss: 0.378217] [G loss: 1.692359]\n",
            "[Epoch 42/50] [Batch 107/600] [D loss: 0.455475] [G loss: 1.807167]\n",
            "[Epoch 42/50] [Batch 108/600] [D loss: 0.419627] [G loss: 1.655019]\n",
            "[Epoch 42/50] [Batch 109/600] [D loss: 0.340024] [G loss: 1.661966]\n",
            "[Epoch 42/50] [Batch 110/600] [D loss: 0.476005] [G loss: 1.690479]\n",
            "[Epoch 42/50] [Batch 111/600] [D loss: 0.504746] [G loss: 1.631071]\n",
            "[Epoch 42/50] [Batch 112/600] [D loss: 0.415485] [G loss: 1.881580]\n",
            "[Epoch 42/50] [Batch 113/600] [D loss: 0.424935] [G loss: 1.845184]\n",
            "[Epoch 42/50] [Batch 114/600] [D loss: 0.410399] [G loss: 1.523095]\n",
            "[Epoch 42/50] [Batch 115/600] [D loss: 0.429578] [G loss: 1.429947]\n",
            "[Epoch 42/50] [Batch 116/600] [D loss: 0.402610] [G loss: 1.354362]\n",
            "[Epoch 42/50] [Batch 117/600] [D loss: 0.386981] [G loss: 1.550350]\n",
            "[Epoch 42/50] [Batch 118/600] [D loss: 0.415893] [G loss: 1.894915]\n",
            "[Epoch 42/50] [Batch 119/600] [D loss: 0.492147] [G loss: 1.894454]\n",
            "[Epoch 42/50] [Batch 120/600] [D loss: 0.413451] [G loss: 1.948184]\n",
            "[Epoch 42/50] [Batch 121/600] [D loss: 0.389970] [G loss: 1.464259]\n",
            "[Epoch 42/50] [Batch 122/600] [D loss: 0.406259] [G loss: 1.683102]\n",
            "[Epoch 42/50] [Batch 123/600] [D loss: 0.394547] [G loss: 1.708292]\n",
            "[Epoch 42/50] [Batch 124/600] [D loss: 0.359922] [G loss: 2.078346]\n",
            "[Epoch 42/50] [Batch 125/600] [D loss: 0.379759] [G loss: 1.952637]\n",
            "[Epoch 42/50] [Batch 126/600] [D loss: 0.409345] [G loss: 1.715325]\n",
            "[Epoch 42/50] [Batch 127/600] [D loss: 0.465075] [G loss: 1.835820]\n",
            "[Epoch 42/50] [Batch 128/600] [D loss: 0.447068] [G loss: 1.729305]\n",
            "[Epoch 42/50] [Batch 129/600] [D loss: 0.392985] [G loss: 1.790272]\n",
            "[Epoch 42/50] [Batch 130/600] [D loss: 0.405289] [G loss: 1.644750]\n",
            "[Epoch 42/50] [Batch 131/600] [D loss: 0.395334] [G loss: 1.377865]\n",
            "[Epoch 42/50] [Batch 132/600] [D loss: 0.402522] [G loss: 1.738852]\n",
            "[Epoch 42/50] [Batch 133/600] [D loss: 0.409333] [G loss: 1.694219]\n",
            "[Epoch 42/50] [Batch 134/600] [D loss: 0.439042] [G loss: 1.930729]\n",
            "[Epoch 42/50] [Batch 135/600] [D loss: 0.418175] [G loss: 1.710108]\n",
            "[Epoch 42/50] [Batch 136/600] [D loss: 0.438237] [G loss: 1.872952]\n",
            "[Epoch 42/50] [Batch 137/600] [D loss: 0.474216] [G loss: 1.393826]\n",
            "[Epoch 42/50] [Batch 138/600] [D loss: 0.382279] [G loss: 1.565344]\n",
            "[Epoch 42/50] [Batch 139/600] [D loss: 0.439185] [G loss: 1.914257]\n",
            "[Epoch 42/50] [Batch 140/600] [D loss: 0.410636] [G loss: 1.695673]\n",
            "[Epoch 42/50] [Batch 141/600] [D loss: 0.376968] [G loss: 1.871855]\n",
            "[Epoch 42/50] [Batch 142/600] [D loss: 0.452470] [G loss: 1.738589]\n",
            "[Epoch 42/50] [Batch 143/600] [D loss: 0.392549] [G loss: 1.740937]\n",
            "[Epoch 42/50] [Batch 144/600] [D loss: 0.427487] [G loss: 1.897079]\n",
            "[Epoch 42/50] [Batch 145/600] [D loss: 0.407896] [G loss: 1.798143]\n",
            "[Epoch 42/50] [Batch 146/600] [D loss: 0.429137] [G loss: 1.694501]\n",
            "[Epoch 42/50] [Batch 147/600] [D loss: 0.435840] [G loss: 1.661963]\n",
            "[Epoch 42/50] [Batch 148/600] [D loss: 0.431664] [G loss: 1.854989]\n",
            "[Epoch 42/50] [Batch 149/600] [D loss: 0.468092] [G loss: 1.709004]\n",
            "[Epoch 42/50] [Batch 150/600] [D loss: 0.434081] [G loss: 1.673858]\n",
            "[Epoch 42/50] [Batch 151/600] [D loss: 0.470766] [G loss: 1.719739]\n",
            "[Epoch 42/50] [Batch 152/600] [D loss: 0.389645] [G loss: 1.599578]\n",
            "[Epoch 42/50] [Batch 153/600] [D loss: 0.508710] [G loss: 1.744159]\n",
            "[Epoch 42/50] [Batch 154/600] [D loss: 0.434758] [G loss: 1.748207]\n",
            "[Epoch 42/50] [Batch 155/600] [D loss: 0.400159] [G loss: 1.555055]\n",
            "[Epoch 42/50] [Batch 156/600] [D loss: 0.370475] [G loss: 1.681522]\n",
            "[Epoch 42/50] [Batch 157/600] [D loss: 0.474016] [G loss: 1.887729]\n",
            "[Epoch 42/50] [Batch 158/600] [D loss: 0.413463] [G loss: 1.753039]\n",
            "[Epoch 42/50] [Batch 159/600] [D loss: 0.429808] [G loss: 1.624599]\n",
            "[Epoch 42/50] [Batch 160/600] [D loss: 0.502937] [G loss: 1.623537]\n",
            "[Epoch 42/50] [Batch 161/600] [D loss: 0.505474] [G loss: 1.546753]\n",
            "[Epoch 42/50] [Batch 162/600] [D loss: 0.379405] [G loss: 1.607935]\n",
            "[Epoch 42/50] [Batch 163/600] [D loss: 0.444036] [G loss: 1.576794]\n",
            "[Epoch 42/50] [Batch 164/600] [D loss: 0.460857] [G loss: 1.515816]\n",
            "[Epoch 42/50] [Batch 165/600] [D loss: 0.489191] [G loss: 1.524028]\n",
            "[Epoch 42/50] [Batch 166/600] [D loss: 0.437446] [G loss: 1.555404]\n",
            "[Epoch 42/50] [Batch 167/600] [D loss: 0.355267] [G loss: 1.610699]\n",
            "[Epoch 42/50] [Batch 168/600] [D loss: 0.420377] [G loss: 1.606902]\n",
            "[Epoch 42/50] [Batch 169/600] [D loss: 0.436411] [G loss: 1.695717]\n",
            "[Epoch 42/50] [Batch 170/600] [D loss: 0.421254] [G loss: 1.552345]\n",
            "[Epoch 42/50] [Batch 171/600] [D loss: 0.416423] [G loss: 1.677147]\n",
            "[Epoch 42/50] [Batch 172/600] [D loss: 0.444519] [G loss: 1.522502]\n",
            "[Epoch 42/50] [Batch 173/600] [D loss: 0.433461] [G loss: 1.785732]\n",
            "[Epoch 42/50] [Batch 174/600] [D loss: 0.441833] [G loss: 1.727798]\n",
            "[Epoch 42/50] [Batch 175/600] [D loss: 0.405543] [G loss: 1.656959]\n",
            "[Epoch 42/50] [Batch 176/600] [D loss: 0.423391] [G loss: 1.704183]\n",
            "[Epoch 42/50] [Batch 177/600] [D loss: 0.514902] [G loss: 1.632262]\n",
            "[Epoch 42/50] [Batch 178/600] [D loss: 0.437203] [G loss: 1.625290]\n",
            "[Epoch 42/50] [Batch 179/600] [D loss: 0.479797] [G loss: 1.761574]\n",
            "[Epoch 42/50] [Batch 180/600] [D loss: 0.456987] [G loss: 1.713937]\n",
            "[Epoch 42/50] [Batch 181/600] [D loss: 0.413872] [G loss: 1.583929]\n",
            "[Epoch 42/50] [Batch 182/600] [D loss: 0.409196] [G loss: 1.654896]\n",
            "[Epoch 42/50] [Batch 183/600] [D loss: 0.474125] [G loss: 1.419126]\n",
            "[Epoch 42/50] [Batch 184/600] [D loss: 0.410364] [G loss: 1.549406]\n",
            "[Epoch 42/50] [Batch 185/600] [D loss: 0.377621] [G loss: 1.538336]\n",
            "[Epoch 42/50] [Batch 186/600] [D loss: 0.414811] [G loss: 1.746473]\n",
            "[Epoch 42/50] [Batch 187/600] [D loss: 0.470965] [G loss: 2.044528]\n",
            "[Epoch 42/50] [Batch 188/600] [D loss: 0.447873] [G loss: 1.638420]\n",
            "[Epoch 42/50] [Batch 189/600] [D loss: 0.380974] [G loss: 1.788112]\n",
            "[Epoch 42/50] [Batch 190/600] [D loss: 0.357002] [G loss: 1.721774]\n",
            "[Epoch 42/50] [Batch 191/600] [D loss: 0.449870] [G loss: 2.012052]\n",
            "[Epoch 42/50] [Batch 192/600] [D loss: 0.423873] [G loss: 1.815516]\n",
            "[Epoch 42/50] [Batch 193/600] [D loss: 0.402699] [G loss: 1.697671]\n",
            "[Epoch 42/50] [Batch 194/600] [D loss: 0.420002] [G loss: 1.538287]\n",
            "[Epoch 42/50] [Batch 195/600] [D loss: 0.481110] [G loss: 1.699184]\n",
            "[Epoch 42/50] [Batch 196/600] [D loss: 0.453052] [G loss: 1.488744]\n",
            "[Epoch 42/50] [Batch 197/600] [D loss: 0.364682] [G loss: 1.699963]\n",
            "[Epoch 42/50] [Batch 198/600] [D loss: 0.410853] [G loss: 1.865837]\n",
            "[Epoch 42/50] [Batch 199/600] [D loss: 0.381066] [G loss: 1.780920]\n",
            "[Epoch 42/50] [Batch 200/600] [D loss: 0.355304] [G loss: 1.891724]\n",
            "[Epoch 42/50] [Batch 201/600] [D loss: 0.406456] [G loss: 1.844766]\n",
            "[Epoch 42/50] [Batch 202/600] [D loss: 0.441485] [G loss: 1.986544]\n",
            "[Epoch 42/50] [Batch 203/600] [D loss: 0.438574] [G loss: 1.895624]\n",
            "[Epoch 42/50] [Batch 204/600] [D loss: 0.325386] [G loss: 1.864722]\n",
            "[Epoch 42/50] [Batch 205/600] [D loss: 0.390217] [G loss: 1.635534]\n",
            "[Epoch 42/50] [Batch 206/600] [D loss: 0.475688] [G loss: 1.821087]\n",
            "[Epoch 42/50] [Batch 207/600] [D loss: 0.362279] [G loss: 1.700477]\n",
            "[Epoch 42/50] [Batch 208/600] [D loss: 0.403598] [G loss: 1.743077]\n",
            "[Epoch 42/50] [Batch 209/600] [D loss: 0.394782] [G loss: 1.526343]\n",
            "[Epoch 42/50] [Batch 210/600] [D loss: 0.384735] [G loss: 1.672366]\n",
            "[Epoch 42/50] [Batch 211/600] [D loss: 0.419570] [G loss: 2.180251]\n",
            "[Epoch 42/50] [Batch 212/600] [D loss: 0.436035] [G loss: 2.221833]\n",
            "[Epoch 42/50] [Batch 213/600] [D loss: 0.452621] [G loss: 1.946075]\n",
            "[Epoch 42/50] [Batch 214/600] [D loss: 0.435115] [G loss: 1.678852]\n",
            "[Epoch 42/50] [Batch 215/600] [D loss: 0.398514] [G loss: 1.661349]\n",
            "[Epoch 42/50] [Batch 216/600] [D loss: 0.473776] [G loss: 1.653564]\n",
            "[Epoch 42/50] [Batch 217/600] [D loss: 0.428667] [G loss: 1.816434]\n",
            "[Epoch 42/50] [Batch 218/600] [D loss: 0.418798] [G loss: 1.593090]\n",
            "[Epoch 42/50] [Batch 219/600] [D loss: 0.315149] [G loss: 1.689334]\n",
            "[Epoch 42/50] [Batch 220/600] [D loss: 0.387799] [G loss: 1.744209]\n",
            "[Epoch 42/50] [Batch 221/600] [D loss: 0.436902] [G loss: 1.753866]\n",
            "[Epoch 42/50] [Batch 222/600] [D loss: 0.478547] [G loss: 1.695267]\n",
            "[Epoch 42/50] [Batch 223/600] [D loss: 0.381047] [G loss: 1.862631]\n",
            "[Epoch 42/50] [Batch 224/600] [D loss: 0.423000] [G loss: 1.764964]\n",
            "[Epoch 42/50] [Batch 225/600] [D loss: 0.452749] [G loss: 1.476112]\n",
            "[Epoch 42/50] [Batch 226/600] [D loss: 0.339841] [G loss: 1.621136]\n",
            "[Epoch 42/50] [Batch 227/600] [D loss: 0.441414] [G loss: 1.758371]\n",
            "[Epoch 42/50] [Batch 228/600] [D loss: 0.319113] [G loss: 1.782242]\n",
            "[Epoch 42/50] [Batch 229/600] [D loss: 0.350764] [G loss: 1.859247]\n",
            "[Epoch 42/50] [Batch 230/600] [D loss: 0.319407] [G loss: 1.977687]\n",
            "[Epoch 42/50] [Batch 231/600] [D loss: 0.382907] [G loss: 2.179296]\n",
            "[Epoch 42/50] [Batch 232/600] [D loss: 0.381262] [G loss: 2.079063]\n",
            "[Epoch 42/50] [Batch 233/600] [D loss: 0.491012] [G loss: 1.907785]\n",
            "[Epoch 42/50] [Batch 234/600] [D loss: 0.398031] [G loss: 1.785918]\n",
            "[Epoch 42/50] [Batch 235/600] [D loss: 0.450991] [G loss: 1.858699]\n",
            "[Epoch 42/50] [Batch 236/600] [D loss: 0.381378] [G loss: 1.809962]\n",
            "[Epoch 42/50] [Batch 237/600] [D loss: 0.498907] [G loss: 1.608370]\n",
            "[Epoch 42/50] [Batch 238/600] [D loss: 0.400748] [G loss: 1.761855]\n",
            "[Epoch 42/50] [Batch 239/600] [D loss: 0.456902] [G loss: 1.597330]\n",
            "[Epoch 42/50] [Batch 240/600] [D loss: 0.458013] [G loss: 1.642602]\n",
            "[Epoch 42/50] [Batch 241/600] [D loss: 0.460826] [G loss: 1.674662]\n",
            "[Epoch 42/50] [Batch 242/600] [D loss: 0.368310] [G loss: 1.497744]\n",
            "[Epoch 42/50] [Batch 243/600] [D loss: 0.482316] [G loss: 1.527052]\n",
            "[Epoch 42/50] [Batch 244/600] [D loss: 0.371199] [G loss: 1.970356]\n",
            "[Epoch 42/50] [Batch 245/600] [D loss: 0.454993] [G loss: 1.947788]\n",
            "[Epoch 42/50] [Batch 246/600] [D loss: 0.336973] [G loss: 1.776239]\n",
            "[Epoch 42/50] [Batch 247/600] [D loss: 0.493460] [G loss: 1.729218]\n",
            "[Epoch 42/50] [Batch 248/600] [D loss: 0.369688] [G loss: 1.651898]\n",
            "[Epoch 42/50] [Batch 249/600] [D loss: 0.399980] [G loss: 1.696810]\n",
            "[Epoch 42/50] [Batch 250/600] [D loss: 0.437592] [G loss: 1.725707]\n",
            "[Epoch 42/50] [Batch 251/600] [D loss: 0.442522] [G loss: 1.606972]\n",
            "[Epoch 42/50] [Batch 252/600] [D loss: 0.445419] [G loss: 1.543574]\n",
            "[Epoch 42/50] [Batch 253/600] [D loss: 0.394428] [G loss: 1.714293]\n",
            "[Epoch 42/50] [Batch 254/600] [D loss: 0.354192] [G loss: 1.647971]\n",
            "[Epoch 42/50] [Batch 255/600] [D loss: 0.460022] [G loss: 1.540150]\n",
            "[Epoch 42/50] [Batch 256/600] [D loss: 0.409751] [G loss: 1.673618]\n",
            "[Epoch 42/50] [Batch 257/600] [D loss: 0.406930] [G loss: 1.762623]\n",
            "[Epoch 42/50] [Batch 258/600] [D loss: 0.530183] [G loss: 1.897715]\n",
            "[Epoch 42/50] [Batch 259/600] [D loss: 0.438681] [G loss: 1.867428]\n",
            "[Epoch 42/50] [Batch 260/600] [D loss: 0.476842] [G loss: 1.655048]\n",
            "[Epoch 42/50] [Batch 261/600] [D loss: 0.460152] [G loss: 1.648477]\n",
            "[Epoch 42/50] [Batch 262/600] [D loss: 0.454947] [G loss: 1.641163]\n",
            "[Epoch 42/50] [Batch 263/600] [D loss: 0.449049] [G loss: 1.668232]\n",
            "[Epoch 42/50] [Batch 264/600] [D loss: 0.467344] [G loss: 1.507160]\n",
            "[Epoch 42/50] [Batch 265/600] [D loss: 0.442902] [G loss: 1.595030]\n",
            "[Epoch 42/50] [Batch 266/600] [D loss: 0.357611] [G loss: 1.711655]\n",
            "[Epoch 42/50] [Batch 267/600] [D loss: 0.465874] [G loss: 1.837335]\n",
            "[Epoch 42/50] [Batch 268/600] [D loss: 0.491979] [G loss: 1.658632]\n",
            "[Epoch 42/50] [Batch 269/600] [D loss: 0.472315] [G loss: 1.665711]\n",
            "[Epoch 42/50] [Batch 270/600] [D loss: 0.458486] [G loss: 1.742616]\n",
            "[Epoch 42/50] [Batch 271/600] [D loss: 0.386490] [G loss: 1.927424]\n",
            "[Epoch 42/50] [Batch 272/600] [D loss: 0.350388] [G loss: 1.796817]\n",
            "[Epoch 42/50] [Batch 273/600] [D loss: 0.419785] [G loss: 1.580068]\n",
            "[Epoch 42/50] [Batch 274/600] [D loss: 0.399184] [G loss: 1.570527]\n",
            "[Epoch 42/50] [Batch 275/600] [D loss: 0.484007] [G loss: 1.588572]\n",
            "[Epoch 42/50] [Batch 276/600] [D loss: 0.421513] [G loss: 1.866156]\n",
            "[Epoch 42/50] [Batch 277/600] [D loss: 0.436520] [G loss: 1.987695]\n",
            "[Epoch 42/50] [Batch 278/600] [D loss: 0.471398] [G loss: 1.797475]\n",
            "[Epoch 42/50] [Batch 279/600] [D loss: 0.473942] [G loss: 1.618740]\n",
            "[Epoch 42/50] [Batch 280/600] [D loss: 0.394359] [G loss: 1.517080]\n",
            "[Epoch 42/50] [Batch 281/600] [D loss: 0.449908] [G loss: 1.442823]\n",
            "[Epoch 42/50] [Batch 282/600] [D loss: 0.414474] [G loss: 1.463072]\n",
            "[Epoch 42/50] [Batch 283/600] [D loss: 0.399062] [G loss: 1.570583]\n",
            "[Epoch 42/50] [Batch 284/600] [D loss: 0.425754] [G loss: 1.447678]\n",
            "[Epoch 42/50] [Batch 285/600] [D loss: 0.390215] [G loss: 1.604147]\n",
            "[Epoch 42/50] [Batch 286/600] [D loss: 0.415889] [G loss: 1.750333]\n",
            "[Epoch 42/50] [Batch 287/600] [D loss: 0.474540] [G loss: 1.684701]\n",
            "[Epoch 42/50] [Batch 288/600] [D loss: 0.383158] [G loss: 1.527220]\n",
            "[Epoch 42/50] [Batch 289/600] [D loss: 0.394162] [G loss: 1.600650]\n",
            "[Epoch 42/50] [Batch 290/600] [D loss: 0.503359] [G loss: 1.615453]\n",
            "[Epoch 42/50] [Batch 291/600] [D loss: 0.524557] [G loss: 1.521038]\n",
            "[Epoch 42/50] [Batch 292/600] [D loss: 0.480073] [G loss: 1.459796]\n",
            "[Epoch 42/50] [Batch 293/600] [D loss: 0.466617] [G loss: 1.466066]\n",
            "[Epoch 42/50] [Batch 294/600] [D loss: 0.431006] [G loss: 1.594338]\n",
            "[Epoch 42/50] [Batch 295/600] [D loss: 0.502445] [G loss: 1.572471]\n",
            "[Epoch 42/50] [Batch 296/600] [D loss: 0.386348] [G loss: 1.471892]\n",
            "[Epoch 42/50] [Batch 297/600] [D loss: 0.490913] [G loss: 1.367898]\n",
            "[Epoch 42/50] [Batch 298/600] [D loss: 0.482000] [G loss: 1.499592]\n",
            "[Epoch 42/50] [Batch 299/600] [D loss: 0.444385] [G loss: 1.592381]\n",
            "[Epoch 42/50] [Batch 300/600] [D loss: 0.473830] [G loss: 1.403198]\n",
            "[Epoch 42/50] [Batch 301/600] [D loss: 0.362646] [G loss: 1.587687]\n",
            "[Epoch 42/50] [Batch 302/600] [D loss: 0.471870] [G loss: 1.564303]\n",
            "[Epoch 42/50] [Batch 303/600] [D loss: 0.427115] [G loss: 1.722305]\n",
            "[Epoch 42/50] [Batch 304/600] [D loss: 0.422864] [G loss: 1.531276]\n",
            "[Epoch 42/50] [Batch 305/600] [D loss: 0.423851] [G loss: 1.662300]\n",
            "[Epoch 42/50] [Batch 306/600] [D loss: 0.528621] [G loss: 1.739347]\n",
            "[Epoch 42/50] [Batch 307/600] [D loss: 0.411385] [G loss: 1.462974]\n",
            "[Epoch 42/50] [Batch 308/600] [D loss: 0.451818] [G loss: 1.766239]\n",
            "[Epoch 42/50] [Batch 309/600] [D loss: 0.445855] [G loss: 1.486916]\n",
            "[Epoch 42/50] [Batch 310/600] [D loss: 0.394375] [G loss: 1.611464]\n",
            "[Epoch 42/50] [Batch 311/600] [D loss: 0.435551] [G loss: 1.641623]\n",
            "[Epoch 42/50] [Batch 312/600] [D loss: 0.434464] [G loss: 1.705895]\n",
            "[Epoch 42/50] [Batch 313/600] [D loss: 0.443240] [G loss: 1.502283]\n",
            "[Epoch 42/50] [Batch 314/600] [D loss: 0.430592] [G loss: 1.509238]\n",
            "[Epoch 42/50] [Batch 315/600] [D loss: 0.477438] [G loss: 1.595709]\n",
            "[Epoch 42/50] [Batch 316/600] [D loss: 0.437976] [G loss: 1.660008]\n",
            "[Epoch 42/50] [Batch 317/600] [D loss: 0.498010] [G loss: 1.468061]\n",
            "[Epoch 42/50] [Batch 318/600] [D loss: 0.398233] [G loss: 1.761670]\n",
            "[Epoch 42/50] [Batch 319/600] [D loss: 0.423606] [G loss: 1.655791]\n",
            "[Epoch 42/50] [Batch 320/600] [D loss: 0.495137] [G loss: 1.469633]\n",
            "[Epoch 42/50] [Batch 321/600] [D loss: 0.417113] [G loss: 1.465892]\n",
            "[Epoch 42/50] [Batch 322/600] [D loss: 0.317606] [G loss: 1.840637]\n",
            "[Epoch 42/50] [Batch 323/600] [D loss: 0.410428] [G loss: 1.494915]\n",
            "[Epoch 42/50] [Batch 324/600] [D loss: 0.369171] [G loss: 1.740885]\n",
            "[Epoch 42/50] [Batch 325/600] [D loss: 0.385970] [G loss: 1.757186]\n",
            "[Epoch 42/50] [Batch 326/600] [D loss: 0.423361] [G loss: 2.100535]\n",
            "[Epoch 42/50] [Batch 327/600] [D loss: 0.463701] [G loss: 1.787117]\n",
            "[Epoch 42/50] [Batch 328/600] [D loss: 0.395994] [G loss: 1.695361]\n",
            "[Epoch 42/50] [Batch 329/600] [D loss: 0.375537] [G loss: 1.937073]\n",
            "[Epoch 42/50] [Batch 330/600] [D loss: 0.381025] [G loss: 1.610081]\n",
            "[Epoch 42/50] [Batch 331/600] [D loss: 0.435986] [G loss: 1.886882]\n",
            "[Epoch 42/50] [Batch 332/600] [D loss: 0.401970] [G loss: 1.901508]\n",
            "[Epoch 42/50] [Batch 333/600] [D loss: 0.350944] [G loss: 1.670672]\n",
            "[Epoch 42/50] [Batch 334/600] [D loss: 0.445515] [G loss: 1.750451]\n",
            "[Epoch 42/50] [Batch 335/600] [D loss: 0.503203] [G loss: 1.657854]\n",
            "[Epoch 42/50] [Batch 336/600] [D loss: 0.474083] [G loss: 1.660605]\n",
            "[Epoch 42/50] [Batch 337/600] [D loss: 0.447821] [G loss: 1.593188]\n",
            "[Epoch 42/50] [Batch 338/600] [D loss: 0.425750] [G loss: 1.599445]\n",
            "[Epoch 42/50] [Batch 339/600] [D loss: 0.398077] [G loss: 1.413823]\n",
            "[Epoch 42/50] [Batch 340/600] [D loss: 0.439874] [G loss: 1.881460]\n",
            "[Epoch 42/50] [Batch 341/600] [D loss: 0.389826] [G loss: 1.599936]\n",
            "[Epoch 42/50] [Batch 342/600] [D loss: 0.399595] [G loss: 1.620181]\n",
            "[Epoch 42/50] [Batch 343/600] [D loss: 0.466197] [G loss: 1.792209]\n",
            "[Epoch 42/50] [Batch 344/600] [D loss: 0.382223] [G loss: 1.720198]\n",
            "[Epoch 42/50] [Batch 345/600] [D loss: 0.419534] [G loss: 1.671728]\n",
            "[Epoch 42/50] [Batch 346/600] [D loss: 0.367497] [G loss: 1.729841]\n",
            "[Epoch 42/50] [Batch 347/600] [D loss: 0.499517] [G loss: 1.351770]\n",
            "[Epoch 42/50] [Batch 348/600] [D loss: 0.430565] [G loss: 1.644668]\n",
            "[Epoch 42/50] [Batch 349/600] [D loss: 0.371552] [G loss: 1.664869]\n",
            "[Epoch 42/50] [Batch 350/600] [D loss: 0.433020] [G loss: 1.703436]\n",
            "[Epoch 42/50] [Batch 351/600] [D loss: 0.440946] [G loss: 1.715981]\n",
            "[Epoch 42/50] [Batch 352/600] [D loss: 0.409770] [G loss: 1.728702]\n",
            "[Epoch 42/50] [Batch 353/600] [D loss: 0.383907] [G loss: 1.935004]\n",
            "[Epoch 42/50] [Batch 354/600] [D loss: 0.308063] [G loss: 2.031665]\n",
            "[Epoch 42/50] [Batch 355/600] [D loss: 0.403485] [G loss: 2.241406]\n",
            "[Epoch 42/50] [Batch 356/600] [D loss: 0.387320] [G loss: 2.146071]\n",
            "[Epoch 42/50] [Batch 357/600] [D loss: 0.390163] [G loss: 1.848712]\n",
            "[Epoch 42/50] [Batch 358/600] [D loss: 0.439187] [G loss: 1.856853]\n",
            "[Epoch 42/50] [Batch 359/600] [D loss: 0.456522] [G loss: 1.527290]\n",
            "[Epoch 42/50] [Batch 360/600] [D loss: 0.478653] [G loss: 1.584512]\n",
            "[Epoch 42/50] [Batch 361/600] [D loss: 0.404049] [G loss: 1.735502]\n",
            "[Epoch 42/50] [Batch 362/600] [D loss: 0.415489] [G loss: 1.611822]\n",
            "[Epoch 42/50] [Batch 363/600] [D loss: 0.338921] [G loss: 1.954534]\n",
            "[Epoch 42/50] [Batch 364/600] [D loss: 0.393146] [G loss: 1.752558]\n",
            "[Epoch 42/50] [Batch 365/600] [D loss: 0.436002] [G loss: 1.718518]\n",
            "[Epoch 42/50] [Batch 366/600] [D loss: 0.389134] [G loss: 1.712015]\n",
            "[Epoch 42/50] [Batch 367/600] [D loss: 0.416360] [G loss: 1.870481]\n",
            "[Epoch 42/50] [Batch 368/600] [D loss: 0.483992] [G loss: 2.078434]\n",
            "[Epoch 42/50] [Batch 369/600] [D loss: 0.489874] [G loss: 1.728643]\n",
            "[Epoch 42/50] [Batch 370/600] [D loss: 0.437904] [G loss: 1.741613]\n",
            "[Epoch 42/50] [Batch 371/600] [D loss: 0.423554] [G loss: 1.609440]\n",
            "[Epoch 42/50] [Batch 372/600] [D loss: 0.317321] [G loss: 1.489291]\n",
            "[Epoch 42/50] [Batch 373/600] [D loss: 0.380318] [G loss: 1.680657]\n",
            "[Epoch 42/50] [Batch 374/600] [D loss: 0.435409] [G loss: 1.713162]\n",
            "[Epoch 42/50] [Batch 375/600] [D loss: 0.433968] [G loss: 1.627118]\n",
            "[Epoch 42/50] [Batch 376/600] [D loss: 0.392623] [G loss: 1.514863]\n",
            "[Epoch 42/50] [Batch 377/600] [D loss: 0.377566] [G loss: 1.589730]\n",
            "[Epoch 42/50] [Batch 378/600] [D loss: 0.354882] [G loss: 1.755147]\n",
            "[Epoch 42/50] [Batch 379/600] [D loss: 0.414617] [G loss: 1.787761]\n",
            "[Epoch 42/50] [Batch 380/600] [D loss: 0.389210] [G loss: 1.976259]\n",
            "[Epoch 42/50] [Batch 381/600] [D loss: 0.364957] [G loss: 1.812624]\n",
            "[Epoch 42/50] [Batch 382/600] [D loss: 0.463023] [G loss: 2.216784]\n",
            "[Epoch 42/50] [Batch 383/600] [D loss: 0.449834] [G loss: 2.104821]\n",
            "[Epoch 42/50] [Batch 384/600] [D loss: 0.379061] [G loss: 1.614673]\n",
            "[Epoch 42/50] [Batch 385/600] [D loss: 0.353396] [G loss: 1.846904]\n",
            "[Epoch 42/50] [Batch 386/600] [D loss: 0.377180] [G loss: 1.721145]\n",
            "[Epoch 42/50] [Batch 387/600] [D loss: 0.449030] [G loss: 1.909742]\n",
            "[Epoch 42/50] [Batch 388/600] [D loss: 0.414504] [G loss: 1.776678]\n",
            "[Epoch 42/50] [Batch 389/600] [D loss: 0.462103] [G loss: 1.862114]\n",
            "[Epoch 42/50] [Batch 390/600] [D loss: 0.376337] [G loss: 1.966038]\n",
            "[Epoch 42/50] [Batch 391/600] [D loss: 0.346288] [G loss: 1.897164]\n",
            "[Epoch 42/50] [Batch 392/600] [D loss: 0.326989] [G loss: 1.760814]\n",
            "[Epoch 42/50] [Batch 393/600] [D loss: 0.479407] [G loss: 1.775707]\n",
            "[Epoch 42/50] [Batch 394/600] [D loss: 0.412190] [G loss: 1.517212]\n",
            "[Epoch 42/50] [Batch 395/600] [D loss: 0.408208] [G loss: 1.715606]\n",
            "[Epoch 42/50] [Batch 396/600] [D loss: 0.360120] [G loss: 1.618245]\n",
            "[Epoch 42/50] [Batch 397/600] [D loss: 0.404656] [G loss: 1.673550]\n",
            "[Epoch 42/50] [Batch 398/600] [D loss: 0.455161] [G loss: 1.996985]\n",
            "[Epoch 42/50] [Batch 399/600] [D loss: 0.475667] [G loss: 1.795963]\n",
            "[Epoch 42/50] [Batch 400/600] [D loss: 0.375778] [G loss: 1.594137]\n",
            "[Epoch 42/50] [Batch 401/600] [D loss: 0.359257] [G loss: 1.689686]\n",
            "[Epoch 42/50] [Batch 402/600] [D loss: 0.455201] [G loss: 1.774521]\n",
            "[Epoch 42/50] [Batch 403/600] [D loss: 0.424760] [G loss: 1.795685]\n",
            "[Epoch 42/50] [Batch 404/600] [D loss: 0.353184] [G loss: 1.841576]\n",
            "[Epoch 42/50] [Batch 405/600] [D loss: 0.362242] [G loss: 1.920193]\n",
            "[Epoch 42/50] [Batch 406/600] [D loss: 0.378193] [G loss: 1.918638]\n",
            "[Epoch 42/50] [Batch 407/600] [D loss: 0.366733] [G loss: 1.779821]\n",
            "[Epoch 42/50] [Batch 408/600] [D loss: 0.380304] [G loss: 1.789397]\n",
            "[Epoch 42/50] [Batch 409/600] [D loss: 0.431289] [G loss: 1.987315]\n",
            "[Epoch 42/50] [Batch 410/600] [D loss: 0.407424] [G loss: 1.933412]\n",
            "[Epoch 42/50] [Batch 411/600] [D loss: 0.409118] [G loss: 1.719593]\n",
            "[Epoch 42/50] [Batch 412/600] [D loss: 0.384832] [G loss: 1.826084]\n",
            "[Epoch 42/50] [Batch 413/600] [D loss: 0.404907] [G loss: 1.933697]\n",
            "[Epoch 42/50] [Batch 414/600] [D loss: 0.364049] [G loss: 2.209910]\n",
            "[Epoch 42/50] [Batch 415/600] [D loss: 0.366828] [G loss: 1.854112]\n",
            "[Epoch 42/50] [Batch 416/600] [D loss: 0.430705] [G loss: 1.829437]\n",
            "[Epoch 42/50] [Batch 417/600] [D loss: 0.452742] [G loss: 1.857676]\n",
            "[Epoch 42/50] [Batch 418/600] [D loss: 0.411310] [G loss: 1.589023]\n",
            "[Epoch 42/50] [Batch 419/600] [D loss: 0.457866] [G loss: 1.578858]\n",
            "[Epoch 42/50] [Batch 420/600] [D loss: 0.451516] [G loss: 1.817945]\n",
            "[Epoch 42/50] [Batch 421/600] [D loss: 0.367968] [G loss: 1.994396]\n",
            "[Epoch 42/50] [Batch 422/600] [D loss: 0.367302] [G loss: 1.936834]\n",
            "[Epoch 42/50] [Batch 423/600] [D loss: 0.324207] [G loss: 1.583030]\n",
            "[Epoch 42/50] [Batch 424/600] [D loss: 0.427305] [G loss: 1.853159]\n",
            "[Epoch 42/50] [Batch 425/600] [D loss: 0.489165] [G loss: 1.476912]\n",
            "[Epoch 42/50] [Batch 426/600] [D loss: 0.419356] [G loss: 1.614029]\n",
            "[Epoch 42/50] [Batch 427/600] [D loss: 0.375173] [G loss: 1.514519]\n",
            "[Epoch 42/50] [Batch 428/600] [D loss: 0.464963] [G loss: 1.603354]\n",
            "[Epoch 42/50] [Batch 429/600] [D loss: 0.426668] [G loss: 1.852572]\n",
            "[Epoch 42/50] [Batch 430/600] [D loss: 0.449054] [G loss: 1.744747]\n",
            "[Epoch 42/50] [Batch 431/600] [D loss: 0.415873] [G loss: 1.743172]\n",
            "[Epoch 42/50] [Batch 432/600] [D loss: 0.392630] [G loss: 1.685891]\n",
            "[Epoch 42/50] [Batch 433/600] [D loss: 0.433978] [G loss: 1.727508]\n",
            "[Epoch 42/50] [Batch 434/600] [D loss: 0.384421] [G loss: 1.638954]\n",
            "[Epoch 42/50] [Batch 435/600] [D loss: 0.396832] [G loss: 1.692261]\n",
            "[Epoch 42/50] [Batch 436/600] [D loss: 0.467442] [G loss: 1.909939]\n",
            "[Epoch 42/50] [Batch 437/600] [D loss: 0.484793] [G loss: 1.584661]\n",
            "[Epoch 42/50] [Batch 438/600] [D loss: 0.456229] [G loss: 1.815368]\n",
            "[Epoch 42/50] [Batch 439/600] [D loss: 0.452928] [G loss: 1.550608]\n",
            "[Epoch 42/50] [Batch 440/600] [D loss: 0.491254] [G loss: 1.547752]\n",
            "[Epoch 42/50] [Batch 441/600] [D loss: 0.418060] [G loss: 1.635132]\n",
            "[Epoch 42/50] [Batch 442/600] [D loss: 0.401286] [G loss: 1.824252]\n",
            "[Epoch 42/50] [Batch 443/600] [D loss: 0.360978] [G loss: 1.719700]\n",
            "[Epoch 42/50] [Batch 444/600] [D loss: 0.434597] [G loss: 1.695839]\n",
            "[Epoch 42/50] [Batch 445/600] [D loss: 0.429498] [G loss: 1.804668]\n",
            "[Epoch 42/50] [Batch 446/600] [D loss: 0.427426] [G loss: 1.652063]\n",
            "[Epoch 42/50] [Batch 447/600] [D loss: 0.393680] [G loss: 1.940962]\n",
            "[Epoch 42/50] [Batch 448/600] [D loss: 0.476954] [G loss: 1.526507]\n",
            "[Epoch 42/50] [Batch 449/600] [D loss: 0.397226] [G loss: 1.762135]\n",
            "[Epoch 42/50] [Batch 450/600] [D loss: 0.451482] [G loss: 1.609126]\n",
            "[Epoch 42/50] [Batch 451/600] [D loss: 0.438244] [G loss: 1.559499]\n",
            "[Epoch 42/50] [Batch 452/600] [D loss: 0.413024] [G loss: 1.608885]\n",
            "[Epoch 42/50] [Batch 453/600] [D loss: 0.414617] [G loss: 1.653111]\n",
            "[Epoch 42/50] [Batch 454/600] [D loss: 0.411342] [G loss: 1.793055]\n",
            "[Epoch 42/50] [Batch 455/600] [D loss: 0.420518] [G loss: 1.844858]\n",
            "[Epoch 42/50] [Batch 456/600] [D loss: 0.447438] [G loss: 1.842975]\n",
            "[Epoch 42/50] [Batch 457/600] [D loss: 0.464599] [G loss: 1.817881]\n",
            "[Epoch 42/50] [Batch 458/600] [D loss: 0.504580] [G loss: 1.583593]\n",
            "[Epoch 42/50] [Batch 459/600] [D loss: 0.452874] [G loss: 1.436404]\n",
            "[Epoch 42/50] [Batch 460/600] [D loss: 0.405135] [G loss: 1.857328]\n",
            "[Epoch 42/50] [Batch 461/600] [D loss: 0.460695] [G loss: 1.551700]\n",
            "[Epoch 42/50] [Batch 462/600] [D loss: 0.471375] [G loss: 1.722084]\n",
            "[Epoch 42/50] [Batch 463/600] [D loss: 0.388596] [G loss: 1.693925]\n",
            "[Epoch 42/50] [Batch 464/600] [D loss: 0.422278] [G loss: 1.693215]\n",
            "[Epoch 42/50] [Batch 465/600] [D loss: 0.342912] [G loss: 1.774233]\n",
            "[Epoch 42/50] [Batch 466/600] [D loss: 0.393271] [G loss: 1.603833]\n",
            "[Epoch 42/50] [Batch 467/600] [D loss: 0.381869] [G loss: 1.739583]\n",
            "[Epoch 42/50] [Batch 468/600] [D loss: 0.416483] [G loss: 1.680948]\n",
            "[Epoch 42/50] [Batch 469/600] [D loss: 0.443639] [G loss: 1.768133]\n",
            "[Epoch 42/50] [Batch 470/600] [D loss: 0.391919] [G loss: 1.857564]\n",
            "[Epoch 42/50] [Batch 471/600] [D loss: 0.462537] [G loss: 1.755478]\n",
            "[Epoch 42/50] [Batch 472/600] [D loss: 0.481570] [G loss: 1.820631]\n",
            "[Epoch 42/50] [Batch 473/600] [D loss: 0.494776] [G loss: 1.720030]\n",
            "[Epoch 42/50] [Batch 474/600] [D loss: 0.432805] [G loss: 1.651855]\n",
            "[Epoch 42/50] [Batch 475/600] [D loss: 0.396143] [G loss: 1.598526]\n",
            "[Epoch 42/50] [Batch 476/600] [D loss: 0.371087] [G loss: 1.621424]\n",
            "[Epoch 42/50] [Batch 477/600] [D loss: 0.349512] [G loss: 1.532738]\n",
            "[Epoch 42/50] [Batch 478/600] [D loss: 0.433562] [G loss: 1.683195]\n",
            "[Epoch 42/50] [Batch 479/600] [D loss: 0.366456] [G loss: 1.691893]\n",
            "[Epoch 42/50] [Batch 480/600] [D loss: 0.406993] [G loss: 1.970043]\n",
            "[Epoch 42/50] [Batch 481/600] [D loss: 0.354048] [G loss: 1.548009]\n",
            "[Epoch 42/50] [Batch 482/600] [D loss: 0.396603] [G loss: 1.776373]\n",
            "[Epoch 42/50] [Batch 483/600] [D loss: 0.372123] [G loss: 1.827171]\n",
            "[Epoch 42/50] [Batch 484/600] [D loss: 0.458070] [G loss: 1.697769]\n",
            "[Epoch 42/50] [Batch 485/600] [D loss: 0.422442] [G loss: 1.696968]\n",
            "[Epoch 42/50] [Batch 486/600] [D loss: 0.401637] [G loss: 1.818576]\n",
            "[Epoch 42/50] [Batch 487/600] [D loss: 0.461214] [G loss: 1.725759]\n",
            "[Epoch 42/50] [Batch 488/600] [D loss: 0.339817] [G loss: 1.654143]\n",
            "[Epoch 42/50] [Batch 489/600] [D loss: 0.539202] [G loss: 1.759071]\n",
            "[Epoch 42/50] [Batch 490/600] [D loss: 0.486436] [G loss: 1.569100]\n",
            "[Epoch 42/50] [Batch 491/600] [D loss: 0.447957] [G loss: 1.447568]\n",
            "[Epoch 42/50] [Batch 492/600] [D loss: 0.374085] [G loss: 1.588837]\n",
            "[Epoch 42/50] [Batch 493/600] [D loss: 0.406477] [G loss: 1.654462]\n",
            "[Epoch 42/50] [Batch 494/600] [D loss: 0.449051] [G loss: 1.716316]\n",
            "[Epoch 42/50] [Batch 495/600] [D loss: 0.326953] [G loss: 1.884898]\n",
            "[Epoch 42/50] [Batch 496/600] [D loss: 0.380422] [G loss: 1.630482]\n",
            "[Epoch 42/50] [Batch 497/600] [D loss: 0.391992] [G loss: 1.670162]\n",
            "[Epoch 42/50] [Batch 498/600] [D loss: 0.422758] [G loss: 1.742413]\n",
            "[Epoch 42/50] [Batch 499/600] [D loss: 0.393345] [G loss: 1.778596]\n",
            "[Epoch 42/50] [Batch 500/600] [D loss: 0.377916] [G loss: 1.864072]\n",
            "[Epoch 42/50] [Batch 501/600] [D loss: 0.439173] [G loss: 1.889152]\n",
            "[Epoch 42/50] [Batch 502/600] [D loss: 0.414762] [G loss: 2.043202]\n",
            "[Epoch 42/50] [Batch 503/600] [D loss: 0.409468] [G loss: 1.832678]\n",
            "[Epoch 42/50] [Batch 504/600] [D loss: 0.474560] [G loss: 1.647856]\n",
            "[Epoch 42/50] [Batch 505/600] [D loss: 0.387684] [G loss: 1.854697]\n",
            "[Epoch 42/50] [Batch 506/600] [D loss: 0.413826] [G loss: 1.678828]\n",
            "[Epoch 42/50] [Batch 507/600] [D loss: 0.452726] [G loss: 1.615236]\n",
            "[Epoch 42/50] [Batch 508/600] [D loss: 0.441680] [G loss: 1.733811]\n",
            "[Epoch 42/50] [Batch 509/600] [D loss: 0.387699] [G loss: 1.545552]\n",
            "[Epoch 42/50] [Batch 510/600] [D loss: 0.437862] [G loss: 1.838537]\n",
            "[Epoch 42/50] [Batch 511/600] [D loss: 0.426326] [G loss: 1.868782]\n",
            "[Epoch 42/50] [Batch 512/600] [D loss: 0.493451] [G loss: 1.685306]\n",
            "[Epoch 42/50] [Batch 513/600] [D loss: 0.390636] [G loss: 1.561757]\n",
            "[Epoch 42/50] [Batch 514/600] [D loss: 0.399897] [G loss: 1.709260]\n",
            "[Epoch 42/50] [Batch 515/600] [D loss: 0.399424] [G loss: 2.024781]\n",
            "[Epoch 42/50] [Batch 516/600] [D loss: 0.392093] [G loss: 1.896533]\n",
            "[Epoch 42/50] [Batch 517/600] [D loss: 0.382546] [G loss: 1.732689]\n",
            "[Epoch 42/50] [Batch 518/600] [D loss: 0.407713] [G loss: 1.668191]\n",
            "[Epoch 42/50] [Batch 519/600] [D loss: 0.453510] [G loss: 1.657237]\n",
            "[Epoch 42/50] [Batch 520/600] [D loss: 0.453705] [G loss: 1.694500]\n",
            "[Epoch 42/50] [Batch 521/600] [D loss: 0.405025] [G loss: 1.614160]\n",
            "[Epoch 42/50] [Batch 522/600] [D loss: 0.543038] [G loss: 1.748973]\n",
            "[Epoch 42/50] [Batch 523/600] [D loss: 0.463039] [G loss: 1.872410]\n",
            "[Epoch 42/50] [Batch 524/600] [D loss: 0.435198] [G loss: 1.799248]\n",
            "[Epoch 42/50] [Batch 525/600] [D loss: 0.392877] [G loss: 1.748808]\n",
            "[Epoch 42/50] [Batch 526/600] [D loss: 0.372082] [G loss: 1.711900]\n",
            "[Epoch 42/50] [Batch 527/600] [D loss: 0.402085] [G loss: 1.849356]\n",
            "[Epoch 42/50] [Batch 528/600] [D loss: 0.431193] [G loss: 1.611230]\n",
            "[Epoch 42/50] [Batch 529/600] [D loss: 0.457793] [G loss: 1.753173]\n",
            "[Epoch 42/50] [Batch 530/600] [D loss: 0.480261] [G loss: 1.613461]\n",
            "[Epoch 42/50] [Batch 531/600] [D loss: 0.419429] [G loss: 1.604759]\n",
            "[Epoch 42/50] [Batch 532/600] [D loss: 0.383629] [G loss: 1.692546]\n",
            "[Epoch 42/50] [Batch 533/600] [D loss: 0.372974] [G loss: 1.650129]\n",
            "[Epoch 42/50] [Batch 534/600] [D loss: 0.407301] [G loss: 1.811558]\n",
            "[Epoch 42/50] [Batch 535/600] [D loss: 0.368135] [G loss: 1.653857]\n",
            "[Epoch 42/50] [Batch 536/600] [D loss: 0.440809] [G loss: 1.668809]\n",
            "[Epoch 42/50] [Batch 537/600] [D loss: 0.431368] [G loss: 1.769060]\n",
            "[Epoch 42/50] [Batch 538/600] [D loss: 0.395934] [G loss: 1.661304]\n",
            "[Epoch 42/50] [Batch 539/600] [D loss: 0.455677] [G loss: 1.528220]\n",
            "[Epoch 42/50] [Batch 540/600] [D loss: 0.441858] [G loss: 1.938387]\n",
            "[Epoch 42/50] [Batch 541/600] [D loss: 0.434034] [G loss: 1.407493]\n",
            "[Epoch 42/50] [Batch 542/600] [D loss: 0.414327] [G loss: 1.572528]\n",
            "[Epoch 42/50] [Batch 543/600] [D loss: 0.495685] [G loss: 1.588240]\n",
            "[Epoch 42/50] [Batch 544/600] [D loss: 0.434137] [G loss: 1.938715]\n",
            "[Epoch 42/50] [Batch 545/600] [D loss: 0.433740] [G loss: 1.778604]\n",
            "[Epoch 42/50] [Batch 546/600] [D loss: 0.437117] [G loss: 1.567194]\n",
            "[Epoch 42/50] [Batch 547/600] [D loss: 0.432834] [G loss: 1.588405]\n",
            "[Epoch 42/50] [Batch 548/600] [D loss: 0.349787] [G loss: 1.770410]\n",
            "[Epoch 42/50] [Batch 549/600] [D loss: 0.469429] [G loss: 1.825581]\n",
            "[Epoch 42/50] [Batch 550/600] [D loss: 0.438886] [G loss: 1.666661]\n",
            "[Epoch 42/50] [Batch 551/600] [D loss: 0.374123] [G loss: 1.514603]\n",
            "[Epoch 42/50] [Batch 552/600] [D loss: 0.468829] [G loss: 1.686266]\n",
            "[Epoch 42/50] [Batch 553/600] [D loss: 0.424206] [G loss: 1.936568]\n",
            "[Epoch 42/50] [Batch 554/600] [D loss: 0.450144] [G loss: 1.854956]\n",
            "[Epoch 42/50] [Batch 555/600] [D loss: 0.377061] [G loss: 1.551413]\n",
            "[Epoch 42/50] [Batch 556/600] [D loss: 0.422898] [G loss: 1.794307]\n",
            "[Epoch 42/50] [Batch 557/600] [D loss: 0.412393] [G loss: 1.619659]\n",
            "[Epoch 42/50] [Batch 558/600] [D loss: 0.433428] [G loss: 1.499606]\n",
            "[Epoch 42/50] [Batch 559/600] [D loss: 0.387609] [G loss: 1.702787]\n",
            "[Epoch 42/50] [Batch 560/600] [D loss: 0.479358] [G loss: 1.708867]\n",
            "[Epoch 42/50] [Batch 561/600] [D loss: 0.391583] [G loss: 1.721393]\n",
            "[Epoch 42/50] [Batch 562/600] [D loss: 0.430028] [G loss: 1.624655]\n",
            "[Epoch 42/50] [Batch 563/600] [D loss: 0.500759] [G loss: 1.674263]\n",
            "[Epoch 42/50] [Batch 564/600] [D loss: 0.478552] [G loss: 1.476634]\n",
            "[Epoch 42/50] [Batch 565/600] [D loss: 0.412922] [G loss: 1.635743]\n",
            "[Epoch 42/50] [Batch 566/600] [D loss: 0.362287] [G loss: 1.593300]\n",
            "[Epoch 42/50] [Batch 567/600] [D loss: 0.369149] [G loss: 1.706760]\n",
            "[Epoch 42/50] [Batch 568/600] [D loss: 0.442670] [G loss: 1.558563]\n",
            "[Epoch 42/50] [Batch 569/600] [D loss: 0.413041] [G loss: 1.585304]\n",
            "[Epoch 42/50] [Batch 570/600] [D loss: 0.463538] [G loss: 1.593218]\n",
            "[Epoch 42/50] [Batch 571/600] [D loss: 0.406855] [G loss: 1.662764]\n",
            "[Epoch 42/50] [Batch 572/600] [D loss: 0.482448] [G loss: 1.819101]\n",
            "[Epoch 42/50] [Batch 573/600] [D loss: 0.436648] [G loss: 1.782284]\n",
            "[Epoch 42/50] [Batch 574/600] [D loss: 0.395340] [G loss: 1.942386]\n",
            "[Epoch 42/50] [Batch 575/600] [D loss: 0.378505] [G loss: 2.007989]\n",
            "[Epoch 42/50] [Batch 576/600] [D loss: 0.418541] [G loss: 2.024904]\n",
            "[Epoch 42/50] [Batch 577/600] [D loss: 0.450258] [G loss: 1.855941]\n",
            "[Epoch 42/50] [Batch 578/600] [D loss: 0.413940] [G loss: 1.954807]\n",
            "[Epoch 42/50] [Batch 579/600] [D loss: 0.337179] [G loss: 1.867935]\n",
            "[Epoch 42/50] [Batch 580/600] [D loss: 0.395193] [G loss: 1.859898]\n",
            "[Epoch 42/50] [Batch 581/600] [D loss: 0.326369] [G loss: 1.806282]\n",
            "[Epoch 42/50] [Batch 582/600] [D loss: 0.406196] [G loss: 1.932035]\n",
            "[Epoch 42/50] [Batch 583/600] [D loss: 0.355010] [G loss: 1.895167]\n",
            "[Epoch 42/50] [Batch 584/600] [D loss: 0.385075] [G loss: 1.978866]\n",
            "[Epoch 42/50] [Batch 585/600] [D loss: 0.461539] [G loss: 1.862490]\n",
            "[Epoch 42/50] [Batch 586/600] [D loss: 0.457944] [G loss: 1.971855]\n",
            "[Epoch 42/50] [Batch 587/600] [D loss: 0.382439] [G loss: 1.732405]\n",
            "[Epoch 42/50] [Batch 588/600] [D loss: 0.426613] [G loss: 1.821418]\n",
            "[Epoch 42/50] [Batch 589/600] [D loss: 0.390557] [G loss: 1.689904]\n",
            "[Epoch 42/50] [Batch 590/600] [D loss: 0.375206] [G loss: 1.963727]\n",
            "[Epoch 42/50] [Batch 591/600] [D loss: 0.315499] [G loss: 1.953995]\n",
            "[Epoch 42/50] [Batch 592/600] [D loss: 0.413760] [G loss: 1.944630]\n",
            "[Epoch 42/50] [Batch 593/600] [D loss: 0.460379] [G loss: 1.830139]\n",
            "[Epoch 42/50] [Batch 594/600] [D loss: 0.432350] [G loss: 1.637279]\n",
            "[Epoch 42/50] [Batch 595/600] [D loss: 0.419754] [G loss: 1.504666]\n",
            "[Epoch 42/50] [Batch 596/600] [D loss: 0.346108] [G loss: 1.769534]\n",
            "[Epoch 42/50] [Batch 597/600] [D loss: 0.415707] [G loss: 1.824566]\n",
            "[Epoch 42/50] [Batch 598/600] [D loss: 0.470925] [G loss: 1.703504]\n",
            "[Epoch 42/50] [Batch 599/600] [D loss: 0.425306] [G loss: 1.867113]\n",
            "[Epoch 43/50] [Batch 0/600] [D loss: 0.436075] [G loss: 1.867044]\n",
            "[Epoch 43/50] [Batch 1/600] [D loss: 0.420725] [G loss: 1.884798]\n",
            "[Epoch 43/50] [Batch 2/600] [D loss: 0.409604] [G loss: 1.678870]\n",
            "[Epoch 43/50] [Batch 3/600] [D loss: 0.472398] [G loss: 1.539031]\n",
            "[Epoch 43/50] [Batch 4/600] [D loss: 0.391769] [G loss: 1.791505]\n",
            "[Epoch 43/50] [Batch 5/600] [D loss: 0.353779] [G loss: 1.606563]\n",
            "[Epoch 43/50] [Batch 6/600] [D loss: 0.381881] [G loss: 1.760803]\n",
            "[Epoch 43/50] [Batch 7/600] [D loss: 0.408547] [G loss: 1.632741]\n",
            "[Epoch 43/50] [Batch 8/600] [D loss: 0.404623] [G loss: 1.703890]\n",
            "[Epoch 43/50] [Batch 9/600] [D loss: 0.311956] [G loss: 1.715655]\n",
            "[Epoch 43/50] [Batch 10/600] [D loss: 0.495960] [G loss: 1.659170]\n",
            "[Epoch 43/50] [Batch 11/600] [D loss: 0.433633] [G loss: 1.613109]\n",
            "[Epoch 43/50] [Batch 12/600] [D loss: 0.465437] [G loss: 1.751092]\n",
            "[Epoch 43/50] [Batch 13/600] [D loss: 0.472577] [G loss: 1.473956]\n",
            "[Epoch 43/50] [Batch 14/600] [D loss: 0.441406] [G loss: 1.564867]\n",
            "[Epoch 43/50] [Batch 15/600] [D loss: 0.355236] [G loss: 1.675203]\n",
            "[Epoch 43/50] [Batch 16/600] [D loss: 0.388787] [G loss: 1.657052]\n",
            "[Epoch 43/50] [Batch 17/600] [D loss: 0.407682] [G loss: 1.777545]\n",
            "[Epoch 43/50] [Batch 18/600] [D loss: 0.441007] [G loss: 1.577365]\n",
            "[Epoch 43/50] [Batch 19/600] [D loss: 0.493628] [G loss: 1.609841]\n",
            "[Epoch 43/50] [Batch 20/600] [D loss: 0.423624] [G loss: 1.457900]\n",
            "[Epoch 43/50] [Batch 21/600] [D loss: 0.361605] [G loss: 1.621260]\n",
            "[Epoch 43/50] [Batch 22/600] [D loss: 0.379070] [G loss: 1.925192]\n",
            "[Epoch 43/50] [Batch 23/600] [D loss: 0.402314] [G loss: 1.740027]\n",
            "[Epoch 43/50] [Batch 24/600] [D loss: 0.386866] [G loss: 1.580004]\n",
            "[Epoch 43/50] [Batch 25/600] [D loss: 0.452417] [G loss: 1.765518]\n",
            "[Epoch 43/50] [Batch 26/600] [D loss: 0.471086] [G loss: 1.855533]\n",
            "[Epoch 43/50] [Batch 27/600] [D loss: 0.382509] [G loss: 1.987115]\n",
            "[Epoch 43/50] [Batch 28/600] [D loss: 0.357889] [G loss: 1.985634]\n",
            "[Epoch 43/50] [Batch 29/600] [D loss: 0.437762] [G loss: 1.858906]\n",
            "[Epoch 43/50] [Batch 30/600] [D loss: 0.452150] [G loss: 1.882652]\n",
            "[Epoch 43/50] [Batch 31/600] [D loss: 0.386375] [G loss: 1.436897]\n",
            "[Epoch 43/50] [Batch 32/600] [D loss: 0.473875] [G loss: 1.539495]\n",
            "[Epoch 43/50] [Batch 33/600] [D loss: 0.418058] [G loss: 1.816108]\n",
            "[Epoch 43/50] [Batch 34/600] [D loss: 0.380522] [G loss: 1.908551]\n",
            "[Epoch 43/50] [Batch 35/600] [D loss: 0.343929] [G loss: 1.910119]\n",
            "[Epoch 43/50] [Batch 36/600] [D loss: 0.436007] [G loss: 1.754952]\n",
            "[Epoch 43/50] [Batch 37/600] [D loss: 0.389212] [G loss: 1.997598]\n",
            "[Epoch 43/50] [Batch 38/600] [D loss: 0.437372] [G loss: 1.814675]\n",
            "[Epoch 43/50] [Batch 39/600] [D loss: 0.427451] [G loss: 1.786660]\n",
            "[Epoch 43/50] [Batch 40/600] [D loss: 0.473159] [G loss: 1.646137]\n",
            "[Epoch 43/50] [Batch 41/600] [D loss: 0.369522] [G loss: 1.790888]\n",
            "[Epoch 43/50] [Batch 42/600] [D loss: 0.435356] [G loss: 1.749282]\n",
            "[Epoch 43/50] [Batch 43/600] [D loss: 0.445876] [G loss: 1.783017]\n",
            "[Epoch 43/50] [Batch 44/600] [D loss: 0.363357] [G loss: 1.766670]\n",
            "[Epoch 43/50] [Batch 45/600] [D loss: 0.412934] [G loss: 1.604043]\n",
            "[Epoch 43/50] [Batch 46/600] [D loss: 0.356901] [G loss: 1.578469]\n",
            "[Epoch 43/50] [Batch 47/600] [D loss: 0.380198] [G loss: 1.745988]\n",
            "[Epoch 43/50] [Batch 48/600] [D loss: 0.384525] [G loss: 1.828596]\n",
            "[Epoch 43/50] [Batch 49/600] [D loss: 0.357258] [G loss: 2.113542]\n",
            "[Epoch 43/50] [Batch 50/600] [D loss: 0.374515] [G loss: 2.168606]\n",
            "[Epoch 43/50] [Batch 51/600] [D loss: 0.391963] [G loss: 2.258291]\n",
            "[Epoch 43/50] [Batch 52/600] [D loss: 0.413772] [G loss: 1.630388]\n",
            "[Epoch 43/50] [Batch 53/600] [D loss: 0.414689] [G loss: 1.694340]\n",
            "[Epoch 43/50] [Batch 54/600] [D loss: 0.336910] [G loss: 1.960650]\n",
            "[Epoch 43/50] [Batch 55/600] [D loss: 0.434133] [G loss: 1.871354]\n",
            "[Epoch 43/50] [Batch 56/600] [D loss: 0.297984] [G loss: 2.098335]\n",
            "[Epoch 43/50] [Batch 57/600] [D loss: 0.509008] [G loss: 1.929382]\n",
            "[Epoch 43/50] [Batch 58/600] [D loss: 0.458686] [G loss: 1.818005]\n",
            "[Epoch 43/50] [Batch 59/600] [D loss: 0.321134] [G loss: 1.927122]\n",
            "[Epoch 43/50] [Batch 60/600] [D loss: 0.347845] [G loss: 1.802692]\n",
            "[Epoch 43/50] [Batch 61/600] [D loss: 0.322701] [G loss: 1.800341]\n",
            "[Epoch 43/50] [Batch 62/600] [D loss: 0.372475] [G loss: 2.024602]\n",
            "[Epoch 43/50] [Batch 63/600] [D loss: 0.357486] [G loss: 2.053098]\n",
            "[Epoch 43/50] [Batch 64/600] [D loss: 0.385890] [G loss: 1.893803]\n",
            "[Epoch 43/50] [Batch 65/600] [D loss: 0.377446] [G loss: 2.233495]\n",
            "[Epoch 43/50] [Batch 66/600] [D loss: 0.489825] [G loss: 2.141602]\n",
            "[Epoch 43/50] [Batch 67/600] [D loss: 0.446028] [G loss: 2.019458]\n",
            "[Epoch 43/50] [Batch 68/600] [D loss: 0.491550] [G loss: 1.733910]\n",
            "[Epoch 43/50] [Batch 69/600] [D loss: 0.391067] [G loss: 1.614544]\n",
            "[Epoch 43/50] [Batch 70/600] [D loss: 0.385438] [G loss: 1.639764]\n",
            "[Epoch 43/50] [Batch 71/600] [D loss: 0.444777] [G loss: 1.502203]\n",
            "[Epoch 43/50] [Batch 72/600] [D loss: 0.507358] [G loss: 1.885558]\n",
            "[Epoch 43/50] [Batch 73/600] [D loss: 0.464181] [G loss: 1.682378]\n",
            "[Epoch 43/50] [Batch 74/600] [D loss: 0.423862] [G loss: 1.826216]\n",
            "[Epoch 43/50] [Batch 75/600] [D loss: 0.480407] [G loss: 1.854835]\n",
            "[Epoch 43/50] [Batch 76/600] [D loss: 0.462388] [G loss: 1.561314]\n",
            "[Epoch 43/50] [Batch 77/600] [D loss: 0.384576] [G loss: 1.545393]\n",
            "[Epoch 43/50] [Batch 78/600] [D loss: 0.345578] [G loss: 1.835207]\n",
            "[Epoch 43/50] [Batch 79/600] [D loss: 0.358601] [G loss: 1.850899]\n",
            "[Epoch 43/50] [Batch 80/600] [D loss: 0.351494] [G loss: 1.725384]\n",
            "[Epoch 43/50] [Batch 81/600] [D loss: 0.379680] [G loss: 1.862352]\n",
            "[Epoch 43/50] [Batch 82/600] [D loss: 0.421706] [G loss: 1.798654]\n",
            "[Epoch 43/50] [Batch 83/600] [D loss: 0.403589] [G loss: 1.807078]\n",
            "[Epoch 43/50] [Batch 84/600] [D loss: 0.549129] [G loss: 1.626459]\n",
            "[Epoch 43/50] [Batch 85/600] [D loss: 0.361861] [G loss: 1.631974]\n",
            "[Epoch 43/50] [Batch 86/600] [D loss: 0.447661] [G loss: 1.554113]\n",
            "[Epoch 43/50] [Batch 87/600] [D loss: 0.424713] [G loss: 1.865449]\n",
            "[Epoch 43/50] [Batch 88/600] [D loss: 0.452517] [G loss: 1.568564]\n",
            "[Epoch 43/50] [Batch 89/600] [D loss: 0.428120] [G loss: 1.546111]\n",
            "[Epoch 43/50] [Batch 90/600] [D loss: 0.387021] [G loss: 1.893034]\n",
            "[Epoch 43/50] [Batch 91/600] [D loss: 0.493536] [G loss: 1.897219]\n",
            "[Epoch 43/50] [Batch 92/600] [D loss: 0.493651] [G loss: 1.749136]\n",
            "[Epoch 43/50] [Batch 93/600] [D loss: 0.384528] [G loss: 1.723518]\n",
            "[Epoch 43/50] [Batch 94/600] [D loss: 0.408730] [G loss: 1.345803]\n",
            "[Epoch 43/50] [Batch 95/600] [D loss: 0.417019] [G loss: 1.597312]\n",
            "[Epoch 43/50] [Batch 96/600] [D loss: 0.437129] [G loss: 1.679637]\n",
            "[Epoch 43/50] [Batch 97/600] [D loss: 0.442640] [G loss: 1.706514]\n",
            "[Epoch 43/50] [Batch 98/600] [D loss: 0.345500] [G loss: 1.709660]\n",
            "[Epoch 43/50] [Batch 99/600] [D loss: 0.444485] [G loss: 1.736790]\n",
            "[Epoch 43/50] [Batch 100/600] [D loss: 0.442355] [G loss: 1.793467]\n",
            "[Epoch 43/50] [Batch 101/600] [D loss: 0.465780] [G loss: 1.836490]\n",
            "[Epoch 43/50] [Batch 102/600] [D loss: 0.387489] [G loss: 1.690530]\n",
            "[Epoch 43/50] [Batch 103/600] [D loss: 0.366237] [G loss: 2.062359]\n",
            "[Epoch 43/50] [Batch 104/600] [D loss: 0.470613] [G loss: 1.707090]\n",
            "[Epoch 43/50] [Batch 105/600] [D loss: 0.379487] [G loss: 1.795662]\n",
            "[Epoch 43/50] [Batch 106/600] [D loss: 0.446292] [G loss: 1.982140]\n",
            "[Epoch 43/50] [Batch 107/600] [D loss: 0.395540] [G loss: 1.631269]\n",
            "[Epoch 43/50] [Batch 108/600] [D loss: 0.393091] [G loss: 1.786622]\n",
            "[Epoch 43/50] [Batch 109/600] [D loss: 0.364821] [G loss: 1.703583]\n",
            "[Epoch 43/50] [Batch 110/600] [D loss: 0.401027] [G loss: 1.769599]\n",
            "[Epoch 43/50] [Batch 111/600] [D loss: 0.462821] [G loss: 1.724712]\n",
            "[Epoch 43/50] [Batch 112/600] [D loss: 0.423601] [G loss: 1.754249]\n",
            "[Epoch 43/50] [Batch 113/600] [D loss: 0.406983] [G loss: 1.644399]\n",
            "[Epoch 43/50] [Batch 114/600] [D loss: 0.472208] [G loss: 1.769921]\n",
            "[Epoch 43/50] [Batch 115/600] [D loss: 0.438481] [G loss: 1.794312]\n",
            "[Epoch 43/50] [Batch 116/600] [D loss: 0.439948] [G loss: 1.527663]\n",
            "[Epoch 43/50] [Batch 117/600] [D loss: 0.392051] [G loss: 1.954661]\n",
            "[Epoch 43/50] [Batch 118/600] [D loss: 0.469032] [G loss: 1.513973]\n",
            "[Epoch 43/50] [Batch 119/600] [D loss: 0.520940] [G loss: 1.629741]\n",
            "[Epoch 43/50] [Batch 120/600] [D loss: 0.420752] [G loss: 1.635426]\n",
            "[Epoch 43/50] [Batch 121/600] [D loss: 0.396950] [G loss: 1.661402]\n",
            "[Epoch 43/50] [Batch 122/600] [D loss: 0.412647] [G loss: 1.503827]\n",
            "[Epoch 43/50] [Batch 123/600] [D loss: 0.418033] [G loss: 1.745803]\n",
            "[Epoch 43/50] [Batch 124/600] [D loss: 0.413889] [G loss: 1.828080]\n",
            "[Epoch 43/50] [Batch 125/600] [D loss: 0.472355] [G loss: 1.634041]\n",
            "[Epoch 43/50] [Batch 126/600] [D loss: 0.414872] [G loss: 1.617434]\n",
            "[Epoch 43/50] [Batch 127/600] [D loss: 0.431542] [G loss: 1.647741]\n",
            "[Epoch 43/50] [Batch 128/600] [D loss: 0.476576] [G loss: 1.670251]\n",
            "[Epoch 43/50] [Batch 129/600] [D loss: 0.344055] [G loss: 1.622981]\n",
            "[Epoch 43/50] [Batch 130/600] [D loss: 0.412938] [G loss: 1.666675]\n",
            "[Epoch 43/50] [Batch 131/600] [D loss: 0.358038] [G loss: 1.958710]\n",
            "[Epoch 43/50] [Batch 132/600] [D loss: 0.328527] [G loss: 2.018008]\n",
            "[Epoch 43/50] [Batch 133/600] [D loss: 0.431249] [G loss: 1.786148]\n",
            "[Epoch 43/50] [Batch 134/600] [D loss: 0.382419] [G loss: 1.846995]\n",
            "[Epoch 43/50] [Batch 135/600] [D loss: 0.426366] [G loss: 1.600348]\n",
            "[Epoch 43/50] [Batch 136/600] [D loss: 0.449303] [G loss: 1.520313]\n",
            "[Epoch 43/50] [Batch 137/600] [D loss: 0.464414] [G loss: 1.883624]\n",
            "[Epoch 43/50] [Batch 138/600] [D loss: 0.442361] [G loss: 1.894092]\n",
            "[Epoch 43/50] [Batch 139/600] [D loss: 0.394010] [G loss: 1.863564]\n",
            "[Epoch 43/50] [Batch 140/600] [D loss: 0.391330] [G loss: 1.798167]\n",
            "[Epoch 43/50] [Batch 141/600] [D loss: 0.315322] [G loss: 1.992087]\n",
            "[Epoch 43/50] [Batch 142/600] [D loss: 0.395418] [G loss: 1.748122]\n",
            "[Epoch 43/50] [Batch 143/600] [D loss: 0.394202] [G loss: 1.766340]\n",
            "[Epoch 43/50] [Batch 144/600] [D loss: 0.421466] [G loss: 1.814641]\n",
            "[Epoch 43/50] [Batch 145/600] [D loss: 0.507347] [G loss: 1.714172]\n",
            "[Epoch 43/50] [Batch 146/600] [D loss: 0.459000] [G loss: 1.822822]\n",
            "[Epoch 43/50] [Batch 147/600] [D loss: 0.447691] [G loss: 1.731647]\n",
            "[Epoch 43/50] [Batch 148/600] [D loss: 0.375790] [G loss: 1.793893]\n",
            "[Epoch 43/50] [Batch 149/600] [D loss: 0.426821] [G loss: 1.853403]\n",
            "[Epoch 43/50] [Batch 150/600] [D loss: 0.441090] [G loss: 1.953531]\n",
            "[Epoch 43/50] [Batch 151/600] [D loss: 0.393915] [G loss: 1.995367]\n",
            "[Epoch 43/50] [Batch 152/600] [D loss: 0.451500] [G loss: 1.719777]\n",
            "[Epoch 43/50] [Batch 153/600] [D loss: 0.442084] [G loss: 1.708907]\n",
            "[Epoch 43/50] [Batch 154/600] [D loss: 0.443007] [G loss: 1.641948]\n",
            "[Epoch 43/50] [Batch 155/600] [D loss: 0.341119] [G loss: 1.859900]\n",
            "[Epoch 43/50] [Batch 156/600] [D loss: 0.413112] [G loss: 1.778569]\n",
            "[Epoch 43/50] [Batch 157/600] [D loss: 0.421601] [G loss: 1.882465]\n",
            "[Epoch 43/50] [Batch 158/600] [D loss: 0.400008] [G loss: 1.573478]\n",
            "[Epoch 43/50] [Batch 159/600] [D loss: 0.418073] [G loss: 1.789906]\n",
            "[Epoch 43/50] [Batch 160/600] [D loss: 0.456513] [G loss: 1.807215]\n",
            "[Epoch 43/50] [Batch 161/600] [D loss: 0.443742] [G loss: 1.602337]\n",
            "[Epoch 43/50] [Batch 162/600] [D loss: 0.359967] [G loss: 1.550807]\n",
            "[Epoch 43/50] [Batch 163/600] [D loss: 0.477217] [G loss: 1.914172]\n",
            "[Epoch 43/50] [Batch 164/600] [D loss: 0.404256] [G loss: 1.775402]\n",
            "[Epoch 43/50] [Batch 165/600] [D loss: 0.394002] [G loss: 1.630487]\n",
            "[Epoch 43/50] [Batch 166/600] [D loss: 0.417572] [G loss: 1.868914]\n",
            "[Epoch 43/50] [Batch 167/600] [D loss: 0.394863] [G loss: 1.763525]\n",
            "[Epoch 43/50] [Batch 168/600] [D loss: 0.434477] [G loss: 1.705420]\n",
            "[Epoch 43/50] [Batch 169/600] [D loss: 0.499024] [G loss: 1.538310]\n",
            "[Epoch 43/50] [Batch 170/600] [D loss: 0.398332] [G loss: 1.831469]\n",
            "[Epoch 43/50] [Batch 171/600] [D loss: 0.374774] [G loss: 1.657804]\n",
            "[Epoch 43/50] [Batch 172/600] [D loss: 0.404457] [G loss: 1.599006]\n",
            "[Epoch 43/50] [Batch 173/600] [D loss: 0.444924] [G loss: 1.479602]\n",
            "[Epoch 43/50] [Batch 174/600] [D loss: 0.412831] [G loss: 1.974551]\n",
            "[Epoch 43/50] [Batch 175/600] [D loss: 0.422987] [G loss: 2.070374]\n",
            "[Epoch 43/50] [Batch 176/600] [D loss: 0.429098] [G loss: 1.769625]\n",
            "[Epoch 43/50] [Batch 177/600] [D loss: 0.478777] [G loss: 1.455075]\n",
            "[Epoch 43/50] [Batch 178/600] [D loss: 0.460216] [G loss: 1.569734]\n",
            "[Epoch 43/50] [Batch 179/600] [D loss: 0.452495] [G loss: 1.692827]\n",
            "[Epoch 43/50] [Batch 180/600] [D loss: 0.448751] [G loss: 1.495049]\n",
            "[Epoch 43/50] [Batch 181/600] [D loss: 0.424467] [G loss: 1.880036]\n",
            "[Epoch 43/50] [Batch 182/600] [D loss: 0.446342] [G loss: 1.883800]\n",
            "[Epoch 43/50] [Batch 183/600] [D loss: 0.412371] [G loss: 1.768639]\n",
            "[Epoch 43/50] [Batch 184/600] [D loss: 0.464371] [G loss: 1.669506]\n",
            "[Epoch 43/50] [Batch 185/600] [D loss: 0.446554] [G loss: 1.615745]\n",
            "[Epoch 43/50] [Batch 186/600] [D loss: 0.433338] [G loss: 1.580770]\n",
            "[Epoch 43/50] [Batch 187/600] [D loss: 0.450921] [G loss: 1.557656]\n",
            "[Epoch 43/50] [Batch 188/600] [D loss: 0.405855] [G loss: 1.515587]\n",
            "[Epoch 43/50] [Batch 189/600] [D loss: 0.411883] [G loss: 1.773984]\n",
            "[Epoch 43/50] [Batch 190/600] [D loss: 0.401803] [G loss: 1.793307]\n",
            "[Epoch 43/50] [Batch 191/600] [D loss: 0.423982] [G loss: 1.865395]\n",
            "[Epoch 43/50] [Batch 192/600] [D loss: 0.462703] [G loss: 1.731127]\n",
            "[Epoch 43/50] [Batch 193/600] [D loss: 0.402556] [G loss: 1.594508]\n",
            "[Epoch 43/50] [Batch 194/600] [D loss: 0.390178] [G loss: 1.521928]\n",
            "[Epoch 43/50] [Batch 195/600] [D loss: 0.352219] [G loss: 1.800127]\n",
            "[Epoch 43/50] [Batch 196/600] [D loss: 0.390358] [G loss: 1.558106]\n",
            "[Epoch 43/50] [Batch 197/600] [D loss: 0.423162] [G loss: 1.799320]\n",
            "[Epoch 43/50] [Batch 198/600] [D loss: 0.419523] [G loss: 1.650975]\n",
            "[Epoch 43/50] [Batch 199/600] [D loss: 0.346440] [G loss: 1.821288]\n",
            "[Epoch 43/50] [Batch 200/600] [D loss: 0.441917] [G loss: 1.723257]\n",
            "[Epoch 43/50] [Batch 201/600] [D loss: 0.368337] [G loss: 1.793473]\n",
            "[Epoch 43/50] [Batch 202/600] [D loss: 0.520974] [G loss: 1.897557]\n",
            "[Epoch 43/50] [Batch 203/600] [D loss: 0.426089] [G loss: 1.802428]\n",
            "[Epoch 43/50] [Batch 204/600] [D loss: 0.329825] [G loss: 1.713318]\n",
            "[Epoch 43/50] [Batch 205/600] [D loss: 0.471312] [G loss: 1.713089]\n",
            "[Epoch 43/50] [Batch 206/600] [D loss: 0.459955] [G loss: 1.791477]\n",
            "[Epoch 43/50] [Batch 207/600] [D loss: 0.426277] [G loss: 1.694081]\n",
            "[Epoch 43/50] [Batch 208/600] [D loss: 0.359020] [G loss: 1.784079]\n",
            "[Epoch 43/50] [Batch 209/600] [D loss: 0.373072] [G loss: 1.585096]\n",
            "[Epoch 43/50] [Batch 210/600] [D loss: 0.392699] [G loss: 1.702941]\n",
            "[Epoch 43/50] [Batch 211/600] [D loss: 0.406910] [G loss: 1.792665]\n",
            "[Epoch 43/50] [Batch 212/600] [D loss: 0.369867] [G loss: 1.890715]\n",
            "[Epoch 43/50] [Batch 213/600] [D loss: 0.452048] [G loss: 1.931653]\n",
            "[Epoch 43/50] [Batch 214/600] [D loss: 0.372960] [G loss: 1.879119]\n",
            "[Epoch 43/50] [Batch 215/600] [D loss: 0.442692] [G loss: 1.740976]\n",
            "[Epoch 43/50] [Batch 216/600] [D loss: 0.361606] [G loss: 2.036009]\n",
            "[Epoch 43/50] [Batch 217/600] [D loss: 0.388813] [G loss: 1.603350]\n",
            "[Epoch 43/50] [Batch 218/600] [D loss: 0.383907] [G loss: 1.892808]\n",
            "[Epoch 43/50] [Batch 219/600] [D loss: 0.358991] [G loss: 1.464206]\n",
            "[Epoch 43/50] [Batch 220/600] [D loss: 0.352469] [G loss: 1.765256]\n",
            "[Epoch 43/50] [Batch 221/600] [D loss: 0.339388] [G loss: 2.109543]\n",
            "[Epoch 43/50] [Batch 222/600] [D loss: 0.472640] [G loss: 2.108149]\n",
            "[Epoch 43/50] [Batch 223/600] [D loss: 0.382834] [G loss: 1.808465]\n",
            "[Epoch 43/50] [Batch 224/600] [D loss: 0.424778] [G loss: 1.839695]\n",
            "[Epoch 43/50] [Batch 225/600] [D loss: 0.462462] [G loss: 1.776370]\n",
            "[Epoch 43/50] [Batch 226/600] [D loss: 0.423905] [G loss: 2.003929]\n",
            "[Epoch 43/50] [Batch 227/600] [D loss: 0.355110] [G loss: 2.043748]\n",
            "[Epoch 43/50] [Batch 228/600] [D loss: 0.375961] [G loss: 1.962207]\n",
            "[Epoch 43/50] [Batch 229/600] [D loss: 0.366546] [G loss: 1.908041]\n",
            "[Epoch 43/50] [Batch 230/600] [D loss: 0.416929] [G loss: 1.855585]\n",
            "[Epoch 43/50] [Batch 231/600] [D loss: 0.407437] [G loss: 2.002304]\n",
            "[Epoch 43/50] [Batch 232/600] [D loss: 0.377134] [G loss: 1.782507]\n",
            "[Epoch 43/50] [Batch 233/600] [D loss: 0.367441] [G loss: 1.820327]\n",
            "[Epoch 43/50] [Batch 234/600] [D loss: 0.452505] [G loss: 1.788149]\n",
            "[Epoch 43/50] [Batch 235/600] [D loss: 0.457593] [G loss: 1.835878]\n",
            "[Epoch 43/50] [Batch 236/600] [D loss: 0.413491] [G loss: 1.567441]\n",
            "[Epoch 43/50] [Batch 237/600] [D loss: 0.423451] [G loss: 1.947971]\n",
            "[Epoch 43/50] [Batch 238/600] [D loss: 0.431719] [G loss: 1.827235]\n",
            "[Epoch 43/50] [Batch 239/600] [D loss: 0.456380] [G loss: 1.516412]\n",
            "[Epoch 43/50] [Batch 240/600] [D loss: 0.450056] [G loss: 1.712219]\n",
            "[Epoch 43/50] [Batch 241/600] [D loss: 0.432208] [G loss: 1.538257]\n",
            "[Epoch 43/50] [Batch 242/600] [D loss: 0.403925] [G loss: 1.543294]\n",
            "[Epoch 43/50] [Batch 243/600] [D loss: 0.418409] [G loss: 1.663511]\n",
            "[Epoch 43/50] [Batch 244/600] [D loss: 0.339406] [G loss: 1.888422]\n",
            "[Epoch 43/50] [Batch 245/600] [D loss: 0.486064] [G loss: 1.766231]\n",
            "[Epoch 43/50] [Batch 246/600] [D loss: 0.397916] [G loss: 1.681947]\n",
            "[Epoch 43/50] [Batch 247/600] [D loss: 0.382767] [G loss: 1.747861]\n",
            "[Epoch 43/50] [Batch 248/600] [D loss: 0.397251] [G loss: 1.533107]\n",
            "[Epoch 43/50] [Batch 249/600] [D loss: 0.475388] [G loss: 1.812999]\n",
            "[Epoch 43/50] [Batch 250/600] [D loss: 0.388633] [G loss: 1.590037]\n",
            "[Epoch 43/50] [Batch 251/600] [D loss: 0.431116] [G loss: 1.778758]\n",
            "[Epoch 43/50] [Batch 252/600] [D loss: 0.419733] [G loss: 1.570638]\n",
            "[Epoch 43/50] [Batch 253/600] [D loss: 0.383762] [G loss: 1.632930]\n",
            "[Epoch 43/50] [Batch 254/600] [D loss: 0.387476] [G loss: 1.631295]\n",
            "[Epoch 43/50] [Batch 255/600] [D loss: 0.373502] [G loss: 1.535995]\n",
            "[Epoch 43/50] [Batch 256/600] [D loss: 0.450333] [G loss: 1.777495]\n",
            "[Epoch 43/50] [Batch 257/600] [D loss: 0.358264] [G loss: 1.906534]\n",
            "[Epoch 43/50] [Batch 258/600] [D loss: 0.495851] [G loss: 1.920995]\n",
            "[Epoch 43/50] [Batch 259/600] [D loss: 0.381583] [G loss: 1.800853]\n",
            "[Epoch 43/50] [Batch 260/600] [D loss: 0.472794] [G loss: 1.861768]\n",
            "[Epoch 43/50] [Batch 261/600] [D loss: 0.419308] [G loss: 1.623177]\n",
            "[Epoch 43/50] [Batch 262/600] [D loss: 0.459878] [G loss: 1.820263]\n",
            "[Epoch 43/50] [Batch 263/600] [D loss: 0.499646] [G loss: 1.822911]\n",
            "[Epoch 43/50] [Batch 264/600] [D loss: 0.416870] [G loss: 1.700483]\n",
            "[Epoch 43/50] [Batch 265/600] [D loss: 0.474423] [G loss: 1.543670]\n",
            "[Epoch 43/50] [Batch 266/600] [D loss: 0.381583] [G loss: 1.683060]\n",
            "[Epoch 43/50] [Batch 267/600] [D loss: 0.422393] [G loss: 1.671628]\n",
            "[Epoch 43/50] [Batch 268/600] [D loss: 0.463692] [G loss: 1.549543]\n",
            "[Epoch 43/50] [Batch 269/600] [D loss: 0.403166] [G loss: 1.376158]\n",
            "[Epoch 43/50] [Batch 270/600] [D loss: 0.377370] [G loss: 1.516274]\n",
            "[Epoch 43/50] [Batch 271/600] [D loss: 0.390172] [G loss: 1.762211]\n",
            "[Epoch 43/50] [Batch 272/600] [D loss: 0.389044] [G loss: 1.727206]\n",
            "[Epoch 43/50] [Batch 273/600] [D loss: 0.408424] [G loss: 1.742729]\n",
            "[Epoch 43/50] [Batch 274/600] [D loss: 0.350691] [G loss: 1.925640]\n",
            "[Epoch 43/50] [Batch 275/600] [D loss: 0.383225] [G loss: 1.719520]\n",
            "[Epoch 43/50] [Batch 276/600] [D loss: 0.416477] [G loss: 1.838096]\n",
            "[Epoch 43/50] [Batch 277/600] [D loss: 0.406471] [G loss: 1.861958]\n",
            "[Epoch 43/50] [Batch 278/600] [D loss: 0.447198] [G loss: 1.750551]\n",
            "[Epoch 43/50] [Batch 279/600] [D loss: 0.476714] [G loss: 2.080518]\n",
            "[Epoch 43/50] [Batch 280/600] [D loss: 0.406050] [G loss: 1.596423]\n",
            "[Epoch 43/50] [Batch 281/600] [D loss: 0.450121] [G loss: 1.494226]\n",
            "[Epoch 43/50] [Batch 282/600] [D loss: 0.433756] [G loss: 1.401242]\n",
            "[Epoch 43/50] [Batch 283/600] [D loss: 0.417602] [G loss: 1.673360]\n",
            "[Epoch 43/50] [Batch 284/600] [D loss: 0.416608] [G loss: 1.466993]\n",
            "[Epoch 43/50] [Batch 285/600] [D loss: 0.448546] [G loss: 1.657248]\n",
            "[Epoch 43/50] [Batch 286/600] [D loss: 0.379731] [G loss: 1.627068]\n",
            "[Epoch 43/50] [Batch 287/600] [D loss: 0.423781] [G loss: 1.687129]\n",
            "[Epoch 43/50] [Batch 288/600] [D loss: 0.372470] [G loss: 1.560271]\n",
            "[Epoch 43/50] [Batch 289/600] [D loss: 0.354215] [G loss: 2.011057]\n",
            "[Epoch 43/50] [Batch 290/600] [D loss: 0.431257] [G loss: 1.805847]\n",
            "[Epoch 43/50] [Batch 291/600] [D loss: 0.505254] [G loss: 1.825726]\n",
            "[Epoch 43/50] [Batch 292/600] [D loss: 0.471748] [G loss: 1.737668]\n",
            "[Epoch 43/50] [Batch 293/600] [D loss: 0.422327] [G loss: 1.721678]\n",
            "[Epoch 43/50] [Batch 294/600] [D loss: 0.446715] [G loss: 1.551714]\n",
            "[Epoch 43/50] [Batch 295/600] [D loss: 0.446010] [G loss: 1.671568]\n",
            "[Epoch 43/50] [Batch 296/600] [D loss: 0.456197] [G loss: 1.396108]\n",
            "[Epoch 43/50] [Batch 297/600] [D loss: 0.404281] [G loss: 1.555059]\n",
            "[Epoch 43/50] [Batch 298/600] [D loss: 0.503812] [G loss: 1.682425]\n",
            "[Epoch 43/50] [Batch 299/600] [D loss: 0.469622] [G loss: 1.654551]\n",
            "[Epoch 43/50] [Batch 300/600] [D loss: 0.419564] [G loss: 1.767997]\n",
            "[Epoch 43/50] [Batch 301/600] [D loss: 0.372716] [G loss: 1.655062]\n",
            "[Epoch 43/50] [Batch 302/600] [D loss: 0.501728] [G loss: 1.601679]\n",
            "[Epoch 43/50] [Batch 303/600] [D loss: 0.400528] [G loss: 1.730247]\n",
            "[Epoch 43/50] [Batch 304/600] [D loss: 0.414666] [G loss: 1.618133]\n",
            "[Epoch 43/50] [Batch 305/600] [D loss: 0.415300] [G loss: 1.732015]\n",
            "[Epoch 43/50] [Batch 306/600] [D loss: 0.509185] [G loss: 1.708068]\n",
            "[Epoch 43/50] [Batch 307/600] [D loss: 0.429465] [G loss: 1.795622]\n",
            "[Epoch 43/50] [Batch 308/600] [D loss: 0.456802] [G loss: 1.614130]\n",
            "[Epoch 43/50] [Batch 309/600] [D loss: 0.476211] [G loss: 1.595814]\n",
            "[Epoch 43/50] [Batch 310/600] [D loss: 0.436940] [G loss: 1.477578]\n",
            "[Epoch 43/50] [Batch 311/600] [D loss: 0.444382] [G loss: 1.475645]\n",
            "[Epoch 43/50] [Batch 312/600] [D loss: 0.406648] [G loss: 1.683562]\n",
            "[Epoch 43/50] [Batch 313/600] [D loss: 0.418950] [G loss: 1.727117]\n",
            "[Epoch 43/50] [Batch 314/600] [D loss: 0.423567] [G loss: 1.804702]\n",
            "[Epoch 43/50] [Batch 315/600] [D loss: 0.436834] [G loss: 1.679183]\n",
            "[Epoch 43/50] [Batch 316/600] [D loss: 0.382857] [G loss: 1.711329]\n",
            "[Epoch 43/50] [Batch 317/600] [D loss: 0.504476] [G loss: 1.748719]\n",
            "[Epoch 43/50] [Batch 318/600] [D loss: 0.422415] [G loss: 1.783357]\n",
            "[Epoch 43/50] [Batch 319/600] [D loss: 0.406806] [G loss: 1.567577]\n",
            "[Epoch 43/50] [Batch 320/600] [D loss: 0.449112] [G loss: 1.555372]\n",
            "[Epoch 43/50] [Batch 321/600] [D loss: 0.424409] [G loss: 1.616033]\n",
            "[Epoch 43/50] [Batch 322/600] [D loss: 0.391793] [G loss: 1.697941]\n",
            "[Epoch 43/50] [Batch 323/600] [D loss: 0.461858] [G loss: 1.679913]\n",
            "[Epoch 43/50] [Batch 324/600] [D loss: 0.360723] [G loss: 1.820272]\n",
            "[Epoch 43/50] [Batch 325/600] [D loss: 0.460928] [G loss: 1.751130]\n",
            "[Epoch 43/50] [Batch 326/600] [D loss: 0.412539] [G loss: 1.761174]\n",
            "[Epoch 43/50] [Batch 327/600] [D loss: 0.476873] [G loss: 1.690699]\n",
            "[Epoch 43/50] [Batch 328/600] [D loss: 0.413282] [G loss: 1.608153]\n",
            "[Epoch 43/50] [Batch 329/600] [D loss: 0.397196] [G loss: 1.717023]\n",
            "[Epoch 43/50] [Batch 330/600] [D loss: 0.364611] [G loss: 1.657105]\n",
            "[Epoch 43/50] [Batch 331/600] [D loss: 0.409149] [G loss: 1.806621]\n",
            "[Epoch 43/50] [Batch 332/600] [D loss: 0.428181] [G loss: 1.652569]\n",
            "[Epoch 43/50] [Batch 333/600] [D loss: 0.372198] [G loss: 1.767344]\n",
            "[Epoch 43/50] [Batch 334/600] [D loss: 0.363540] [G loss: 1.941675]\n",
            "[Epoch 43/50] [Batch 335/600] [D loss: 0.457015] [G loss: 1.837186]\n",
            "[Epoch 43/50] [Batch 336/600] [D loss: 0.389754] [G loss: 1.891961]\n",
            "[Epoch 43/50] [Batch 337/600] [D loss: 0.434135] [G loss: 1.713872]\n",
            "[Epoch 43/50] [Batch 338/600] [D loss: 0.413561] [G loss: 1.552136]\n",
            "[Epoch 43/50] [Batch 339/600] [D loss: 0.396578] [G loss: 1.636234]\n",
            "[Epoch 43/50] [Batch 340/600] [D loss: 0.466607] [G loss: 1.748781]\n",
            "[Epoch 43/50] [Batch 341/600] [D loss: 0.407829] [G loss: 1.642049]\n",
            "[Epoch 43/50] [Batch 342/600] [D loss: 0.385015] [G loss: 1.967859]\n",
            "[Epoch 43/50] [Batch 343/600] [D loss: 0.509606] [G loss: 1.764527]\n",
            "[Epoch 43/50] [Batch 344/600] [D loss: 0.383520] [G loss: 1.650631]\n",
            "[Epoch 43/50] [Batch 345/600] [D loss: 0.474590] [G loss: 1.579661]\n",
            "[Epoch 43/50] [Batch 346/600] [D loss: 0.429994] [G loss: 1.697170]\n",
            "[Epoch 43/50] [Batch 347/600] [D loss: 0.448226] [G loss: 1.546299]\n",
            "[Epoch 43/50] [Batch 348/600] [D loss: 0.458337] [G loss: 1.700550]\n",
            "[Epoch 43/50] [Batch 349/600] [D loss: 0.437614] [G loss: 1.492271]\n",
            "[Epoch 43/50] [Batch 350/600] [D loss: 0.491859] [G loss: 1.564742]\n",
            "[Epoch 43/50] [Batch 351/600] [D loss: 0.425119] [G loss: 1.760443]\n",
            "[Epoch 43/50] [Batch 352/600] [D loss: 0.370895] [G loss: 1.865223]\n",
            "[Epoch 43/50] [Batch 353/600] [D loss: 0.395031] [G loss: 1.817538]\n",
            "[Epoch 43/50] [Batch 354/600] [D loss: 0.335146] [G loss: 1.928810]\n",
            "[Epoch 43/50] [Batch 355/600] [D loss: 0.416417] [G loss: 1.679350]\n",
            "[Epoch 43/50] [Batch 356/600] [D loss: 0.408484] [G loss: 1.624368]\n",
            "[Epoch 43/50] [Batch 357/600] [D loss: 0.459212] [G loss: 1.559274]\n",
            "[Epoch 43/50] [Batch 358/600] [D loss: 0.412512] [G loss: 1.644869]\n",
            "[Epoch 43/50] [Batch 359/600] [D loss: 0.477852] [G loss: 1.447724]\n",
            "[Epoch 43/50] [Batch 360/600] [D loss: 0.514008] [G loss: 1.630901]\n",
            "[Epoch 43/50] [Batch 361/600] [D loss: 0.362449] [G loss: 1.509955]\n",
            "[Epoch 43/50] [Batch 362/600] [D loss: 0.389648] [G loss: 1.773451]\n",
            "[Epoch 43/50] [Batch 363/600] [D loss: 0.369100] [G loss: 1.978248]\n",
            "[Epoch 43/50] [Batch 364/600] [D loss: 0.401467] [G loss: 2.000170]\n",
            "[Epoch 43/50] [Batch 365/600] [D loss: 0.418944] [G loss: 1.991929]\n",
            "[Epoch 43/50] [Batch 366/600] [D loss: 0.441379] [G loss: 1.844451]\n",
            "[Epoch 43/50] [Batch 367/600] [D loss: 0.341819] [G loss: 1.748487]\n",
            "[Epoch 43/50] [Batch 368/600] [D loss: 0.412502] [G loss: 1.951321]\n",
            "[Epoch 43/50] [Batch 369/600] [D loss: 0.417507] [G loss: 1.750550]\n",
            "[Epoch 43/50] [Batch 370/600] [D loss: 0.438828] [G loss: 1.938403]\n",
            "[Epoch 43/50] [Batch 371/600] [D loss: 0.455027] [G loss: 1.678498]\n",
            "[Epoch 43/50] [Batch 372/600] [D loss: 0.401441] [G loss: 1.669767]\n",
            "[Epoch 43/50] [Batch 373/600] [D loss: 0.428591] [G loss: 1.836359]\n",
            "[Epoch 43/50] [Batch 374/600] [D loss: 0.432559] [G loss: 1.617281]\n",
            "[Epoch 43/50] [Batch 375/600] [D loss: 0.510229] [G loss: 1.583765]\n",
            "[Epoch 43/50] [Batch 376/600] [D loss: 0.427203] [G loss: 1.645778]\n",
            "[Epoch 43/50] [Batch 377/600] [D loss: 0.438584] [G loss: 1.749572]\n",
            "[Epoch 43/50] [Batch 378/600] [D loss: 0.396113] [G loss: 1.609066]\n",
            "[Epoch 43/50] [Batch 379/600] [D loss: 0.400718] [G loss: 1.806512]\n",
            "[Epoch 43/50] [Batch 380/600] [D loss: 0.442931] [G loss: 1.808592]\n",
            "[Epoch 43/50] [Batch 381/600] [D loss: 0.366648] [G loss: 1.720168]\n",
            "[Epoch 43/50] [Batch 382/600] [D loss: 0.412945] [G loss: 1.823612]\n",
            "[Epoch 43/50] [Batch 383/600] [D loss: 0.454777] [G loss: 1.796651]\n",
            "[Epoch 43/50] [Batch 384/600] [D loss: 0.375028] [G loss: 1.621234]\n",
            "[Epoch 43/50] [Batch 385/600] [D loss: 0.424002] [G loss: 1.806626]\n",
            "[Epoch 43/50] [Batch 386/600] [D loss: 0.355886] [G loss: 2.066395]\n",
            "[Epoch 43/50] [Batch 387/600] [D loss: 0.457065] [G loss: 2.029141]\n",
            "[Epoch 43/50] [Batch 388/600] [D loss: 0.375153] [G loss: 1.630527]\n",
            "[Epoch 43/50] [Batch 389/600] [D loss: 0.434324] [G loss: 1.725022]\n",
            "[Epoch 43/50] [Batch 390/600] [D loss: 0.431051] [G loss: 1.643786]\n",
            "[Epoch 43/50] [Batch 391/600] [D loss: 0.351934] [G loss: 1.841425]\n",
            "[Epoch 43/50] [Batch 392/600] [D loss: 0.426150] [G loss: 1.523436]\n",
            "[Epoch 43/50] [Batch 393/600] [D loss: 0.421860] [G loss: 1.751700]\n",
            "[Epoch 43/50] [Batch 394/600] [D loss: 0.369820] [G loss: 1.517967]\n",
            "[Epoch 43/50] [Batch 395/600] [D loss: 0.361943] [G loss: 1.544591]\n",
            "[Epoch 43/50] [Batch 396/600] [D loss: 0.427699] [G loss: 1.617135]\n",
            "[Epoch 43/50] [Batch 397/600] [D loss: 0.407070] [G loss: 1.763549]\n",
            "[Epoch 43/50] [Batch 398/600] [D loss: 0.376557] [G loss: 1.958714]\n",
            "[Epoch 43/50] [Batch 399/600] [D loss: 0.421579] [G loss: 2.228317]\n",
            "[Epoch 43/50] [Batch 400/600] [D loss: 0.389484] [G loss: 2.054499]\n",
            "[Epoch 43/50] [Batch 401/600] [D loss: 0.459999] [G loss: 1.659210]\n",
            "[Epoch 43/50] [Batch 402/600] [D loss: 0.453262] [G loss: 1.433901]\n",
            "[Epoch 43/50] [Batch 403/600] [D loss: 0.412172] [G loss: 1.752061]\n",
            "[Epoch 43/50] [Batch 404/600] [D loss: 0.369031] [G loss: 1.906161]\n",
            "[Epoch 43/50] [Batch 405/600] [D loss: 0.324049] [G loss: 1.730630]\n",
            "[Epoch 43/50] [Batch 406/600] [D loss: 0.462292] [G loss: 1.706048]\n",
            "[Epoch 43/50] [Batch 407/600] [D loss: 0.457150] [G loss: 1.898579]\n",
            "[Epoch 43/50] [Batch 408/600] [D loss: 0.350172] [G loss: 2.147298]\n",
            "[Epoch 43/50] [Batch 409/600] [D loss: 0.436344] [G loss: 2.220877]\n",
            "[Epoch 43/50] [Batch 410/600] [D loss: 0.501858] [G loss: 1.944621]\n",
            "[Epoch 43/50] [Batch 411/600] [D loss: 0.399716] [G loss: 1.834279]\n",
            "[Epoch 43/50] [Batch 412/600] [D loss: 0.432485] [G loss: 1.627533]\n",
            "[Epoch 43/50] [Batch 413/600] [D loss: 0.405439] [G loss: 1.694404]\n",
            "[Epoch 43/50] [Batch 414/600] [D loss: 0.391564] [G loss: 1.714342]\n",
            "[Epoch 43/50] [Batch 415/600] [D loss: 0.392267] [G loss: 1.817788]\n",
            "[Epoch 43/50] [Batch 416/600] [D loss: 0.403577] [G loss: 1.992284]\n",
            "[Epoch 43/50] [Batch 417/600] [D loss: 0.479590] [G loss: 1.784284]\n",
            "[Epoch 43/50] [Batch 418/600] [D loss: 0.371931] [G loss: 1.709872]\n",
            "[Epoch 43/50] [Batch 419/600] [D loss: 0.428243] [G loss: 1.547638]\n",
            "[Epoch 43/50] [Batch 420/600] [D loss: 0.404220] [G loss: 1.722675]\n",
            "[Epoch 43/50] [Batch 421/600] [D loss: 0.374896] [G loss: 1.764457]\n",
            "[Epoch 43/50] [Batch 422/600] [D loss: 0.396560] [G loss: 1.683458]\n",
            "[Epoch 43/50] [Batch 423/600] [D loss: 0.406727] [G loss: 1.714423]\n",
            "[Epoch 43/50] [Batch 424/600] [D loss: 0.406766] [G loss: 1.582589]\n",
            "[Epoch 43/50] [Batch 425/600] [D loss: 0.412955] [G loss: 1.702112]\n",
            "[Epoch 43/50] [Batch 426/600] [D loss: 0.378737] [G loss: 1.722862]\n",
            "[Epoch 43/50] [Batch 427/600] [D loss: 0.378649] [G loss: 1.757810]\n",
            "[Epoch 43/50] [Batch 428/600] [D loss: 0.418111] [G loss: 1.829071]\n",
            "[Epoch 43/50] [Batch 429/600] [D loss: 0.461165] [G loss: 1.768514]\n",
            "[Epoch 43/50] [Batch 430/600] [D loss: 0.483003] [G loss: 2.013779]\n",
            "[Epoch 43/50] [Batch 431/600] [D loss: 0.407173] [G loss: 1.740834]\n",
            "[Epoch 43/50] [Batch 432/600] [D loss: 0.379181] [G loss: 1.569764]\n",
            "[Epoch 43/50] [Batch 433/600] [D loss: 0.436086] [G loss: 1.480165]\n",
            "[Epoch 43/50] [Batch 434/600] [D loss: 0.391262] [G loss: 1.604043]\n",
            "[Epoch 43/50] [Batch 435/600] [D loss: 0.418339] [G loss: 1.640467]\n",
            "[Epoch 43/50] [Batch 436/600] [D loss: 0.382252] [G loss: 2.072784]\n",
            "[Epoch 43/50] [Batch 437/600] [D loss: 0.432676] [G loss: 2.052564]\n",
            "[Epoch 43/50] [Batch 438/600] [D loss: 0.374576] [G loss: 2.024526]\n",
            "[Epoch 43/50] [Batch 439/600] [D loss: 0.490014] [G loss: 1.714712]\n",
            "[Epoch 43/50] [Batch 440/600] [D loss: 0.447367] [G loss: 1.912835]\n",
            "[Epoch 43/50] [Batch 441/600] [D loss: 0.448597] [G loss: 1.692170]\n",
            "[Epoch 43/50] [Batch 442/600] [D loss: 0.424959] [G loss: 1.902295]\n",
            "[Epoch 43/50] [Batch 443/600] [D loss: 0.366053] [G loss: 1.692725]\n",
            "[Epoch 43/50] [Batch 444/600] [D loss: 0.460282] [G loss: 1.792462]\n",
            "[Epoch 43/50] [Batch 445/600] [D loss: 0.450911] [G loss: 1.873363]\n",
            "[Epoch 43/50] [Batch 446/600] [D loss: 0.378567] [G loss: 1.812255]\n",
            "[Epoch 43/50] [Batch 447/600] [D loss: 0.437710] [G loss: 1.641374]\n",
            "[Epoch 43/50] [Batch 448/600] [D loss: 0.405143] [G loss: 1.790122]\n",
            "[Epoch 43/50] [Batch 449/600] [D loss: 0.411387] [G loss: 1.643614]\n",
            "[Epoch 43/50] [Batch 450/600] [D loss: 0.449252] [G loss: 1.573944]\n",
            "[Epoch 43/50] [Batch 451/600] [D loss: 0.428367] [G loss: 1.672855]\n",
            "[Epoch 43/50] [Batch 452/600] [D loss: 0.367469] [G loss: 1.811417]\n",
            "[Epoch 43/50] [Batch 453/600] [D loss: 0.415041] [G loss: 1.819577]\n",
            "[Epoch 43/50] [Batch 454/600] [D loss: 0.428665] [G loss: 1.690729]\n",
            "[Epoch 43/50] [Batch 455/600] [D loss: 0.460946] [G loss: 1.743687]\n",
            "[Epoch 43/50] [Batch 456/600] [D loss: 0.452005] [G loss: 2.080444]\n",
            "[Epoch 43/50] [Batch 457/600] [D loss: 0.496735] [G loss: 1.640845]\n",
            "[Epoch 43/50] [Batch 458/600] [D loss: 0.507670] [G loss: 1.641584]\n",
            "[Epoch 43/50] [Batch 459/600] [D loss: 0.444728] [G loss: 1.665272]\n",
            "[Epoch 43/50] [Batch 460/600] [D loss: 0.474114] [G loss: 1.500910]\n",
            "[Epoch 43/50] [Batch 461/600] [D loss: 0.461541] [G loss: 1.567170]\n",
            "[Epoch 43/50] [Batch 462/600] [D loss: 0.421889] [G loss: 1.641033]\n",
            "[Epoch 43/50] [Batch 463/600] [D loss: 0.434888] [G loss: 1.492222]\n",
            "[Epoch 43/50] [Batch 464/600] [D loss: 0.364134] [G loss: 1.567778]\n",
            "[Epoch 43/50] [Batch 465/600] [D loss: 0.397787] [G loss: 1.712706]\n",
            "[Epoch 43/50] [Batch 466/600] [D loss: 0.459353] [G loss: 1.491590]\n",
            "[Epoch 43/50] [Batch 467/600] [D loss: 0.420187] [G loss: 1.502408]\n",
            "[Epoch 43/50] [Batch 468/600] [D loss: 0.462766] [G loss: 1.573136]\n",
            "[Epoch 43/50] [Batch 469/600] [D loss: 0.416427] [G loss: 1.741701]\n",
            "[Epoch 43/50] [Batch 470/600] [D loss: 0.409703] [G loss: 1.546406]\n",
            "[Epoch 43/50] [Batch 471/600] [D loss: 0.452676] [G loss: 1.558899]\n",
            "[Epoch 43/50] [Batch 472/600] [D loss: 0.468858] [G loss: 1.828573]\n",
            "[Epoch 43/50] [Batch 473/600] [D loss: 0.450737] [G loss: 1.802150]\n",
            "[Epoch 43/50] [Batch 474/600] [D loss: 0.410680] [G loss: 1.675048]\n",
            "[Epoch 43/50] [Batch 475/600] [D loss: 0.398774] [G loss: 1.425546]\n",
            "[Epoch 43/50] [Batch 476/600] [D loss: 0.376729] [G loss: 1.684435]\n",
            "[Epoch 43/50] [Batch 477/600] [D loss: 0.337568] [G loss: 1.598078]\n",
            "[Epoch 43/50] [Batch 478/600] [D loss: 0.433800] [G loss: 1.781422]\n",
            "[Epoch 43/50] [Batch 479/600] [D loss: 0.370441] [G loss: 1.813097]\n",
            "[Epoch 43/50] [Batch 480/600] [D loss: 0.488995] [G loss: 1.862227]\n",
            "[Epoch 43/50] [Batch 481/600] [D loss: 0.340472] [G loss: 1.759857]\n",
            "[Epoch 43/50] [Batch 482/600] [D loss: 0.481642] [G loss: 1.400195]\n",
            "[Epoch 43/50] [Batch 483/600] [D loss: 0.396580] [G loss: 1.546310]\n",
            "[Epoch 43/50] [Batch 484/600] [D loss: 0.368718] [G loss: 1.898875]\n",
            "[Epoch 43/50] [Batch 485/600] [D loss: 0.407254] [G loss: 1.810055]\n",
            "[Epoch 43/50] [Batch 486/600] [D loss: 0.417790] [G loss: 1.758280]\n",
            "[Epoch 43/50] [Batch 487/600] [D loss: 0.453200] [G loss: 1.783595]\n",
            "[Epoch 43/50] [Batch 488/600] [D loss: 0.349071] [G loss: 1.797186]\n",
            "[Epoch 43/50] [Batch 489/600] [D loss: 0.494096] [G loss: 1.649823]\n",
            "[Epoch 43/50] [Batch 490/600] [D loss: 0.428141] [G loss: 1.958611]\n",
            "[Epoch 43/50] [Batch 491/600] [D loss: 0.397720] [G loss: 1.697448]\n",
            "[Epoch 43/50] [Batch 492/600] [D loss: 0.448396] [G loss: 1.914424]\n",
            "[Epoch 43/50] [Batch 493/600] [D loss: 0.440244] [G loss: 1.802168]\n",
            "[Epoch 43/50] [Batch 494/600] [D loss: 0.397478] [G loss: 1.695326]\n",
            "[Epoch 43/50] [Batch 495/600] [D loss: 0.372518] [G loss: 1.720635]\n",
            "[Epoch 43/50] [Batch 496/600] [D loss: 0.444346] [G loss: 1.604302]\n",
            "[Epoch 43/50] [Batch 497/600] [D loss: 0.378018] [G loss: 1.866969]\n",
            "[Epoch 43/50] [Batch 498/600] [D loss: 0.403308] [G loss: 1.657523]\n",
            "[Epoch 43/50] [Batch 499/600] [D loss: 0.412767] [G loss: 1.802337]\n",
            "[Epoch 43/50] [Batch 500/600] [D loss: 0.408493] [G loss: 1.924052]\n",
            "[Epoch 43/50] [Batch 501/600] [D loss: 0.394004] [G loss: 1.891708]\n",
            "[Epoch 43/50] [Batch 502/600] [D loss: 0.436892] [G loss: 1.640024]\n",
            "[Epoch 43/50] [Batch 503/600] [D loss: 0.406731] [G loss: 1.739021]\n",
            "[Epoch 43/50] [Batch 504/600] [D loss: 0.479990] [G loss: 1.791757]\n",
            "[Epoch 43/50] [Batch 505/600] [D loss: 0.407665] [G loss: 1.652501]\n",
            "[Epoch 43/50] [Batch 506/600] [D loss: 0.390452] [G loss: 1.981409]\n",
            "[Epoch 43/50] [Batch 507/600] [D loss: 0.476429] [G loss: 2.154651]\n",
            "[Epoch 43/50] [Batch 508/600] [D loss: 0.431417] [G loss: 1.601215]\n",
            "[Epoch 43/50] [Batch 509/600] [D loss: 0.425615] [G loss: 1.504263]\n",
            "[Epoch 43/50] [Batch 510/600] [D loss: 0.422128] [G loss: 1.504052]\n",
            "[Epoch 43/50] [Batch 511/600] [D loss: 0.386258] [G loss: 1.796613]\n",
            "[Epoch 43/50] [Batch 512/600] [D loss: 0.467671] [G loss: 1.548313]\n",
            "[Epoch 43/50] [Batch 513/600] [D loss: 0.431749] [G loss: 1.946936]\n",
            "[Epoch 43/50] [Batch 514/600] [D loss: 0.477460] [G loss: 1.482642]\n",
            "[Epoch 43/50] [Batch 515/600] [D loss: 0.409345] [G loss: 1.936270]\n",
            "[Epoch 43/50] [Batch 516/600] [D loss: 0.429819] [G loss: 1.816815]\n",
            "[Epoch 43/50] [Batch 517/600] [D loss: 0.421304] [G loss: 1.809705]\n",
            "[Epoch 43/50] [Batch 518/600] [D loss: 0.417977] [G loss: 1.930886]\n",
            "[Epoch 43/50] [Batch 519/600] [D loss: 0.508263] [G loss: 1.690236]\n",
            "[Epoch 43/50] [Batch 520/600] [D loss: 0.455372] [G loss: 1.480933]\n",
            "[Epoch 43/50] [Batch 521/600] [D loss: 0.347929] [G loss: 1.729915]\n",
            "[Epoch 43/50] [Batch 522/600] [D loss: 0.459271] [G loss: 1.674235]\n",
            "[Epoch 43/50] [Batch 523/600] [D loss: 0.472579] [G loss: 1.593243]\n",
            "[Epoch 43/50] [Batch 524/600] [D loss: 0.396069] [G loss: 1.689928]\n",
            "[Epoch 43/50] [Batch 525/600] [D loss: 0.391830] [G loss: 1.514209]\n",
            "[Epoch 43/50] [Batch 526/600] [D loss: 0.359928] [G loss: 1.599590]\n",
            "[Epoch 43/50] [Batch 527/600] [D loss: 0.365999] [G loss: 1.576309]\n",
            "[Epoch 43/50] [Batch 528/600] [D loss: 0.437706] [G loss: 2.058094]\n",
            "[Epoch 43/50] [Batch 529/600] [D loss: 0.512931] [G loss: 1.783247]\n",
            "[Epoch 43/50] [Batch 530/600] [D loss: 0.478749] [G loss: 1.657695]\n",
            "[Epoch 43/50] [Batch 531/600] [D loss: 0.460559] [G loss: 1.630967]\n",
            "[Epoch 43/50] [Batch 532/600] [D loss: 0.444074] [G loss: 1.580220]\n",
            "[Epoch 43/50] [Batch 533/600] [D loss: 0.419795] [G loss: 1.592511]\n",
            "[Epoch 43/50] [Batch 534/600] [D loss: 0.429257] [G loss: 1.768983]\n",
            "[Epoch 43/50] [Batch 535/600] [D loss: 0.414580] [G loss: 1.695425]\n",
            "[Epoch 43/50] [Batch 536/600] [D loss: 0.413908] [G loss: 1.859517]\n",
            "[Epoch 43/50] [Batch 537/600] [D loss: 0.426047] [G loss: 1.672586]\n",
            "[Epoch 43/50] [Batch 538/600] [D loss: 0.408774] [G loss: 1.631325]\n",
            "[Epoch 43/50] [Batch 539/600] [D loss: 0.430721] [G loss: 1.680748]\n",
            "[Epoch 43/50] [Batch 540/600] [D loss: 0.436668] [G loss: 1.825089]\n",
            "[Epoch 43/50] [Batch 541/600] [D loss: 0.367075] [G loss: 1.762823]\n",
            "[Epoch 43/50] [Batch 542/600] [D loss: 0.440641] [G loss: 1.607608]\n",
            "[Epoch 43/50] [Batch 543/600] [D loss: 0.417683] [G loss: 1.863342]\n",
            "[Epoch 43/50] [Batch 544/600] [D loss: 0.429606] [G loss: 1.899133]\n",
            "[Epoch 43/50] [Batch 545/600] [D loss: 0.417844] [G loss: 1.994872]\n",
            "[Epoch 43/50] [Batch 546/600] [D loss: 0.408073] [G loss: 1.737171]\n",
            "[Epoch 43/50] [Batch 547/600] [D loss: 0.435489] [G loss: 1.802421]\n",
            "[Epoch 43/50] [Batch 548/600] [D loss: 0.370619] [G loss: 1.754296]\n",
            "[Epoch 43/50] [Batch 549/600] [D loss: 0.387133] [G loss: 1.967982]\n",
            "[Epoch 43/50] [Batch 550/600] [D loss: 0.368279] [G loss: 1.883180]\n",
            "[Epoch 43/50] [Batch 551/600] [D loss: 0.384316] [G loss: 2.165902]\n",
            "[Epoch 43/50] [Batch 552/600] [D loss: 0.457119] [G loss: 1.857370]\n",
            "[Epoch 43/50] [Batch 553/600] [D loss: 0.417036] [G loss: 1.882948]\n",
            "[Epoch 43/50] [Batch 554/600] [D loss: 0.487214] [G loss: 1.503400]\n",
            "[Epoch 43/50] [Batch 555/600] [D loss: 0.366036] [G loss: 1.699441]\n",
            "[Epoch 43/50] [Batch 556/600] [D loss: 0.490704] [G loss: 1.766535]\n",
            "[Epoch 43/50] [Batch 557/600] [D loss: 0.375477] [G loss: 1.881261]\n",
            "[Epoch 43/50] [Batch 558/600] [D loss: 0.427984] [G loss: 1.842905]\n",
            "[Epoch 43/50] [Batch 559/600] [D loss: 0.389023] [G loss: 1.857140]\n",
            "[Epoch 43/50] [Batch 560/600] [D loss: 0.444063] [G loss: 2.088862]\n",
            "[Epoch 43/50] [Batch 561/600] [D loss: 0.370636] [G loss: 1.723191]\n",
            "[Epoch 43/50] [Batch 562/600] [D loss: 0.491319] [G loss: 1.707024]\n",
            "[Epoch 43/50] [Batch 563/600] [D loss: 0.472515] [G loss: 1.828034]\n",
            "[Epoch 43/50] [Batch 564/600] [D loss: 0.437450] [G loss: 1.567559]\n",
            "[Epoch 43/50] [Batch 565/600] [D loss: 0.416621] [G loss: 1.535453]\n",
            "[Epoch 43/50] [Batch 566/600] [D loss: 0.412857] [G loss: 1.454335]\n",
            "[Epoch 43/50] [Batch 567/600] [D loss: 0.380689] [G loss: 1.635012]\n",
            "[Epoch 43/50] [Batch 568/600] [D loss: 0.357607] [G loss: 1.651731]\n",
            "[Epoch 43/50] [Batch 569/600] [D loss: 0.368376] [G loss: 1.553723]\n",
            "[Epoch 43/50] [Batch 570/600] [D loss: 0.479472] [G loss: 1.692978]\n",
            "[Epoch 43/50] [Batch 571/600] [D loss: 0.427966] [G loss: 1.848189]\n",
            "[Epoch 43/50] [Batch 572/600] [D loss: 0.422016] [G loss: 1.931960]\n",
            "[Epoch 43/50] [Batch 573/600] [D loss: 0.446476] [G loss: 1.779902]\n",
            "[Epoch 43/50] [Batch 574/600] [D loss: 0.444711] [G loss: 1.792148]\n",
            "[Epoch 43/50] [Batch 575/600] [D loss: 0.423893] [G loss: 1.720142]\n",
            "[Epoch 43/50] [Batch 576/600] [D loss: 0.448293] [G loss: 1.437173]\n",
            "[Epoch 43/50] [Batch 577/600] [D loss: 0.449119] [G loss: 1.641981]\n",
            "[Epoch 43/50] [Batch 578/600] [D loss: 0.428703] [G loss: 1.555453]\n",
            "[Epoch 43/50] [Batch 579/600] [D loss: 0.420958] [G loss: 1.625687]\n",
            "[Epoch 43/50] [Batch 580/600] [D loss: 0.381705] [G loss: 1.717139]\n",
            "[Epoch 43/50] [Batch 581/600] [D loss: 0.349731] [G loss: 1.899820]\n",
            "[Epoch 43/50] [Batch 582/600] [D loss: 0.371079] [G loss: 1.706784]\n",
            "[Epoch 43/50] [Batch 583/600] [D loss: 0.414155] [G loss: 1.741472]\n",
            "[Epoch 43/50] [Batch 584/600] [D loss: 0.388246] [G loss: 1.843655]\n",
            "[Epoch 43/50] [Batch 585/600] [D loss: 0.436751] [G loss: 1.956743]\n",
            "[Epoch 43/50] [Batch 586/600] [D loss: 0.462384] [G loss: 1.941914]\n",
            "[Epoch 43/50] [Batch 587/600] [D loss: 0.437742] [G loss: 1.503860]\n",
            "[Epoch 43/50] [Batch 588/600] [D loss: 0.443230] [G loss: 1.546223]\n",
            "[Epoch 43/50] [Batch 589/600] [D loss: 0.325900] [G loss: 1.732485]\n",
            "[Epoch 43/50] [Batch 590/600] [D loss: 0.356986] [G loss: 2.057599]\n",
            "[Epoch 43/50] [Batch 591/600] [D loss: 0.304158] [G loss: 2.115883]\n",
            "[Epoch 43/50] [Batch 592/600] [D loss: 0.377632] [G loss: 2.248818]\n",
            "[Epoch 43/50] [Batch 593/600] [D loss: 0.452581] [G loss: 1.852407]\n",
            "[Epoch 43/50] [Batch 594/600] [D loss: 0.387774] [G loss: 1.797967]\n",
            "[Epoch 43/50] [Batch 595/600] [D loss: 0.365679] [G loss: 1.767395]\n",
            "[Epoch 43/50] [Batch 596/600] [D loss: 0.387336] [G loss: 1.631453]\n",
            "[Epoch 43/50] [Batch 597/600] [D loss: 0.428030] [G loss: 1.942713]\n",
            "[Epoch 43/50] [Batch 598/600] [D loss: 0.363670] [G loss: 2.015241]\n",
            "[Epoch 43/50] [Batch 599/600] [D loss: 0.420303] [G loss: 1.922944]\n",
            "[Epoch 44/50] [Batch 0/600] [D loss: 0.367442] [G loss: 1.901193]\n",
            "[Epoch 44/50] [Batch 1/600] [D loss: 0.380272] [G loss: 2.049237]\n",
            "[Epoch 44/50] [Batch 2/600] [D loss: 0.440627] [G loss: 1.871970]\n",
            "[Epoch 44/50] [Batch 3/600] [D loss: 0.445634] [G loss: 1.959934]\n",
            "[Epoch 44/50] [Batch 4/600] [D loss: 0.346193] [G loss: 1.757878]\n",
            "[Epoch 44/50] [Batch 5/600] [D loss: 0.361160] [G loss: 1.677165]\n",
            "[Epoch 44/50] [Batch 6/600] [D loss: 0.489313] [G loss: 1.839899]\n",
            "[Epoch 44/50] [Batch 7/600] [D loss: 0.387376] [G loss: 2.089800]\n",
            "[Epoch 44/50] [Batch 8/600] [D loss: 0.375497] [G loss: 1.829552]\n",
            "[Epoch 44/50] [Batch 9/600] [D loss: 0.402003] [G loss: 1.894109]\n",
            "[Epoch 44/50] [Batch 10/600] [D loss: 0.433922] [G loss: 1.760235]\n",
            "[Epoch 44/50] [Batch 11/600] [D loss: 0.405164] [G loss: 2.164179]\n",
            "[Epoch 44/50] [Batch 12/600] [D loss: 0.436921] [G loss: 1.955983]\n",
            "[Epoch 44/50] [Batch 13/600] [D loss: 0.454387] [G loss: 1.457361]\n",
            "[Epoch 44/50] [Batch 14/600] [D loss: 0.461249] [G loss: 1.366113]\n",
            "[Epoch 44/50] [Batch 15/600] [D loss: 0.368830] [G loss: 1.571863]\n",
            "[Epoch 44/50] [Batch 16/600] [D loss: 0.477961] [G loss: 1.701865]\n",
            "[Epoch 44/50] [Batch 17/600] [D loss: 0.382306] [G loss: 2.003376]\n",
            "[Epoch 44/50] [Batch 18/600] [D loss: 0.399011] [G loss: 1.824615]\n",
            "[Epoch 44/50] [Batch 19/600] [D loss: 0.397225] [G loss: 1.911631]\n",
            "[Epoch 44/50] [Batch 20/600] [D loss: 0.414342] [G loss: 1.888006]\n",
            "[Epoch 44/50] [Batch 21/600] [D loss: 0.415618] [G loss: 1.865341]\n",
            "[Epoch 44/50] [Batch 22/600] [D loss: 0.412680] [G loss: 1.852558]\n",
            "[Epoch 44/50] [Batch 23/600] [D loss: 0.448630] [G loss: 1.654752]\n",
            "[Epoch 44/50] [Batch 24/600] [D loss: 0.355890] [G loss: 2.041201]\n",
            "[Epoch 44/50] [Batch 25/600] [D loss: 0.373893] [G loss: 1.959323]\n",
            "[Epoch 44/50] [Batch 26/600] [D loss: 0.417438] [G loss: 2.034607]\n",
            "[Epoch 44/50] [Batch 27/600] [D loss: 0.430039] [G loss: 2.087188]\n",
            "[Epoch 44/50] [Batch 28/600] [D loss: 0.331902] [G loss: 1.895097]\n",
            "[Epoch 44/50] [Batch 29/600] [D loss: 0.421443] [G loss: 2.306060]\n",
            "[Epoch 44/50] [Batch 30/600] [D loss: 0.494888] [G loss: 1.679714]\n",
            "[Epoch 44/50] [Batch 31/600] [D loss: 0.381910] [G loss: 1.660534]\n",
            "[Epoch 44/50] [Batch 32/600] [D loss: 0.502276] [G loss: 1.676306]\n",
            "[Epoch 44/50] [Batch 33/600] [D loss: 0.435015] [G loss: 1.555739]\n",
            "[Epoch 44/50] [Batch 34/600] [D loss: 0.455105] [G loss: 1.844594]\n",
            "[Epoch 44/50] [Batch 35/600] [D loss: 0.425688] [G loss: 1.736799]\n",
            "[Epoch 44/50] [Batch 36/600] [D loss: 0.408322] [G loss: 1.873991]\n",
            "[Epoch 44/50] [Batch 37/600] [D loss: 0.391406] [G loss: 1.969467]\n",
            "[Epoch 44/50] [Batch 38/600] [D loss: 0.373650] [G loss: 1.717303]\n",
            "[Epoch 44/50] [Batch 39/600] [D loss: 0.425300] [G loss: 1.745932]\n",
            "[Epoch 44/50] [Batch 40/600] [D loss: 0.405326] [G loss: 1.528982]\n",
            "[Epoch 44/50] [Batch 41/600] [D loss: 0.464896] [G loss: 1.637001]\n",
            "[Epoch 44/50] [Batch 42/600] [D loss: 0.466825] [G loss: 1.741148]\n",
            "[Epoch 44/50] [Batch 43/600] [D loss: 0.441651] [G loss: 1.901299]\n",
            "[Epoch 44/50] [Batch 44/600] [D loss: 0.356284] [G loss: 1.746063]\n",
            "[Epoch 44/50] [Batch 45/600] [D loss: 0.418875] [G loss: 1.566039]\n",
            "[Epoch 44/50] [Batch 46/600] [D loss: 0.395714] [G loss: 1.801856]\n",
            "[Epoch 44/50] [Batch 47/600] [D loss: 0.352587] [G loss: 1.608868]\n",
            "[Epoch 44/50] [Batch 48/600] [D loss: 0.442156] [G loss: 1.972390]\n",
            "[Epoch 44/50] [Batch 49/600] [D loss: 0.387291] [G loss: 2.152558]\n",
            "[Epoch 44/50] [Batch 50/600] [D loss: 0.383993] [G loss: 1.776381]\n",
            "[Epoch 44/50] [Batch 51/600] [D loss: 0.420076] [G loss: 1.913573]\n",
            "[Epoch 44/50] [Batch 52/600] [D loss: 0.372949] [G loss: 1.721619]\n",
            "[Epoch 44/50] [Batch 53/600] [D loss: 0.357140] [G loss: 1.847449]\n",
            "[Epoch 44/50] [Batch 54/600] [D loss: 0.351665] [G loss: 1.774985]\n",
            "[Epoch 44/50] [Batch 55/600] [D loss: 0.391730] [G loss: 2.269106]\n",
            "[Epoch 44/50] [Batch 56/600] [D loss: 0.430350] [G loss: 1.944848]\n",
            "[Epoch 44/50] [Batch 57/600] [D loss: 0.490564] [G loss: 1.838816]\n",
            "[Epoch 44/50] [Batch 58/600] [D loss: 0.410891] [G loss: 1.827163]\n",
            "[Epoch 44/50] [Batch 59/600] [D loss: 0.423493] [G loss: 1.785493]\n",
            "[Epoch 44/50] [Batch 60/600] [D loss: 0.352356] [G loss: 1.999088]\n",
            "[Epoch 44/50] [Batch 61/600] [D loss: 0.389235] [G loss: 1.809078]\n",
            "[Epoch 44/50] [Batch 62/600] [D loss: 0.369288] [G loss: 1.560201]\n",
            "[Epoch 44/50] [Batch 63/600] [D loss: 0.417505] [G loss: 1.732647]\n",
            "[Epoch 44/50] [Batch 64/600] [D loss: 0.416942] [G loss: 1.617968]\n",
            "[Epoch 44/50] [Batch 65/600] [D loss: 0.350815] [G loss: 1.928087]\n",
            "[Epoch 44/50] [Batch 66/600] [D loss: 0.413209] [G loss: 2.137752]\n",
            "[Epoch 44/50] [Batch 67/600] [D loss: 0.422429] [G loss: 2.016682]\n",
            "[Epoch 44/50] [Batch 68/600] [D loss: 0.497138] [G loss: 1.901079]\n",
            "[Epoch 44/50] [Batch 69/600] [D loss: 0.406891] [G loss: 1.530779]\n",
            "[Epoch 44/50] [Batch 70/600] [D loss: 0.456310] [G loss: 1.532778]\n",
            "[Epoch 44/50] [Batch 71/600] [D loss: 0.447497] [G loss: 1.627364]\n",
            "[Epoch 44/50] [Batch 72/600] [D loss: 0.473555] [G loss: 1.701737]\n",
            "[Epoch 44/50] [Batch 73/600] [D loss: 0.465442] [G loss: 1.505261]\n",
            "[Epoch 44/50] [Batch 74/600] [D loss: 0.451514] [G loss: 1.563451]\n",
            "[Epoch 44/50] [Batch 75/600] [D loss: 0.413331] [G loss: 1.543442]\n",
            "[Epoch 44/50] [Batch 76/600] [D loss: 0.371372] [G loss: 1.662178]\n",
            "[Epoch 44/50] [Batch 77/600] [D loss: 0.425159] [G loss: 1.639902]\n",
            "[Epoch 44/50] [Batch 78/600] [D loss: 0.329635] [G loss: 1.946894]\n",
            "[Epoch 44/50] [Batch 79/600] [D loss: 0.423406] [G loss: 1.707161]\n",
            "[Epoch 44/50] [Batch 80/600] [D loss: 0.373045] [G loss: 1.923923]\n",
            "[Epoch 44/50] [Batch 81/600] [D loss: 0.356827] [G loss: 1.963793]\n",
            "[Epoch 44/50] [Batch 82/600] [D loss: 0.426623] [G loss: 1.753405]\n",
            "[Epoch 44/50] [Batch 83/600] [D loss: 0.394589] [G loss: 1.779439]\n",
            "[Epoch 44/50] [Batch 84/600] [D loss: 0.435644] [G loss: 1.991176]\n",
            "[Epoch 44/50] [Batch 85/600] [D loss: 0.336216] [G loss: 1.827036]\n",
            "[Epoch 44/50] [Batch 86/600] [D loss: 0.414400] [G loss: 1.589756]\n",
            "[Epoch 44/50] [Batch 87/600] [D loss: 0.404955] [G loss: 1.779935]\n",
            "[Epoch 44/50] [Batch 88/600] [D loss: 0.437217] [G loss: 1.735778]\n",
            "[Epoch 44/50] [Batch 89/600] [D loss: 0.465224] [G loss: 1.695807]\n",
            "[Epoch 44/50] [Batch 90/600] [D loss: 0.428619] [G loss: 1.860035]\n",
            "[Epoch 44/50] [Batch 91/600] [D loss: 0.446457] [G loss: 1.933987]\n",
            "[Epoch 44/50] [Batch 92/600] [D loss: 0.477941] [G loss: 1.814695]\n",
            "[Epoch 44/50] [Batch 93/600] [D loss: 0.410400] [G loss: 1.639233]\n",
            "[Epoch 44/50] [Batch 94/600] [D loss: 0.396681] [G loss: 1.805803]\n",
            "[Epoch 44/50] [Batch 95/600] [D loss: 0.389291] [G loss: 1.791682]\n",
            "[Epoch 44/50] [Batch 96/600] [D loss: 0.393714] [G loss: 1.563780]\n",
            "[Epoch 44/50] [Batch 97/600] [D loss: 0.415386] [G loss: 1.747554]\n",
            "[Epoch 44/50] [Batch 98/600] [D loss: 0.393042] [G loss: 1.873767]\n",
            "[Epoch 44/50] [Batch 99/600] [D loss: 0.433682] [G loss: 1.803200]\n",
            "[Epoch 44/50] [Batch 100/600] [D loss: 0.372847] [G loss: 1.893077]\n",
            "[Epoch 44/50] [Batch 101/600] [D loss: 0.419263] [G loss: 1.992771]\n",
            "[Epoch 44/50] [Batch 102/600] [D loss: 0.481788] [G loss: 1.669671]\n",
            "[Epoch 44/50] [Batch 103/600] [D loss: 0.402190] [G loss: 1.573405]\n",
            "[Epoch 44/50] [Batch 104/600] [D loss: 0.434363] [G loss: 1.526053]\n",
            "[Epoch 44/50] [Batch 105/600] [D loss: 0.376454] [G loss: 1.646695]\n",
            "[Epoch 44/50] [Batch 106/600] [D loss: 0.411047] [G loss: 1.658742]\n",
            "[Epoch 44/50] [Batch 107/600] [D loss: 0.423082] [G loss: 1.916403]\n",
            "[Epoch 44/50] [Batch 108/600] [D loss: 0.401011] [G loss: 1.871161]\n",
            "[Epoch 44/50] [Batch 109/600] [D loss: 0.355499] [G loss: 1.928264]\n",
            "[Epoch 44/50] [Batch 110/600] [D loss: 0.397146] [G loss: 1.848399]\n",
            "[Epoch 44/50] [Batch 111/600] [D loss: 0.490110] [G loss: 1.796742]\n",
            "[Epoch 44/50] [Batch 112/600] [D loss: 0.499773] [G loss: 1.633350]\n",
            "[Epoch 44/50] [Batch 113/600] [D loss: 0.433890] [G loss: 1.446429]\n",
            "[Epoch 44/50] [Batch 114/600] [D loss: 0.381276] [G loss: 1.807986]\n",
            "[Epoch 44/50] [Batch 115/600] [D loss: 0.446590] [G loss: 1.858603]\n",
            "[Epoch 44/50] [Batch 116/600] [D loss: 0.365914] [G loss: 1.455332]\n",
            "[Epoch 44/50] [Batch 117/600] [D loss: 0.425364] [G loss: 1.473473]\n",
            "[Epoch 44/50] [Batch 118/600] [D loss: 0.460642] [G loss: 1.505016]\n",
            "[Epoch 44/50] [Batch 119/600] [D loss: 0.466302] [G loss: 1.602043]\n",
            "[Epoch 44/50] [Batch 120/600] [D loss: 0.429995] [G loss: 1.857013]\n",
            "[Epoch 44/50] [Batch 121/600] [D loss: 0.392218] [G loss: 1.534708]\n",
            "[Epoch 44/50] [Batch 122/600] [D loss: 0.341363] [G loss: 1.734442]\n",
            "[Epoch 44/50] [Batch 123/600] [D loss: 0.380106] [G loss: 1.603209]\n",
            "[Epoch 44/50] [Batch 124/600] [D loss: 0.336062] [G loss: 2.016657]\n",
            "[Epoch 44/50] [Batch 125/600] [D loss: 0.417957] [G loss: 1.808130]\n",
            "[Epoch 44/50] [Batch 126/600] [D loss: 0.394439] [G loss: 1.910017]\n",
            "[Epoch 44/50] [Batch 127/600] [D loss: 0.376638] [G loss: 2.006471]\n",
            "[Epoch 44/50] [Batch 128/600] [D loss: 0.510269] [G loss: 1.816851]\n",
            "[Epoch 44/50] [Batch 129/600] [D loss: 0.365543] [G loss: 1.866044]\n",
            "[Epoch 44/50] [Batch 130/600] [D loss: 0.427934] [G loss: 1.827804]\n",
            "[Epoch 44/50] [Batch 131/600] [D loss: 0.389631] [G loss: 1.943540]\n",
            "[Epoch 44/50] [Batch 132/600] [D loss: 0.380064] [G loss: 1.845858]\n",
            "[Epoch 44/50] [Batch 133/600] [D loss: 0.439631] [G loss: 1.863145]\n",
            "[Epoch 44/50] [Batch 134/600] [D loss: 0.423958] [G loss: 1.809698]\n",
            "[Epoch 44/50] [Batch 135/600] [D loss: 0.439843] [G loss: 1.711026]\n",
            "[Epoch 44/50] [Batch 136/600] [D loss: 0.410873] [G loss: 1.904559]\n",
            "[Epoch 44/50] [Batch 137/600] [D loss: 0.508450] [G loss: 1.663955]\n",
            "[Epoch 44/50] [Batch 138/600] [D loss: 0.442392] [G loss: 1.623217]\n",
            "[Epoch 44/50] [Batch 139/600] [D loss: 0.339857] [G loss: 1.764406]\n",
            "[Epoch 44/50] [Batch 140/600] [D loss: 0.407554] [G loss: 1.892430]\n",
            "[Epoch 44/50] [Batch 141/600] [D loss: 0.377930] [G loss: 1.917249]\n",
            "[Epoch 44/50] [Batch 142/600] [D loss: 0.409435] [G loss: 1.822344]\n",
            "[Epoch 44/50] [Batch 143/600] [D loss: 0.398461] [G loss: 1.717868]\n",
            "[Epoch 44/50] [Batch 144/600] [D loss: 0.393324] [G loss: 1.594834]\n",
            "[Epoch 44/50] [Batch 145/600] [D loss: 0.372149] [G loss: 1.686460]\n",
            "[Epoch 44/50] [Batch 146/600] [D loss: 0.482323] [G loss: 1.699821]\n",
            "[Epoch 44/50] [Batch 147/600] [D loss: 0.443851] [G loss: 1.647822]\n",
            "[Epoch 44/50] [Batch 148/600] [D loss: 0.359215] [G loss: 1.627374]\n",
            "[Epoch 44/50] [Batch 149/600] [D loss: 0.518901] [G loss: 1.970905]\n",
            "[Epoch 44/50] [Batch 150/600] [D loss: 0.448202] [G loss: 1.690629]\n",
            "[Epoch 44/50] [Batch 151/600] [D loss: 0.458655] [G loss: 1.779846]\n",
            "[Epoch 44/50] [Batch 152/600] [D loss: 0.476838] [G loss: 1.670579]\n",
            "[Epoch 44/50] [Batch 153/600] [D loss: 0.447748] [G loss: 1.694880]\n",
            "[Epoch 44/50] [Batch 154/600] [D loss: 0.396402] [G loss: 1.498551]\n",
            "[Epoch 44/50] [Batch 155/600] [D loss: 0.404260] [G loss: 1.454840]\n",
            "[Epoch 44/50] [Batch 156/600] [D loss: 0.356793] [G loss: 1.682255]\n",
            "[Epoch 44/50] [Batch 157/600] [D loss: 0.461917] [G loss: 1.777052]\n",
            "[Epoch 44/50] [Batch 158/600] [D loss: 0.439407] [G loss: 1.706953]\n",
            "[Epoch 44/50] [Batch 159/600] [D loss: 0.453285] [G loss: 1.653674]\n",
            "[Epoch 44/50] [Batch 160/600] [D loss: 0.464422] [G loss: 1.460142]\n",
            "[Epoch 44/50] [Batch 161/600] [D loss: 0.410068] [G loss: 1.629496]\n",
            "[Epoch 44/50] [Batch 162/600] [D loss: 0.379534] [G loss: 1.692386]\n",
            "[Epoch 44/50] [Batch 163/600] [D loss: 0.413369] [G loss: 1.700135]\n",
            "[Epoch 44/50] [Batch 164/600] [D loss: 0.431131] [G loss: 1.813529]\n",
            "[Epoch 44/50] [Batch 165/600] [D loss: 0.479535] [G loss: 1.749687]\n",
            "[Epoch 44/50] [Batch 166/600] [D loss: 0.406078] [G loss: 1.603561]\n",
            "[Epoch 44/50] [Batch 167/600] [D loss: 0.393772] [G loss: 1.618138]\n",
            "[Epoch 44/50] [Batch 168/600] [D loss: 0.401309] [G loss: 1.928234]\n",
            "[Epoch 44/50] [Batch 169/600] [D loss: 0.495691] [G loss: 1.683276]\n",
            "[Epoch 44/50] [Batch 170/600] [D loss: 0.418171] [G loss: 1.621141]\n",
            "[Epoch 44/50] [Batch 171/600] [D loss: 0.473475] [G loss: 1.671045]\n",
            "[Epoch 44/50] [Batch 172/600] [D loss: 0.400399] [G loss: 1.783586]\n",
            "[Epoch 44/50] [Batch 173/600] [D loss: 0.462131] [G loss: 1.853241]\n",
            "[Epoch 44/50] [Batch 174/600] [D loss: 0.410896] [G loss: 1.784896]\n",
            "[Epoch 44/50] [Batch 175/600] [D loss: 0.452634] [G loss: 1.614275]\n",
            "[Epoch 44/50] [Batch 176/600] [D loss: 0.409324] [G loss: 1.607350]\n",
            "[Epoch 44/50] [Batch 177/600] [D loss: 0.522048] [G loss: 1.464840]\n",
            "[Epoch 44/50] [Batch 178/600] [D loss: 0.436932] [G loss: 1.542066]\n",
            "[Epoch 44/50] [Batch 179/600] [D loss: 0.427988] [G loss: 1.748412]\n",
            "[Epoch 44/50] [Batch 180/600] [D loss: 0.459219] [G loss: 1.643120]\n",
            "[Epoch 44/50] [Batch 181/600] [D loss: 0.425819] [G loss: 1.494341]\n",
            "[Epoch 44/50] [Batch 182/600] [D loss: 0.364745] [G loss: 1.571985]\n",
            "[Epoch 44/50] [Batch 183/600] [D loss: 0.437782] [G loss: 1.940321]\n",
            "[Epoch 44/50] [Batch 184/600] [D loss: 0.443281] [G loss: 1.579005]\n",
            "[Epoch 44/50] [Batch 185/600] [D loss: 0.409930] [G loss: 1.670710]\n",
            "[Epoch 44/50] [Batch 186/600] [D loss: 0.447864] [G loss: 1.656555]\n",
            "[Epoch 44/50] [Batch 187/600] [D loss: 0.388533] [G loss: 1.683188]\n",
            "[Epoch 44/50] [Batch 188/600] [D loss: 0.426016] [G loss: 1.617656]\n",
            "[Epoch 44/50] [Batch 189/600] [D loss: 0.443497] [G loss: 1.692913]\n",
            "[Epoch 44/50] [Batch 190/600] [D loss: 0.446912] [G loss: 1.631865]\n",
            "[Epoch 44/50] [Batch 191/600] [D loss: 0.425224] [G loss: 1.875057]\n",
            "[Epoch 44/50] [Batch 192/600] [D loss: 0.447599] [G loss: 1.574597]\n",
            "[Epoch 44/50] [Batch 193/600] [D loss: 0.427965] [G loss: 1.572632]\n",
            "[Epoch 44/50] [Batch 194/600] [D loss: 0.401420] [G loss: 1.440818]\n",
            "[Epoch 44/50] [Batch 195/600] [D loss: 0.462184] [G loss: 1.610891]\n",
            "[Epoch 44/50] [Batch 196/600] [D loss: 0.365141] [G loss: 1.598598]\n",
            "[Epoch 44/50] [Batch 197/600] [D loss: 0.371250] [G loss: 1.609868]\n",
            "[Epoch 44/50] [Batch 198/600] [D loss: 0.396611] [G loss: 1.779493]\n",
            "[Epoch 44/50] [Batch 199/600] [D loss: 0.369965] [G loss: 1.802548]\n",
            "[Epoch 44/50] [Batch 200/600] [D loss: 0.396961] [G loss: 1.974370]\n",
            "[Epoch 44/50] [Batch 201/600] [D loss: 0.430549] [G loss: 2.002340]\n",
            "[Epoch 44/50] [Batch 202/600] [D loss: 0.489228] [G loss: 1.795276]\n",
            "[Epoch 44/50] [Batch 203/600] [D loss: 0.458059] [G loss: 1.663642]\n",
            "[Epoch 44/50] [Batch 204/600] [D loss: 0.398717] [G loss: 1.545902]\n",
            "[Epoch 44/50] [Batch 205/600] [D loss: 0.389836] [G loss: 1.795089]\n",
            "[Epoch 44/50] [Batch 206/600] [D loss: 0.405192] [G loss: 1.689218]\n",
            "[Epoch 44/50] [Batch 207/600] [D loss: 0.452485] [G loss: 1.423085]\n",
            "[Epoch 44/50] [Batch 208/600] [D loss: 0.375726] [G loss: 1.676534]\n",
            "[Epoch 44/50] [Batch 209/600] [D loss: 0.389738] [G loss: 1.530081]\n",
            "[Epoch 44/50] [Batch 210/600] [D loss: 0.357888] [G loss: 1.924983]\n",
            "[Epoch 44/50] [Batch 211/600] [D loss: 0.432344] [G loss: 1.910359]\n",
            "[Epoch 44/50] [Batch 212/600] [D loss: 0.397985] [G loss: 1.844702]\n",
            "[Epoch 44/50] [Batch 213/600] [D loss: 0.391988] [G loss: 1.770285]\n",
            "[Epoch 44/50] [Batch 214/600] [D loss: 0.388228] [G loss: 1.878371]\n",
            "[Epoch 44/50] [Batch 215/600] [D loss: 0.375690] [G loss: 1.741309]\n",
            "[Epoch 44/50] [Batch 216/600] [D loss: 0.400615] [G loss: 1.847008]\n",
            "[Epoch 44/50] [Batch 217/600] [D loss: 0.467076] [G loss: 1.940685]\n",
            "[Epoch 44/50] [Batch 218/600] [D loss: 0.437061] [G loss: 1.918927]\n",
            "[Epoch 44/50] [Batch 219/600] [D loss: 0.319274] [G loss: 1.662278]\n",
            "[Epoch 44/50] [Batch 220/600] [D loss: 0.408677] [G loss: 1.600419]\n",
            "[Epoch 44/50] [Batch 221/600] [D loss: 0.438012] [G loss: 1.686445]\n",
            "[Epoch 44/50] [Batch 222/600] [D loss: 0.517264] [G loss: 2.013170]\n",
            "[Epoch 44/50] [Batch 223/600] [D loss: 0.434120] [G loss: 1.810577]\n",
            "[Epoch 44/50] [Batch 224/600] [D loss: 0.433686] [G loss: 1.626606]\n",
            "[Epoch 44/50] [Batch 225/600] [D loss: 0.474531] [G loss: 1.500298]\n",
            "[Epoch 44/50] [Batch 226/600] [D loss: 0.387098] [G loss: 1.401186]\n",
            "[Epoch 44/50] [Batch 227/600] [D loss: 0.415817] [G loss: 1.500551]\n",
            "[Epoch 44/50] [Batch 228/600] [D loss: 0.306477] [G loss: 1.685175]\n",
            "[Epoch 44/50] [Batch 229/600] [D loss: 0.368415] [G loss: 1.752693]\n",
            "[Epoch 44/50] [Batch 230/600] [D loss: 0.419999] [G loss: 1.822526]\n",
            "[Epoch 44/50] [Batch 231/600] [D loss: 0.434950] [G loss: 1.984361]\n",
            "[Epoch 44/50] [Batch 232/600] [D loss: 0.402908] [G loss: 1.846159]\n",
            "[Epoch 44/50] [Batch 233/600] [D loss: 0.410238] [G loss: 1.701903]\n",
            "[Epoch 44/50] [Batch 234/600] [D loss: 0.407735] [G loss: 1.706628]\n",
            "[Epoch 44/50] [Batch 235/600] [D loss: 0.435277] [G loss: 1.515708]\n",
            "[Epoch 44/50] [Batch 236/600] [D loss: 0.363233] [G loss: 2.057439]\n",
            "[Epoch 44/50] [Batch 237/600] [D loss: 0.413209] [G loss: 1.721258]\n",
            "[Epoch 44/50] [Batch 238/600] [D loss: 0.402913] [G loss: 1.704249]\n",
            "[Epoch 44/50] [Batch 239/600] [D loss: 0.425394] [G loss: 1.627334]\n",
            "[Epoch 44/50] [Batch 240/600] [D loss: 0.496219] [G loss: 1.607487]\n",
            "[Epoch 44/50] [Batch 241/600] [D loss: 0.428950] [G loss: 1.693361]\n",
            "[Epoch 44/50] [Batch 242/600] [D loss: 0.423791] [G loss: 1.774770]\n",
            "[Epoch 44/50] [Batch 243/600] [D loss: 0.398666] [G loss: 1.670487]\n",
            "[Epoch 44/50] [Batch 244/600] [D loss: 0.362113] [G loss: 1.590533]\n",
            "[Epoch 44/50] [Batch 245/600] [D loss: 0.433616] [G loss: 1.797004]\n",
            "[Epoch 44/50] [Batch 246/600] [D loss: 0.342210] [G loss: 1.944798]\n",
            "[Epoch 44/50] [Batch 247/600] [D loss: 0.487479] [G loss: 1.702409]\n",
            "[Epoch 44/50] [Batch 248/600] [D loss: 0.371473] [G loss: 1.776232]\n",
            "[Epoch 44/50] [Batch 249/600] [D loss: 0.485921] [G loss: 1.709302]\n",
            "[Epoch 44/50] [Batch 250/600] [D loss: 0.420274] [G loss: 1.710793]\n",
            "[Epoch 44/50] [Batch 251/600] [D loss: 0.441140] [G loss: 1.648599]\n",
            "[Epoch 44/50] [Batch 252/600] [D loss: 0.450787] [G loss: 1.674846]\n",
            "[Epoch 44/50] [Batch 253/600] [D loss: 0.403838] [G loss: 1.518366]\n",
            "[Epoch 44/50] [Batch 254/600] [D loss: 0.400554] [G loss: 1.530590]\n",
            "[Epoch 44/50] [Batch 255/600] [D loss: 0.419208] [G loss: 1.547149]\n",
            "[Epoch 44/50] [Batch 256/600] [D loss: 0.360032] [G loss: 1.785248]\n",
            "[Epoch 44/50] [Batch 257/600] [D loss: 0.412068] [G loss: 1.893422]\n",
            "[Epoch 44/50] [Batch 258/600] [D loss: 0.464851] [G loss: 1.857842]\n",
            "[Epoch 44/50] [Batch 259/600] [D loss: 0.447950] [G loss: 1.904700]\n",
            "[Epoch 44/50] [Batch 260/600] [D loss: 0.438133] [G loss: 1.600108]\n",
            "[Epoch 44/50] [Batch 261/600] [D loss: 0.436335] [G loss: 1.570092]\n",
            "[Epoch 44/50] [Batch 262/600] [D loss: 0.459033] [G loss: 1.627570]\n",
            "[Epoch 44/50] [Batch 263/600] [D loss: 0.399696] [G loss: 1.695780]\n",
            "[Epoch 44/50] [Batch 264/600] [D loss: 0.512234] [G loss: 1.650840]\n",
            "[Epoch 44/50] [Batch 265/600] [D loss: 0.426829] [G loss: 1.558562]\n",
            "[Epoch 44/50] [Batch 266/600] [D loss: 0.481635] [G loss: 1.488901]\n",
            "[Epoch 44/50] [Batch 267/600] [D loss: 0.403730] [G loss: 1.490883]\n",
            "[Epoch 44/50] [Batch 268/600] [D loss: 0.428290] [G loss: 1.509838]\n",
            "[Epoch 44/50] [Batch 269/600] [D loss: 0.481553] [G loss: 1.427418]\n",
            "[Epoch 44/50] [Batch 270/600] [D loss: 0.446146] [G loss: 1.635794]\n",
            "[Epoch 44/50] [Batch 271/600] [D loss: 0.454909] [G loss: 1.716625]\n",
            "[Epoch 44/50] [Batch 272/600] [D loss: 0.418865] [G loss: 1.530726]\n",
            "[Epoch 44/50] [Batch 273/600] [D loss: 0.444792] [G loss: 1.562889]\n",
            "[Epoch 44/50] [Batch 274/600] [D loss: 0.387428] [G loss: 1.797808]\n",
            "[Epoch 44/50] [Batch 275/600] [D loss: 0.447015] [G loss: 1.826600]\n",
            "[Epoch 44/50] [Batch 276/600] [D loss: 0.384802] [G loss: 1.798375]\n",
            "[Epoch 44/50] [Batch 277/600] [D loss: 0.425305] [G loss: 2.117359]\n",
            "[Epoch 44/50] [Batch 278/600] [D loss: 0.446789] [G loss: 1.794006]\n",
            "[Epoch 44/50] [Batch 279/600] [D loss: 0.513819] [G loss: 1.638434]\n",
            "[Epoch 44/50] [Batch 280/600] [D loss: 0.414214] [G loss: 1.690165]\n",
            "[Epoch 44/50] [Batch 281/600] [D loss: 0.450615] [G loss: 1.625235]\n",
            "[Epoch 44/50] [Batch 282/600] [D loss: 0.424347] [G loss: 1.421734]\n",
            "[Epoch 44/50] [Batch 283/600] [D loss: 0.469061] [G loss: 1.416030]\n",
            "[Epoch 44/50] [Batch 284/600] [D loss: 0.404648] [G loss: 1.616627]\n",
            "[Epoch 44/50] [Batch 285/600] [D loss: 0.382990] [G loss: 1.554680]\n",
            "[Epoch 44/50] [Batch 286/600] [D loss: 0.404078] [G loss: 1.671580]\n",
            "[Epoch 44/50] [Batch 287/600] [D loss: 0.504529] [G loss: 1.595198]\n",
            "[Epoch 44/50] [Batch 288/600] [D loss: 0.298808] [G loss: 1.834089]\n",
            "[Epoch 44/50] [Batch 289/600] [D loss: 0.378015] [G loss: 1.774289]\n",
            "[Epoch 44/50] [Batch 290/600] [D loss: 0.457308] [G loss: 1.839869]\n",
            "[Epoch 44/50] [Batch 291/600] [D loss: 0.487258] [G loss: 1.839073]\n",
            "[Epoch 44/50] [Batch 292/600] [D loss: 0.421738] [G loss: 1.601339]\n",
            "[Epoch 44/50] [Batch 293/600] [D loss: 0.454477] [G loss: 1.406867]\n",
            "[Epoch 44/50] [Batch 294/600] [D loss: 0.384750] [G loss: 1.518318]\n",
            "[Epoch 44/50] [Batch 295/600] [D loss: 0.403145] [G loss: 1.516647]\n",
            "[Epoch 44/50] [Batch 296/600] [D loss: 0.433231] [G loss: 1.554506]\n",
            "[Epoch 44/50] [Batch 297/600] [D loss: 0.456654] [G loss: 1.724242]\n",
            "[Epoch 44/50] [Batch 298/600] [D loss: 0.460242] [G loss: 1.645366]\n",
            "[Epoch 44/50] [Batch 299/600] [D loss: 0.435683] [G loss: 1.711892]\n",
            "[Epoch 44/50] [Batch 300/600] [D loss: 0.409301] [G loss: 1.637116]\n",
            "[Epoch 44/50] [Batch 301/600] [D loss: 0.381782] [G loss: 1.641826]\n",
            "[Epoch 44/50] [Batch 302/600] [D loss: 0.386929] [G loss: 1.764801]\n",
            "[Epoch 44/50] [Batch 303/600] [D loss: 0.469778] [G loss: 1.618822]\n",
            "[Epoch 44/50] [Batch 304/600] [D loss: 0.455669] [G loss: 1.520261]\n",
            "[Epoch 44/50] [Batch 305/600] [D loss: 0.426978] [G loss: 1.756147]\n",
            "[Epoch 44/50] [Batch 306/600] [D loss: 0.527538] [G loss: 1.492953]\n",
            "[Epoch 44/50] [Batch 307/600] [D loss: 0.453695] [G loss: 1.695733]\n",
            "[Epoch 44/50] [Batch 308/600] [D loss: 0.510792] [G loss: 1.607371]\n",
            "[Epoch 44/50] [Batch 309/600] [D loss: 0.424441] [G loss: 1.844911]\n",
            "[Epoch 44/50] [Batch 310/600] [D loss: 0.371353] [G loss: 1.607308]\n",
            "[Epoch 44/50] [Batch 311/600] [D loss: 0.380208] [G loss: 1.482617]\n",
            "[Epoch 44/50] [Batch 312/600] [D loss: 0.446350] [G loss: 1.628108]\n",
            "[Epoch 44/50] [Batch 313/600] [D loss: 0.465254] [G loss: 1.682763]\n",
            "[Epoch 44/50] [Batch 314/600] [D loss: 0.444315] [G loss: 1.648942]\n",
            "[Epoch 44/50] [Batch 315/600] [D loss: 0.452945] [G loss: 1.709309]\n",
            "[Epoch 44/50] [Batch 316/600] [D loss: 0.506363] [G loss: 1.614470]\n",
            "[Epoch 44/50] [Batch 317/600] [D loss: 0.476749] [G loss: 1.720462]\n",
            "[Epoch 44/50] [Batch 318/600] [D loss: 0.443780] [G loss: 1.591048]\n",
            "[Epoch 44/50] [Batch 319/600] [D loss: 0.410909] [G loss: 1.503901]\n",
            "[Epoch 44/50] [Batch 320/600] [D loss: 0.442132] [G loss: 1.779660]\n",
            "[Epoch 44/50] [Batch 321/600] [D loss: 0.449934] [G loss: 1.599908]\n",
            "[Epoch 44/50] [Batch 322/600] [D loss: 0.381783] [G loss: 1.538969]\n",
            "[Epoch 44/50] [Batch 323/600] [D loss: 0.432153] [G loss: 1.522800]\n",
            "[Epoch 44/50] [Batch 324/600] [D loss: 0.368128] [G loss: 1.685520]\n",
            "[Epoch 44/50] [Batch 325/600] [D loss: 0.416489] [G loss: 1.564179]\n",
            "[Epoch 44/50] [Batch 326/600] [D loss: 0.469432] [G loss: 1.811909]\n",
            "[Epoch 44/50] [Batch 327/600] [D loss: 0.461090] [G loss: 1.980849]\n",
            "[Epoch 44/50] [Batch 328/600] [D loss: 0.415661] [G loss: 1.779888]\n",
            "[Epoch 44/50] [Batch 329/600] [D loss: 0.377889] [G loss: 1.587515]\n",
            "[Epoch 44/50] [Batch 330/600] [D loss: 0.335958] [G loss: 1.835614]\n",
            "[Epoch 44/50] [Batch 331/600] [D loss: 0.416983] [G loss: 1.724893]\n",
            "[Epoch 44/50] [Batch 332/600] [D loss: 0.405176] [G loss: 1.706936]\n",
            "[Epoch 44/50] [Batch 333/600] [D loss: 0.334147] [G loss: 1.808767]\n",
            "[Epoch 44/50] [Batch 334/600] [D loss: 0.383076] [G loss: 1.936147]\n",
            "[Epoch 44/50] [Batch 335/600] [D loss: 0.430261] [G loss: 1.970258]\n",
            "[Epoch 44/50] [Batch 336/600] [D loss: 0.423663] [G loss: 1.757747]\n",
            "[Epoch 44/50] [Batch 337/600] [D loss: 0.497614] [G loss: 1.837536]\n",
            "[Epoch 44/50] [Batch 338/600] [D loss: 0.419653] [G loss: 1.861812]\n",
            "[Epoch 44/50] [Batch 339/600] [D loss: 0.467550] [G loss: 1.525803]\n",
            "[Epoch 44/50] [Batch 340/600] [D loss: 0.416690] [G loss: 1.545016]\n",
            "[Epoch 44/50] [Batch 341/600] [D loss: 0.374017] [G loss: 1.811313]\n",
            "[Epoch 44/50] [Batch 342/600] [D loss: 0.463861] [G loss: 1.489257]\n",
            "[Epoch 44/50] [Batch 343/600] [D loss: 0.439152] [G loss: 1.738581]\n",
            "[Epoch 44/50] [Batch 344/600] [D loss: 0.421155] [G loss: 1.733483]\n",
            "[Epoch 44/50] [Batch 345/600] [D loss: 0.409025] [G loss: 1.588495]\n",
            "[Epoch 44/50] [Batch 346/600] [D loss: 0.447374] [G loss: 1.627439]\n",
            "[Epoch 44/50] [Batch 347/600] [D loss: 0.436382] [G loss: 1.440861]\n",
            "[Epoch 44/50] [Batch 348/600] [D loss: 0.444984] [G loss: 1.589638]\n",
            "[Epoch 44/50] [Batch 349/600] [D loss: 0.406402] [G loss: 1.767466]\n",
            "[Epoch 44/50] [Batch 350/600] [D loss: 0.447349] [G loss: 1.666994]\n",
            "[Epoch 44/50] [Batch 351/600] [D loss: 0.466774] [G loss: 1.570850]\n",
            "[Epoch 44/50] [Batch 352/600] [D loss: 0.414311] [G loss: 1.515585]\n",
            "[Epoch 44/50] [Batch 353/600] [D loss: 0.451493] [G loss: 1.447814]\n",
            "[Epoch 44/50] [Batch 354/600] [D loss: 0.357297] [G loss: 1.786569]\n",
            "[Epoch 44/50] [Batch 355/600] [D loss: 0.394738] [G loss: 1.803825]\n",
            "[Epoch 44/50] [Batch 356/600] [D loss: 0.420489] [G loss: 1.905725]\n",
            "[Epoch 44/50] [Batch 357/600] [D loss: 0.438740] [G loss: 1.750580]\n",
            "[Epoch 44/50] [Batch 358/600] [D loss: 0.418899] [G loss: 1.783022]\n",
            "[Epoch 44/50] [Batch 359/600] [D loss: 0.449385] [G loss: 1.498049]\n",
            "[Epoch 44/50] [Batch 360/600] [D loss: 0.443179] [G loss: 1.605002]\n",
            "[Epoch 44/50] [Batch 361/600] [D loss: 0.359809] [G loss: 1.743825]\n",
            "[Epoch 44/50] [Batch 362/600] [D loss: 0.390786] [G loss: 1.817595]\n",
            "[Epoch 44/50] [Batch 363/600] [D loss: 0.373097] [G loss: 1.917356]\n",
            "[Epoch 44/50] [Batch 364/600] [D loss: 0.452571] [G loss: 1.951991]\n",
            "[Epoch 44/50] [Batch 365/600] [D loss: 0.422655] [G loss: 1.841762]\n",
            "[Epoch 44/50] [Batch 366/600] [D loss: 0.413542] [G loss: 1.762202]\n",
            "[Epoch 44/50] [Batch 367/600] [D loss: 0.353733] [G loss: 1.732365]\n",
            "[Epoch 44/50] [Batch 368/600] [D loss: 0.443796] [G loss: 1.839715]\n",
            "[Epoch 44/50] [Batch 369/600] [D loss: 0.445653] [G loss: 1.877941]\n",
            "[Epoch 44/50] [Batch 370/600] [D loss: 0.457131] [G loss: 1.776996]\n",
            "[Epoch 44/50] [Batch 371/600] [D loss: 0.359013] [G loss: 1.741128]\n",
            "[Epoch 44/50] [Batch 372/600] [D loss: 0.349672] [G loss: 1.593261]\n",
            "[Epoch 44/50] [Batch 373/600] [D loss: 0.414351] [G loss: 1.601815]\n",
            "[Epoch 44/50] [Batch 374/600] [D loss: 0.494110] [G loss: 1.987459]\n",
            "[Epoch 44/50] [Batch 375/600] [D loss: 0.463091] [G loss: 1.737077]\n",
            "[Epoch 44/50] [Batch 376/600] [D loss: 0.436957] [G loss: 1.620914]\n",
            "[Epoch 44/50] [Batch 377/600] [D loss: 0.435873] [G loss: 1.863226]\n",
            "[Epoch 44/50] [Batch 378/600] [D loss: 0.398888] [G loss: 1.841904]\n",
            "[Epoch 44/50] [Batch 379/600] [D loss: 0.360488] [G loss: 1.921282]\n",
            "[Epoch 44/50] [Batch 380/600] [D loss: 0.436712] [G loss: 1.871774]\n",
            "[Epoch 44/50] [Batch 381/600] [D loss: 0.382458] [G loss: 1.644617]\n",
            "[Epoch 44/50] [Batch 382/600] [D loss: 0.389617] [G loss: 1.720393]\n",
            "[Epoch 44/50] [Batch 383/600] [D loss: 0.472373] [G loss: 1.747491]\n",
            "[Epoch 44/50] [Batch 384/600] [D loss: 0.427495] [G loss: 1.739841]\n",
            "[Epoch 44/50] [Batch 385/600] [D loss: 0.404785] [G loss: 1.935229]\n",
            "[Epoch 44/50] [Batch 386/600] [D loss: 0.353775] [G loss: 2.016117]\n",
            "[Epoch 44/50] [Batch 387/600] [D loss: 0.496411] [G loss: 1.919815]\n",
            "[Epoch 44/50] [Batch 388/600] [D loss: 0.439663] [G loss: 1.565852]\n",
            "[Epoch 44/50] [Batch 389/600] [D loss: 0.470863] [G loss: 1.650777]\n",
            "[Epoch 44/50] [Batch 390/600] [D loss: 0.353581] [G loss: 1.620506]\n",
            "[Epoch 44/50] [Batch 391/600] [D loss: 0.365575] [G loss: 1.836779]\n",
            "[Epoch 44/50] [Batch 392/600] [D loss: 0.403386] [G loss: 1.782055]\n",
            "[Epoch 44/50] [Batch 393/600] [D loss: 0.439290] [G loss: 1.498943]\n",
            "[Epoch 44/50] [Batch 394/600] [D loss: 0.406938] [G loss: 1.591909]\n",
            "[Epoch 44/50] [Batch 395/600] [D loss: 0.454399] [G loss: 1.593142]\n",
            "[Epoch 44/50] [Batch 396/600] [D loss: 0.431095] [G loss: 1.718084]\n",
            "[Epoch 44/50] [Batch 397/600] [D loss: 0.453525] [G loss: 1.777336]\n",
            "[Epoch 44/50] [Batch 398/600] [D loss: 0.447372] [G loss: 1.497181]\n",
            "[Epoch 44/50] [Batch 399/600] [D loss: 0.465626] [G loss: 1.716696]\n",
            "[Epoch 44/50] [Batch 400/600] [D loss: 0.355560] [G loss: 1.670399]\n",
            "[Epoch 44/50] [Batch 401/600] [D loss: 0.424326] [G loss: 1.659543]\n",
            "[Epoch 44/50] [Batch 402/600] [D loss: 0.438510] [G loss: 1.652337]\n",
            "[Epoch 44/50] [Batch 403/600] [D loss: 0.434066] [G loss: 1.558926]\n",
            "[Epoch 44/50] [Batch 404/600] [D loss: 0.371660] [G loss: 1.860281]\n",
            "[Epoch 44/50] [Batch 405/600] [D loss: 0.371285] [G loss: 1.652421]\n",
            "[Epoch 44/50] [Batch 406/600] [D loss: 0.411807] [G loss: 1.824024]\n",
            "[Epoch 44/50] [Batch 407/600] [D loss: 0.391068] [G loss: 1.709827]\n",
            "[Epoch 44/50] [Batch 408/600] [D loss: 0.386046] [G loss: 2.050819]\n",
            "[Epoch 44/50] [Batch 409/600] [D loss: 0.432954] [G loss: 1.862258]\n",
            "[Epoch 44/50] [Batch 410/600] [D loss: 0.424248] [G loss: 1.852346]\n",
            "[Epoch 44/50] [Batch 411/600] [D loss: 0.434509] [G loss: 1.871201]\n",
            "[Epoch 44/50] [Batch 412/600] [D loss: 0.407409] [G loss: 1.693805]\n",
            "[Epoch 44/50] [Batch 413/600] [D loss: 0.411202] [G loss: 1.740700]\n",
            "[Epoch 44/50] [Batch 414/600] [D loss: 0.400484] [G loss: 1.582313]\n",
            "[Epoch 44/50] [Batch 415/600] [D loss: 0.385331] [G loss: 1.653538]\n",
            "[Epoch 44/50] [Batch 416/600] [D loss: 0.433977] [G loss: 1.819754]\n",
            "[Epoch 44/50] [Batch 417/600] [D loss: 0.479085] [G loss: 1.711277]\n",
            "[Epoch 44/50] [Batch 418/600] [D loss: 0.393182] [G loss: 1.738969]\n",
            "[Epoch 44/50] [Batch 419/600] [D loss: 0.486580] [G loss: 1.753245]\n",
            "[Epoch 44/50] [Batch 420/600] [D loss: 0.402791] [G loss: 1.833061]\n",
            "[Epoch 44/50] [Batch 421/600] [D loss: 0.377973] [G loss: 1.744442]\n",
            "[Epoch 44/50] [Batch 422/600] [D loss: 0.358720] [G loss: 1.737681]\n",
            "[Epoch 44/50] [Batch 423/600] [D loss: 0.301696] [G loss: 1.695924]\n",
            "[Epoch 44/50] [Batch 424/600] [D loss: 0.435741] [G loss: 1.541254]\n",
            "[Epoch 44/50] [Batch 425/600] [D loss: 0.426118] [G loss: 1.871213]\n",
            "[Epoch 44/50] [Batch 426/600] [D loss: 0.390235] [G loss: 1.813105]\n",
            "[Epoch 44/50] [Batch 427/600] [D loss: 0.378009] [G loss: 1.762372]\n",
            "[Epoch 44/50] [Batch 428/600] [D loss: 0.432855] [G loss: 1.830170]\n",
            "[Epoch 44/50] [Batch 429/600] [D loss: 0.462328] [G loss: 1.863560]\n",
            "[Epoch 44/50] [Batch 430/600] [D loss: 0.462015] [G loss: 1.708983]\n",
            "[Epoch 44/50] [Batch 431/600] [D loss: 0.441102] [G loss: 1.560330]\n",
            "[Epoch 44/50] [Batch 432/600] [D loss: 0.398641] [G loss: 1.508322]\n",
            "[Epoch 44/50] [Batch 433/600] [D loss: 0.367999] [G loss: 1.761232]\n",
            "[Epoch 44/50] [Batch 434/600] [D loss: 0.399631] [G loss: 1.640435]\n",
            "[Epoch 44/50] [Batch 435/600] [D loss: 0.446759] [G loss: 1.623092]\n",
            "[Epoch 44/50] [Batch 436/600] [D loss: 0.356547] [G loss: 1.928875]\n",
            "[Epoch 44/50] [Batch 437/600] [D loss: 0.529743] [G loss: 1.734249]\n",
            "[Epoch 44/50] [Batch 438/600] [D loss: 0.430301] [G loss: 1.852564]\n",
            "[Epoch 44/50] [Batch 439/600] [D loss: 0.447673] [G loss: 1.660526]\n",
            "[Epoch 44/50] [Batch 440/600] [D loss: 0.376474] [G loss: 1.641244]\n",
            "[Epoch 44/50] [Batch 441/600] [D loss: 0.390743] [G loss: 1.642602]\n",
            "[Epoch 44/50] [Batch 442/600] [D loss: 0.405931] [G loss: 1.697418]\n",
            "[Epoch 44/50] [Batch 443/600] [D loss: 0.367350] [G loss: 1.918682]\n",
            "[Epoch 44/50] [Batch 444/600] [D loss: 0.413383] [G loss: 1.848581]\n",
            "[Epoch 44/50] [Batch 445/600] [D loss: 0.400218] [G loss: 1.932713]\n",
            "[Epoch 44/50] [Batch 446/600] [D loss: 0.395332] [G loss: 1.680143]\n",
            "[Epoch 44/50] [Batch 447/600] [D loss: 0.394950] [G loss: 1.690803]\n",
            "[Epoch 44/50] [Batch 448/600] [D loss: 0.437987] [G loss: 1.848484]\n",
            "[Epoch 44/50] [Batch 449/600] [D loss: 0.556359] [G loss: 1.736251]\n",
            "[Epoch 44/50] [Batch 450/600] [D loss: 0.440867] [G loss: 1.694235]\n",
            "[Epoch 44/50] [Batch 451/600] [D loss: 0.446364] [G loss: 1.405368]\n",
            "[Epoch 44/50] [Batch 452/600] [D loss: 0.389178] [G loss: 1.807311]\n",
            "[Epoch 44/50] [Batch 453/600] [D loss: 0.444887] [G loss: 1.565449]\n",
            "[Epoch 44/50] [Batch 454/600] [D loss: 0.430682] [G loss: 1.845471]\n",
            "[Epoch 44/50] [Batch 455/600] [D loss: 0.477917] [G loss: 1.769655]\n",
            "[Epoch 44/50] [Batch 456/600] [D loss: 0.417108] [G loss: 1.824542]\n",
            "[Epoch 44/50] [Batch 457/600] [D loss: 0.455200] [G loss: 1.550154]\n",
            "[Epoch 44/50] [Batch 458/600] [D loss: 0.438729] [G loss: 1.530840]\n",
            "[Epoch 44/50] [Batch 459/600] [D loss: 0.378382] [G loss: 1.558170]\n",
            "[Epoch 44/50] [Batch 460/600] [D loss: 0.466596] [G loss: 1.440867]\n",
            "[Epoch 44/50] [Batch 461/600] [D loss: 0.522833] [G loss: 1.528594]\n",
            "[Epoch 44/50] [Batch 462/600] [D loss: 0.427356] [G loss: 1.809131]\n",
            "[Epoch 44/50] [Batch 463/600] [D loss: 0.405259] [G loss: 1.774360]\n",
            "[Epoch 44/50] [Batch 464/600] [D loss: 0.399324] [G loss: 1.652537]\n",
            "[Epoch 44/50] [Batch 465/600] [D loss: 0.361547] [G loss: 1.686364]\n",
            "[Epoch 44/50] [Batch 466/600] [D loss: 0.468688] [G loss: 1.667215]\n",
            "[Epoch 44/50] [Batch 467/600] [D loss: 0.422555] [G loss: 1.803419]\n",
            "[Epoch 44/50] [Batch 468/600] [D loss: 0.396518] [G loss: 1.514974]\n",
            "[Epoch 44/50] [Batch 469/600] [D loss: 0.431993] [G loss: 1.729982]\n",
            "[Epoch 44/50] [Batch 470/600] [D loss: 0.311444] [G loss: 1.662225]\n",
            "[Epoch 44/50] [Batch 471/600] [D loss: 0.426589] [G loss: 1.991265]\n",
            "[Epoch 44/50] [Batch 472/600] [D loss: 0.447993] [G loss: 1.866368]\n",
            "[Epoch 44/50] [Batch 473/600] [D loss: 0.360555] [G loss: 1.715611]\n",
            "[Epoch 44/50] [Batch 474/600] [D loss: 0.421883] [G loss: 1.587633]\n",
            "[Epoch 44/50] [Batch 475/600] [D loss: 0.401916] [G loss: 1.665125]\n",
            "[Epoch 44/50] [Batch 476/600] [D loss: 0.359846] [G loss: 1.899833]\n",
            "[Epoch 44/50] [Batch 477/600] [D loss: 0.384771] [G loss: 1.660760]\n",
            "[Epoch 44/50] [Batch 478/600] [D loss: 0.428719] [G loss: 1.929685]\n",
            "[Epoch 44/50] [Batch 479/600] [D loss: 0.380931] [G loss: 1.904627]\n",
            "[Epoch 44/50] [Batch 480/600] [D loss: 0.461446] [G loss: 1.685249]\n",
            "[Epoch 44/50] [Batch 481/600] [D loss: 0.380211] [G loss: 1.749474]\n",
            "[Epoch 44/50] [Batch 482/600] [D loss: 0.375902] [G loss: 1.622493]\n",
            "[Epoch 44/50] [Batch 483/600] [D loss: 0.432868] [G loss: 1.657226]\n",
            "[Epoch 44/50] [Batch 484/600] [D loss: 0.363718] [G loss: 1.785592]\n",
            "[Epoch 44/50] [Batch 485/600] [D loss: 0.364380] [G loss: 1.812203]\n",
            "[Epoch 44/50] [Batch 486/600] [D loss: 0.451063] [G loss: 1.726815]\n",
            "[Epoch 44/50] [Batch 487/600] [D loss: 0.384117] [G loss: 1.739283]\n",
            "[Epoch 44/50] [Batch 488/600] [D loss: 0.387834] [G loss: 1.730107]\n",
            "[Epoch 44/50] [Batch 489/600] [D loss: 0.477988] [G loss: 1.754945]\n",
            "[Epoch 44/50] [Batch 490/600] [D loss: 0.510155] [G loss: 1.728295]\n",
            "[Epoch 44/50] [Batch 491/600] [D loss: 0.358797] [G loss: 1.623005]\n",
            "[Epoch 44/50] [Batch 492/600] [D loss: 0.452215] [G loss: 1.783494]\n",
            "[Epoch 44/50] [Batch 493/600] [D loss: 0.478889] [G loss: 1.781792]\n",
            "[Epoch 44/50] [Batch 494/600] [D loss: 0.467019] [G loss: 1.812765]\n",
            "[Epoch 44/50] [Batch 495/600] [D loss: 0.349759] [G loss: 1.647357]\n",
            "[Epoch 44/50] [Batch 496/600] [D loss: 0.422415] [G loss: 1.845706]\n",
            "[Epoch 44/50] [Batch 497/600] [D loss: 0.387329] [G loss: 1.540315]\n",
            "[Epoch 44/50] [Batch 498/600] [D loss: 0.401334] [G loss: 1.502781]\n",
            "[Epoch 44/50] [Batch 499/600] [D loss: 0.416408] [G loss: 1.567565]\n",
            "[Epoch 44/50] [Batch 500/600] [D loss: 0.449710] [G loss: 1.934760]\n",
            "[Epoch 44/50] [Batch 501/600] [D loss: 0.385500] [G loss: 1.835146]\n",
            "[Epoch 44/50] [Batch 502/600] [D loss: 0.445497] [G loss: 1.692145]\n",
            "[Epoch 44/50] [Batch 503/600] [D loss: 0.445955] [G loss: 1.880116]\n",
            "[Epoch 44/50] [Batch 504/600] [D loss: 0.421537] [G loss: 1.659920]\n",
            "[Epoch 44/50] [Batch 505/600] [D loss: 0.398823] [G loss: 1.641566]\n",
            "[Epoch 44/50] [Batch 506/600] [D loss: 0.398653] [G loss: 1.617890]\n",
            "[Epoch 44/50] [Batch 507/600] [D loss: 0.501849] [G loss: 1.764403]\n",
            "[Epoch 44/50] [Batch 508/600] [D loss: 0.548421] [G loss: 1.610925]\n",
            "[Epoch 44/50] [Batch 509/600] [D loss: 0.420444] [G loss: 1.604691]\n",
            "[Epoch 44/50] [Batch 510/600] [D loss: 0.384977] [G loss: 1.461438]\n",
            "[Epoch 44/50] [Batch 511/600] [D loss: 0.448916] [G loss: 1.426508]\n",
            "[Epoch 44/50] [Batch 512/600] [D loss: 0.412180] [G loss: 1.451696]\n",
            "[Epoch 44/50] [Batch 513/600] [D loss: 0.344685] [G loss: 1.681776]\n",
            "[Epoch 44/50] [Batch 514/600] [D loss: 0.464523] [G loss: 1.650794]\n",
            "[Epoch 44/50] [Batch 515/600] [D loss: 0.411065] [G loss: 1.704599]\n",
            "[Epoch 44/50] [Batch 516/600] [D loss: 0.373238] [G loss: 1.894755]\n",
            "[Epoch 44/50] [Batch 517/600] [D loss: 0.446406] [G loss: 1.803006]\n",
            "[Epoch 44/50] [Batch 518/600] [D loss: 0.441131] [G loss: 1.935194]\n",
            "[Epoch 44/50] [Batch 519/600] [D loss: 0.497903] [G loss: 1.792540]\n",
            "[Epoch 44/50] [Batch 520/600] [D loss: 0.428085] [G loss: 1.657070]\n",
            "[Epoch 44/50] [Batch 521/600] [D loss: 0.407409] [G loss: 1.474942]\n",
            "[Epoch 44/50] [Batch 522/600] [D loss: 0.458322] [G loss: 1.552140]\n",
            "[Epoch 44/50] [Batch 523/600] [D loss: 0.509211] [G loss: 1.416215]\n",
            "[Epoch 44/50] [Batch 524/600] [D loss: 0.412427] [G loss: 1.624293]\n",
            "[Epoch 44/50] [Batch 525/600] [D loss: 0.387452] [G loss: 1.646436]\n",
            "[Epoch 44/50] [Batch 526/600] [D loss: 0.375873] [G loss: 1.578002]\n",
            "[Epoch 44/50] [Batch 527/600] [D loss: 0.399831] [G loss: 1.699119]\n",
            "[Epoch 44/50] [Batch 528/600] [D loss: 0.444174] [G loss: 1.462953]\n",
            "[Epoch 44/50] [Batch 529/600] [D loss: 0.501546] [G loss: 1.802728]\n",
            "[Epoch 44/50] [Batch 530/600] [D loss: 0.435765] [G loss: 1.604129]\n",
            "[Epoch 44/50] [Batch 531/600] [D loss: 0.473057] [G loss: 1.465447]\n",
            "[Epoch 44/50] [Batch 532/600] [D loss: 0.412774] [G loss: 1.432469]\n",
            "[Epoch 44/50] [Batch 533/600] [D loss: 0.413945] [G loss: 1.529138]\n",
            "[Epoch 44/50] [Batch 534/600] [D loss: 0.394409] [G loss: 1.697040]\n",
            "[Epoch 44/50] [Batch 535/600] [D loss: 0.440817] [G loss: 1.665778]\n",
            "[Epoch 44/50] [Batch 536/600] [D loss: 0.426554] [G loss: 1.845577]\n",
            "[Epoch 44/50] [Batch 537/600] [D loss: 0.469538] [G loss: 1.837740]\n",
            "[Epoch 44/50] [Batch 538/600] [D loss: 0.398027] [G loss: 1.527529]\n",
            "[Epoch 44/50] [Batch 539/600] [D loss: 0.435142] [G loss: 1.468560]\n",
            "[Epoch 44/50] [Batch 540/600] [D loss: 0.382506] [G loss: 1.592021]\n",
            "[Epoch 44/50] [Batch 541/600] [D loss: 0.460131] [G loss: 1.477794]\n",
            "[Epoch 44/50] [Batch 542/600] [D loss: 0.407721] [G loss: 1.597485]\n",
            "[Epoch 44/50] [Batch 543/600] [D loss: 0.397762] [G loss: 1.793714]\n",
            "[Epoch 44/50] [Batch 544/600] [D loss: 0.453586] [G loss: 1.765713]\n",
            "[Epoch 44/50] [Batch 545/600] [D loss: 0.385970] [G loss: 1.736377]\n",
            "[Epoch 44/50] [Batch 546/600] [D loss: 0.406833] [G loss: 1.699636]\n",
            "[Epoch 44/50] [Batch 547/600] [D loss: 0.450012] [G loss: 1.663786]\n",
            "[Epoch 44/50] [Batch 548/600] [D loss: 0.430852] [G loss: 1.731646]\n",
            "[Epoch 44/50] [Batch 549/600] [D loss: 0.416798] [G loss: 1.859542]\n",
            "[Epoch 44/50] [Batch 550/600] [D loss: 0.397112] [G loss: 1.628787]\n",
            "[Epoch 44/50] [Batch 551/600] [D loss: 0.349240] [G loss: 1.659926]\n",
            "[Epoch 44/50] [Batch 552/600] [D loss: 0.402316] [G loss: 1.737123]\n",
            "[Epoch 44/50] [Batch 553/600] [D loss: 0.408409] [G loss: 1.751748]\n",
            "[Epoch 44/50] [Batch 554/600] [D loss: 0.477750] [G loss: 1.767386]\n",
            "[Epoch 44/50] [Batch 555/600] [D loss: 0.385700] [G loss: 1.778988]\n",
            "[Epoch 44/50] [Batch 556/600] [D loss: 0.398104] [G loss: 1.963126]\n",
            "[Epoch 44/50] [Batch 557/600] [D loss: 0.370134] [G loss: 1.978158]\n",
            "[Epoch 44/50] [Batch 558/600] [D loss: 0.424554] [G loss: 2.131570]\n",
            "[Epoch 44/50] [Batch 559/600] [D loss: 0.340641] [G loss: 2.006983]\n",
            "[Epoch 44/50] [Batch 560/600] [D loss: 0.412776] [G loss: 1.636208]\n",
            "[Epoch 44/50] [Batch 561/600] [D loss: 0.387365] [G loss: 1.977272]\n",
            "[Epoch 44/50] [Batch 562/600] [D loss: 0.417237] [G loss: 1.836852]\n",
            "[Epoch 44/50] [Batch 563/600] [D loss: 0.476650] [G loss: 1.958041]\n",
            "[Epoch 44/50] [Batch 564/600] [D loss: 0.518800] [G loss: 2.111753]\n",
            "[Epoch 44/50] [Batch 565/600] [D loss: 0.447352] [G loss: 1.678683]\n",
            "[Epoch 44/50] [Batch 566/600] [D loss: 0.526594] [G loss: 1.361756]\n",
            "[Epoch 44/50] [Batch 567/600] [D loss: 0.449269] [G loss: 1.578318]\n",
            "[Epoch 44/50] [Batch 568/600] [D loss: 0.431235] [G loss: 1.557819]\n",
            "[Epoch 44/50] [Batch 569/600] [D loss: 0.377270] [G loss: 1.713949]\n",
            "[Epoch 44/50] [Batch 570/600] [D loss: 0.482576] [G loss: 1.725155]\n",
            "[Epoch 44/50] [Batch 571/600] [D loss: 0.419298] [G loss: 1.581274]\n",
            "[Epoch 44/50] [Batch 572/600] [D loss: 0.403486] [G loss: 1.618826]\n",
            "[Epoch 44/50] [Batch 573/600] [D loss: 0.389249] [G loss: 1.762933]\n",
            "[Epoch 44/50] [Batch 574/600] [D loss: 0.477933] [G loss: 1.520649]\n",
            "[Epoch 44/50] [Batch 575/600] [D loss: 0.378404] [G loss: 1.708148]\n",
            "[Epoch 44/50] [Batch 576/600] [D loss: 0.511976] [G loss: 1.377121]\n",
            "[Epoch 44/50] [Batch 577/600] [D loss: 0.416064] [G loss: 1.803820]\n",
            "[Epoch 44/50] [Batch 578/600] [D loss: 0.437863] [G loss: 1.866132]\n",
            "[Epoch 44/50] [Batch 579/600] [D loss: 0.349701] [G loss: 1.737324]\n",
            "[Epoch 44/50] [Batch 580/600] [D loss: 0.433664] [G loss: 1.604878]\n",
            "[Epoch 44/50] [Batch 581/600] [D loss: 0.388048] [G loss: 1.738835]\n",
            "[Epoch 44/50] [Batch 582/600] [D loss: 0.376791] [G loss: 1.678744]\n",
            "[Epoch 44/50] [Batch 583/600] [D loss: 0.425263] [G loss: 1.919636]\n",
            "[Epoch 44/50] [Batch 584/600] [D loss: 0.423099] [G loss: 1.720978]\n",
            "[Epoch 44/50] [Batch 585/600] [D loss: 0.433795] [G loss: 1.930222]\n",
            "[Epoch 44/50] [Batch 586/600] [D loss: 0.456889] [G loss: 1.543253]\n",
            "[Epoch 44/50] [Batch 587/600] [D loss: 0.431583] [G loss: 1.432231]\n",
            "[Epoch 44/50] [Batch 588/600] [D loss: 0.448117] [G loss: 1.533150]\n",
            "[Epoch 44/50] [Batch 589/600] [D loss: 0.375534] [G loss: 1.617914]\n",
            "[Epoch 44/50] [Batch 590/600] [D loss: 0.377106] [G loss: 1.839856]\n",
            "[Epoch 44/50] [Batch 591/600] [D loss: 0.375436] [G loss: 1.802317]\n",
            "[Epoch 44/50] [Batch 592/600] [D loss: 0.397488] [G loss: 1.828471]\n",
            "[Epoch 44/50] [Batch 593/600] [D loss: 0.513604] [G loss: 1.854305]\n",
            "[Epoch 44/50] [Batch 594/600] [D loss: 0.399081] [G loss: 1.621607]\n",
            "[Epoch 44/50] [Batch 595/600] [D loss: 0.425300] [G loss: 1.638685]\n",
            "[Epoch 44/50] [Batch 596/600] [D loss: 0.405914] [G loss: 1.738445]\n",
            "[Epoch 44/50] [Batch 597/600] [D loss: 0.455984] [G loss: 1.766186]\n",
            "[Epoch 44/50] [Batch 598/600] [D loss: 0.340115] [G loss: 1.975658]\n",
            "[Epoch 44/50] [Batch 599/600] [D loss: 0.413648] [G loss: 1.942404]\n",
            "[Epoch 45/50] [Batch 0/600] [D loss: 0.412241] [G loss: 2.126666]\n",
            "[Epoch 45/50] [Batch 1/600] [D loss: 0.396279] [G loss: 1.886692]\n",
            "[Epoch 45/50] [Batch 2/600] [D loss: 0.401385] [G loss: 1.791481]\n",
            "[Epoch 45/50] [Batch 3/600] [D loss: 0.473166] [G loss: 1.800244]\n",
            "[Epoch 45/50] [Batch 4/600] [D loss: 0.378124] [G loss: 1.745305]\n",
            "[Epoch 45/50] [Batch 5/600] [D loss: 0.427771] [G loss: 1.615693]\n",
            "[Epoch 45/50] [Batch 6/600] [D loss: 0.394102] [G loss: 1.657829]\n",
            "[Epoch 45/50] [Batch 7/600] [D loss: 0.452742] [G loss: 1.691922]\n",
            "[Epoch 45/50] [Batch 8/600] [D loss: 0.373952] [G loss: 1.814599]\n",
            "[Epoch 45/50] [Batch 9/600] [D loss: 0.365539] [G loss: 1.710842]\n",
            "[Epoch 45/50] [Batch 10/600] [D loss: 0.462261] [G loss: 1.935185]\n",
            "[Epoch 45/50] [Batch 11/600] [D loss: 0.449576] [G loss: 1.846077]\n",
            "[Epoch 45/50] [Batch 12/600] [D loss: 0.470690] [G loss: 1.739245]\n",
            "[Epoch 45/50] [Batch 13/600] [D loss: 0.400081] [G loss: 1.445011]\n",
            "[Epoch 45/50] [Batch 14/600] [D loss: 0.384360] [G loss: 1.476318]\n",
            "[Epoch 45/50] [Batch 15/600] [D loss: 0.455995] [G loss: 1.592506]\n",
            "[Epoch 45/50] [Batch 16/600] [D loss: 0.413145] [G loss: 1.845654]\n",
            "[Epoch 45/50] [Batch 17/600] [D loss: 0.379008] [G loss: 1.747446]\n",
            "[Epoch 45/50] [Batch 18/600] [D loss: 0.353007] [G loss: 1.910281]\n",
            "[Epoch 45/50] [Batch 19/600] [D loss: 0.454185] [G loss: 1.810638]\n",
            "[Epoch 45/50] [Batch 20/600] [D loss: 0.515321] [G loss: 1.636381]\n",
            "[Epoch 45/50] [Batch 21/600] [D loss: 0.451172] [G loss: 1.681177]\n",
            "[Epoch 45/50] [Batch 22/600] [D loss: 0.410409] [G loss: 1.513357]\n",
            "[Epoch 45/50] [Batch 23/600] [D loss: 0.400945] [G loss: 1.486013]\n",
            "[Epoch 45/50] [Batch 24/600] [D loss: 0.444433] [G loss: 1.658713]\n",
            "[Epoch 45/50] [Batch 25/600] [D loss: 0.372216] [G loss: 1.503336]\n",
            "[Epoch 45/50] [Batch 26/600] [D loss: 0.426648] [G loss: 1.719201]\n",
            "[Epoch 45/50] [Batch 27/600] [D loss: 0.447071] [G loss: 1.843374]\n",
            "[Epoch 45/50] [Batch 28/600] [D loss: 0.403212] [G loss: 1.828723]\n",
            "[Epoch 45/50] [Batch 29/600] [D loss: 0.390850] [G loss: 1.730309]\n",
            "[Epoch 45/50] [Batch 30/600] [D loss: 0.371089] [G loss: 1.743201]\n",
            "[Epoch 45/50] [Batch 31/600] [D loss: 0.425764] [G loss: 1.777553]\n",
            "[Epoch 45/50] [Batch 32/600] [D loss: 0.410624] [G loss: 1.614103]\n",
            "[Epoch 45/50] [Batch 33/600] [D loss: 0.454164] [G loss: 1.763073]\n",
            "[Epoch 45/50] [Batch 34/600] [D loss: 0.345493] [G loss: 1.721443]\n",
            "[Epoch 45/50] [Batch 35/600] [D loss: 0.339719] [G loss: 1.826267]\n",
            "[Epoch 45/50] [Batch 36/600] [D loss: 0.446423] [G loss: 1.834507]\n",
            "[Epoch 45/50] [Batch 37/600] [D loss: 0.386099] [G loss: 1.720278]\n",
            "[Epoch 45/50] [Batch 38/600] [D loss: 0.436469] [G loss: 1.848466]\n",
            "[Epoch 45/50] [Batch 39/600] [D loss: 0.425468] [G loss: 1.660020]\n",
            "[Epoch 45/50] [Batch 40/600] [D loss: 0.445580] [G loss: 2.052936]\n",
            "[Epoch 45/50] [Batch 41/600] [D loss: 0.353513] [G loss: 2.027462]\n",
            "[Epoch 45/50] [Batch 42/600] [D loss: 0.431682] [G loss: 1.950316]\n",
            "[Epoch 45/50] [Batch 43/600] [D loss: 0.417335] [G loss: 1.932057]\n",
            "[Epoch 45/50] [Batch 44/600] [D loss: 0.321323] [G loss: 1.775923]\n",
            "[Epoch 45/50] [Batch 45/600] [D loss: 0.392367] [G loss: 2.060074]\n",
            "[Epoch 45/50] [Batch 46/600] [D loss: 0.336263] [G loss: 1.747097]\n",
            "[Epoch 45/50] [Batch 47/600] [D loss: 0.329717] [G loss: 1.848680]\n",
            "[Epoch 45/50] [Batch 48/600] [D loss: 0.380571] [G loss: 1.967281]\n",
            "[Epoch 45/50] [Batch 49/600] [D loss: 0.450949] [G loss: 1.732807]\n",
            "[Epoch 45/50] [Batch 50/600] [D loss: 0.387529] [G loss: 1.637429]\n",
            "[Epoch 45/50] [Batch 51/600] [D loss: 0.348233] [G loss: 2.013468]\n",
            "[Epoch 45/50] [Batch 52/600] [D loss: 0.446284] [G loss: 1.736048]\n",
            "[Epoch 45/50] [Batch 53/600] [D loss: 0.432071] [G loss: 2.041372]\n",
            "[Epoch 45/50] [Batch 54/600] [D loss: 0.379765] [G loss: 2.209561]\n",
            "[Epoch 45/50] [Batch 55/600] [D loss: 0.430221] [G loss: 1.949768]\n",
            "[Epoch 45/50] [Batch 56/600] [D loss: 0.427980] [G loss: 1.659689]\n",
            "[Epoch 45/50] [Batch 57/600] [D loss: 0.380265] [G loss: 1.746673]\n",
            "[Epoch 45/50] [Batch 58/600] [D loss: 0.421282] [G loss: 1.770450]\n",
            "[Epoch 45/50] [Batch 59/600] [D loss: 0.380623] [G loss: 1.733017]\n",
            "[Epoch 45/50] [Batch 60/600] [D loss: 0.499700] [G loss: 1.700271]\n",
            "[Epoch 45/50] [Batch 61/600] [D loss: 0.363017] [G loss: 1.948224]\n",
            "[Epoch 45/50] [Batch 62/600] [D loss: 0.395994] [G loss: 1.794792]\n",
            "[Epoch 45/50] [Batch 63/600] [D loss: 0.351283] [G loss: 1.839535]\n",
            "[Epoch 45/50] [Batch 64/600] [D loss: 0.398159] [G loss: 1.786767]\n",
            "[Epoch 45/50] [Batch 65/600] [D loss: 0.394773] [G loss: 1.806852]\n",
            "[Epoch 45/50] [Batch 66/600] [D loss: 0.381723] [G loss: 1.828488]\n",
            "[Epoch 45/50] [Batch 67/600] [D loss: 0.486600] [G loss: 1.847427]\n",
            "[Epoch 45/50] [Batch 68/600] [D loss: 0.461817] [G loss: 1.701288]\n",
            "[Epoch 45/50] [Batch 69/600] [D loss: 0.366930] [G loss: 1.633947]\n",
            "[Epoch 45/50] [Batch 70/600] [D loss: 0.459471] [G loss: 1.645455]\n",
            "[Epoch 45/50] [Batch 71/600] [D loss: 0.366427] [G loss: 1.466076]\n",
            "[Epoch 45/50] [Batch 72/600] [D loss: 0.482572] [G loss: 1.710160]\n",
            "[Epoch 45/50] [Batch 73/600] [D loss: 0.473830] [G loss: 1.656675]\n",
            "[Epoch 45/50] [Batch 74/600] [D loss: 0.427481] [G loss: 2.021582]\n",
            "[Epoch 45/50] [Batch 75/600] [D loss: 0.504575] [G loss: 1.722861]\n",
            "[Epoch 45/50] [Batch 76/600] [D loss: 0.419291] [G loss: 1.695757]\n",
            "[Epoch 45/50] [Batch 77/600] [D loss: 0.313812] [G loss: 1.617291]\n",
            "[Epoch 45/50] [Batch 78/600] [D loss: 0.347545] [G loss: 1.959924]\n",
            "[Epoch 45/50] [Batch 79/600] [D loss: 0.420374] [G loss: 1.975888]\n",
            "[Epoch 45/50] [Batch 80/600] [D loss: 0.372682] [G loss: 1.994151]\n",
            "[Epoch 45/50] [Batch 81/600] [D loss: 0.409060] [G loss: 2.013547]\n",
            "[Epoch 45/50] [Batch 82/600] [D loss: 0.467042] [G loss: 1.921182]\n",
            "[Epoch 45/50] [Batch 83/600] [D loss: 0.435638] [G loss: 1.596646]\n",
            "[Epoch 45/50] [Batch 84/600] [D loss: 0.445124] [G loss: 1.463275]\n",
            "[Epoch 45/50] [Batch 85/600] [D loss: 0.397680] [G loss: 1.763233]\n",
            "[Epoch 45/50] [Batch 86/600] [D loss: 0.403483] [G loss: 1.710670]\n",
            "[Epoch 45/50] [Batch 87/600] [D loss: 0.462496] [G loss: 1.625427]\n",
            "[Epoch 45/50] [Batch 88/600] [D loss: 0.454670] [G loss: 1.446085]\n",
            "[Epoch 45/50] [Batch 89/600] [D loss: 0.442786] [G loss: 1.726531]\n",
            "[Epoch 45/50] [Batch 90/600] [D loss: 0.393016] [G loss: 1.762213]\n",
            "[Epoch 45/50] [Batch 91/600] [D loss: 0.485713] [G loss: 1.831608]\n",
            "[Epoch 45/50] [Batch 92/600] [D loss: 0.501124] [G loss: 1.983057]\n",
            "[Epoch 45/50] [Batch 93/600] [D loss: 0.355691] [G loss: 1.774006]\n",
            "[Epoch 45/50] [Batch 94/600] [D loss: 0.496175] [G loss: 1.514382]\n",
            "[Epoch 45/50] [Batch 95/600] [D loss: 0.339407] [G loss: 1.721412]\n",
            "[Epoch 45/50] [Batch 96/600] [D loss: 0.439633] [G loss: 1.528219]\n",
            "[Epoch 45/50] [Batch 97/600] [D loss: 0.469873] [G loss: 1.552253]\n",
            "[Epoch 45/50] [Batch 98/600] [D loss: 0.408154] [G loss: 1.673336]\n",
            "[Epoch 45/50] [Batch 99/600] [D loss: 0.404515] [G loss: 1.646101]\n",
            "[Epoch 45/50] [Batch 100/600] [D loss: 0.477946] [G loss: 1.713021]\n",
            "[Epoch 45/50] [Batch 101/600] [D loss: 0.459036] [G loss: 1.728203]\n",
            "[Epoch 45/50] [Batch 102/600] [D loss: 0.443317] [G loss: 1.591617]\n",
            "[Epoch 45/50] [Batch 103/600] [D loss: 0.400546] [G loss: 1.532019]\n",
            "[Epoch 45/50] [Batch 104/600] [D loss: 0.513840] [G loss: 1.487141]\n",
            "[Epoch 45/50] [Batch 105/600] [D loss: 0.385635] [G loss: 1.631556]\n",
            "[Epoch 45/50] [Batch 106/600] [D loss: 0.446236] [G loss: 1.705572]\n",
            "[Epoch 45/50] [Batch 107/600] [D loss: 0.488391] [G loss: 1.640710]\n",
            "[Epoch 45/50] [Batch 108/600] [D loss: 0.389087] [G loss: 1.770897]\n",
            "[Epoch 45/50] [Batch 109/600] [D loss: 0.352833] [G loss: 1.783603]\n",
            "[Epoch 45/50] [Batch 110/600] [D loss: 0.367763] [G loss: 1.709276]\n",
            "[Epoch 45/50] [Batch 111/600] [D loss: 0.460004] [G loss: 1.683169]\n",
            "[Epoch 45/50] [Batch 112/600] [D loss: 0.435136] [G loss: 1.725014]\n",
            "[Epoch 45/50] [Batch 113/600] [D loss: 0.428930] [G loss: 1.587814]\n",
            "[Epoch 45/50] [Batch 114/600] [D loss: 0.465304] [G loss: 1.622598]\n",
            "[Epoch 45/50] [Batch 115/600] [D loss: 0.414432] [G loss: 1.799867]\n",
            "[Epoch 45/50] [Batch 116/600] [D loss: 0.385294] [G loss: 1.658740]\n",
            "[Epoch 45/50] [Batch 117/600] [D loss: 0.449622] [G loss: 1.937049]\n",
            "[Epoch 45/50] [Batch 118/600] [D loss: 0.479023] [G loss: 1.445170]\n",
            "[Epoch 45/50] [Batch 119/600] [D loss: 0.453462] [G loss: 1.632517]\n",
            "[Epoch 45/50] [Batch 120/600] [D loss: 0.377420] [G loss: 1.600287]\n",
            "[Epoch 45/50] [Batch 121/600] [D loss: 0.412502] [G loss: 1.433971]\n",
            "[Epoch 45/50] [Batch 122/600] [D loss: 0.352314] [G loss: 1.618930]\n",
            "[Epoch 45/50] [Batch 123/600] [D loss: 0.395249] [G loss: 1.672438]\n",
            "[Epoch 45/50] [Batch 124/600] [D loss: 0.365826] [G loss: 1.629504]\n",
            "[Epoch 45/50] [Batch 125/600] [D loss: 0.422504] [G loss: 1.863270]\n",
            "[Epoch 45/50] [Batch 126/600] [D loss: 0.410859] [G loss: 1.889300]\n",
            "[Epoch 45/50] [Batch 127/600] [D loss: 0.447852] [G loss: 1.904491]\n",
            "[Epoch 45/50] [Batch 128/600] [D loss: 0.468829] [G loss: 1.695430]\n",
            "[Epoch 45/50] [Batch 129/600] [D loss: 0.405866] [G loss: 1.785724]\n",
            "[Epoch 45/50] [Batch 130/600] [D loss: 0.393284] [G loss: 1.813586]\n",
            "[Epoch 45/50] [Batch 131/600] [D loss: 0.388141] [G loss: 1.795908]\n",
            "[Epoch 45/50] [Batch 132/600] [D loss: 0.321872] [G loss: 2.015477]\n",
            "[Epoch 45/50] [Batch 133/600] [D loss: 0.374860] [G loss: 1.795543]\n",
            "[Epoch 45/50] [Batch 134/600] [D loss: 0.377558] [G loss: 1.905818]\n",
            "[Epoch 45/50] [Batch 135/600] [D loss: 0.369167] [G loss: 1.669120]\n",
            "[Epoch 45/50] [Batch 136/600] [D loss: 0.452995] [G loss: 1.817116]\n",
            "[Epoch 45/50] [Batch 137/600] [D loss: 0.436203] [G loss: 1.827757]\n",
            "[Epoch 45/50] [Batch 138/600] [D loss: 0.387696] [G loss: 1.870426]\n",
            "[Epoch 45/50] [Batch 139/600] [D loss: 0.372850] [G loss: 1.692587]\n",
            "[Epoch 45/50] [Batch 140/600] [D loss: 0.407214] [G loss: 1.896378]\n",
            "[Epoch 45/50] [Batch 141/600] [D loss: 0.388557] [G loss: 1.650151]\n",
            "[Epoch 45/50] [Batch 142/600] [D loss: 0.426474] [G loss: 1.917219]\n",
            "[Epoch 45/50] [Batch 143/600] [D loss: 0.419662] [G loss: 1.736055]\n",
            "[Epoch 45/50] [Batch 144/600] [D loss: 0.472772] [G loss: 1.535459]\n",
            "[Epoch 45/50] [Batch 145/600] [D loss: 0.400460] [G loss: 1.912323]\n",
            "[Epoch 45/50] [Batch 146/600] [D loss: 0.447674] [G loss: 1.745897]\n",
            "[Epoch 45/50] [Batch 147/600] [D loss: 0.403493] [G loss: 1.859280]\n",
            "[Epoch 45/50] [Batch 148/600] [D loss: 0.397509] [G loss: 2.005664]\n",
            "[Epoch 45/50] [Batch 149/600] [D loss: 0.492941] [G loss: 1.716270]\n",
            "[Epoch 45/50] [Batch 150/600] [D loss: 0.428989] [G loss: 1.819793]\n",
            "[Epoch 45/50] [Batch 151/600] [D loss: 0.467877] [G loss: 1.726192]\n",
            "[Epoch 45/50] [Batch 152/600] [D loss: 0.484463] [G loss: 1.659119]\n",
            "[Epoch 45/50] [Batch 153/600] [D loss: 0.483716] [G loss: 1.674620]\n",
            "[Epoch 45/50] [Batch 154/600] [D loss: 0.416372] [G loss: 1.546704]\n",
            "[Epoch 45/50] [Batch 155/600] [D loss: 0.350669] [G loss: 1.392276]\n",
            "[Epoch 45/50] [Batch 156/600] [D loss: 0.372475] [G loss: 1.627563]\n",
            "[Epoch 45/50] [Batch 157/600] [D loss: 0.421456] [G loss: 1.782342]\n",
            "[Epoch 45/50] [Batch 158/600] [D loss: 0.425973] [G loss: 1.708836]\n",
            "[Epoch 45/50] [Batch 159/600] [D loss: 0.427381] [G loss: 1.584435]\n",
            "[Epoch 45/50] [Batch 160/600] [D loss: 0.443248] [G loss: 1.552528]\n",
            "[Epoch 45/50] [Batch 161/600] [D loss: 0.402842] [G loss: 1.668135]\n",
            "[Epoch 45/50] [Batch 162/600] [D loss: 0.407478] [G loss: 1.875351]\n",
            "[Epoch 45/50] [Batch 163/600] [D loss: 0.406620] [G loss: 1.509522]\n",
            "[Epoch 45/50] [Batch 164/600] [D loss: 0.414674] [G loss: 1.828350]\n",
            "[Epoch 45/50] [Batch 165/600] [D loss: 0.427505] [G loss: 1.695562]\n",
            "[Epoch 45/50] [Batch 166/600] [D loss: 0.421198] [G loss: 1.789240]\n",
            "[Epoch 45/50] [Batch 167/600] [D loss: 0.425144] [G loss: 1.868747]\n",
            "[Epoch 45/50] [Batch 168/600] [D loss: 0.458150] [G loss: 1.768197]\n",
            "[Epoch 45/50] [Batch 169/600] [D loss: 0.383918] [G loss: 1.587383]\n",
            "[Epoch 45/50] [Batch 170/600] [D loss: 0.481381] [G loss: 1.606890]\n",
            "[Epoch 45/50] [Batch 171/600] [D loss: 0.378714] [G loss: 1.421040]\n",
            "[Epoch 45/50] [Batch 172/600] [D loss: 0.393898] [G loss: 1.480085]\n",
            "[Epoch 45/50] [Batch 173/600] [D loss: 0.501207] [G loss: 1.683845]\n",
            "[Epoch 45/50] [Batch 174/600] [D loss: 0.387538] [G loss: 2.013201]\n",
            "[Epoch 45/50] [Batch 175/600] [D loss: 0.375040] [G loss: 1.854002]\n",
            "[Epoch 45/50] [Batch 176/600] [D loss: 0.398405] [G loss: 1.793285]\n",
            "[Epoch 45/50] [Batch 177/600] [D loss: 0.525793] [G loss: 1.829447]\n",
            "[Epoch 45/50] [Batch 178/600] [D loss: 0.440326] [G loss: 1.601096]\n",
            "[Epoch 45/50] [Batch 179/600] [D loss: 0.392686] [G loss: 1.860846]\n",
            "[Epoch 45/50] [Batch 180/600] [D loss: 0.399328] [G loss: 1.469023]\n",
            "[Epoch 45/50] [Batch 181/600] [D loss: 0.426580] [G loss: 1.533743]\n",
            "[Epoch 45/50] [Batch 182/600] [D loss: 0.362913] [G loss: 1.786602]\n",
            "[Epoch 45/50] [Batch 183/600] [D loss: 0.473351] [G loss: 1.724983]\n",
            "[Epoch 45/50] [Batch 184/600] [D loss: 0.433845] [G loss: 1.636446]\n",
            "[Epoch 45/50] [Batch 185/600] [D loss: 0.362955] [G loss: 1.704431]\n",
            "[Epoch 45/50] [Batch 186/600] [D loss: 0.380492] [G loss: 1.601924]\n",
            "[Epoch 45/50] [Batch 187/600] [D loss: 0.435100] [G loss: 1.610233]\n",
            "[Epoch 45/50] [Batch 188/600] [D loss: 0.422085] [G loss: 1.770037]\n",
            "[Epoch 45/50] [Batch 189/600] [D loss: 0.388044] [G loss: 2.103671]\n",
            "[Epoch 45/50] [Batch 190/600] [D loss: 0.350333] [G loss: 1.878298]\n",
            "[Epoch 45/50] [Batch 191/600] [D loss: 0.407959] [G loss: 2.416881]\n",
            "[Epoch 45/50] [Batch 192/600] [D loss: 0.491622] [G loss: 1.755699]\n",
            "[Epoch 45/50] [Batch 193/600] [D loss: 0.466215] [G loss: 1.792247]\n",
            "[Epoch 45/50] [Batch 194/600] [D loss: 0.368320] [G loss: 1.590936]\n",
            "[Epoch 45/50] [Batch 195/600] [D loss: 0.409117] [G loss: 1.510044]\n",
            "[Epoch 45/50] [Batch 196/600] [D loss: 0.401415] [G loss: 1.530924]\n",
            "[Epoch 45/50] [Batch 197/600] [D loss: 0.333989] [G loss: 1.775360]\n",
            "[Epoch 45/50] [Batch 198/600] [D loss: 0.402300] [G loss: 2.139924]\n",
            "[Epoch 45/50] [Batch 199/600] [D loss: 0.356154] [G loss: 1.751507]\n",
            "[Epoch 45/50] [Batch 200/600] [D loss: 0.394026] [G loss: 2.085131]\n",
            "[Epoch 45/50] [Batch 201/600] [D loss: 0.335263] [G loss: 2.057724]\n",
            "[Epoch 45/50] [Batch 202/600] [D loss: 0.442130] [G loss: 2.198717]\n",
            "[Epoch 45/50] [Batch 203/600] [D loss: 0.451055] [G loss: 1.931741]\n",
            "[Epoch 45/50] [Batch 204/600] [D loss: 0.419780] [G loss: 1.751297]\n",
            "[Epoch 45/50] [Batch 205/600] [D loss: 0.421074] [G loss: 1.871336]\n",
            "[Epoch 45/50] [Batch 206/600] [D loss: 0.445773] [G loss: 1.733448]\n",
            "[Epoch 45/50] [Batch 207/600] [D loss: 0.416856] [G loss: 1.595930]\n",
            "[Epoch 45/50] [Batch 208/600] [D loss: 0.357565] [G loss: 1.534544]\n",
            "[Epoch 45/50] [Batch 209/600] [D loss: 0.335082] [G loss: 1.903048]\n",
            "[Epoch 45/50] [Batch 210/600] [D loss: 0.407239] [G loss: 1.953849]\n",
            "[Epoch 45/50] [Batch 211/600] [D loss: 0.398703] [G loss: 1.815693]\n",
            "[Epoch 45/50] [Batch 212/600] [D loss: 0.403567] [G loss: 1.888782]\n",
            "[Epoch 45/50] [Batch 213/600] [D loss: 0.471991] [G loss: 1.828155]\n",
            "[Epoch 45/50] [Batch 214/600] [D loss: 0.367661] [G loss: 1.885622]\n",
            "[Epoch 45/50] [Batch 215/600] [D loss: 0.400432] [G loss: 1.742534]\n",
            "[Epoch 45/50] [Batch 216/600] [D loss: 0.401001] [G loss: 2.005531]\n",
            "[Epoch 45/50] [Batch 217/600] [D loss: 0.425678] [G loss: 1.647344]\n",
            "[Epoch 45/50] [Batch 218/600] [D loss: 0.419344] [G loss: 1.857196]\n",
            "[Epoch 45/50] [Batch 219/600] [D loss: 0.385724] [G loss: 1.614538]\n",
            "[Epoch 45/50] [Batch 220/600] [D loss: 0.375418] [G loss: 1.594942]\n",
            "[Epoch 45/50] [Batch 221/600] [D loss: 0.404733] [G loss: 1.799922]\n",
            "[Epoch 45/50] [Batch 222/600] [D loss: 0.423653] [G loss: 1.883104]\n",
            "[Epoch 45/50] [Batch 223/600] [D loss: 0.399324] [G loss: 1.739388]\n",
            "[Epoch 45/50] [Batch 224/600] [D loss: 0.492881] [G loss: 1.712478]\n",
            "[Epoch 45/50] [Batch 225/600] [D loss: 0.451760] [G loss: 1.646872]\n",
            "[Epoch 45/50] [Batch 226/600] [D loss: 0.360604] [G loss: 1.653982]\n",
            "[Epoch 45/50] [Batch 227/600] [D loss: 0.378253] [G loss: 1.885052]\n",
            "[Epoch 45/50] [Batch 228/600] [D loss: 0.351875] [G loss: 1.757463]\n",
            "[Epoch 45/50] [Batch 229/600] [D loss: 0.382345] [G loss: 1.797477]\n",
            "[Epoch 45/50] [Batch 230/600] [D loss: 0.412792] [G loss: 1.825319]\n",
            "[Epoch 45/50] [Batch 231/600] [D loss: 0.400313] [G loss: 1.724288]\n",
            "[Epoch 45/50] [Batch 232/600] [D loss: 0.441405] [G loss: 2.036551]\n",
            "[Epoch 45/50] [Batch 233/600] [D loss: 0.446391] [G loss: 1.759429]\n",
            "[Epoch 45/50] [Batch 234/600] [D loss: 0.432970] [G loss: 1.538113]\n",
            "[Epoch 45/50] [Batch 235/600] [D loss: 0.345579] [G loss: 1.754263]\n",
            "[Epoch 45/50] [Batch 236/600] [D loss: 0.482702] [G loss: 1.611485]\n",
            "[Epoch 45/50] [Batch 237/600] [D loss: 0.430988] [G loss: 1.733386]\n",
            "[Epoch 45/50] [Batch 238/600] [D loss: 0.432787] [G loss: 1.730038]\n",
            "[Epoch 45/50] [Batch 239/600] [D loss: 0.466788] [G loss: 1.670400]\n",
            "[Epoch 45/50] [Batch 240/600] [D loss: 0.471858] [G loss: 1.623509]\n",
            "[Epoch 45/50] [Batch 241/600] [D loss: 0.465004] [G loss: 1.493987]\n",
            "[Epoch 45/50] [Batch 242/600] [D loss: 0.437439] [G loss: 1.490863]\n",
            "[Epoch 45/50] [Batch 243/600] [D loss: 0.366015] [G loss: 1.800403]\n",
            "[Epoch 45/50] [Batch 244/600] [D loss: 0.369738] [G loss: 1.705217]\n",
            "[Epoch 45/50] [Batch 245/600] [D loss: 0.387987] [G loss: 1.923290]\n",
            "[Epoch 45/50] [Batch 246/600] [D loss: 0.370709] [G loss: 1.885351]\n",
            "[Epoch 45/50] [Batch 247/600] [D loss: 0.372833] [G loss: 1.909549]\n",
            "[Epoch 45/50] [Batch 248/600] [D loss: 0.373453] [G loss: 1.946558]\n",
            "[Epoch 45/50] [Batch 249/600] [D loss: 0.457005] [G loss: 1.686250]\n",
            "[Epoch 45/50] [Batch 250/600] [D loss: 0.388955] [G loss: 1.733761]\n",
            "[Epoch 45/50] [Batch 251/600] [D loss: 0.474483] [G loss: 1.829957]\n",
            "[Epoch 45/50] [Batch 252/600] [D loss: 0.450819] [G loss: 1.781122]\n",
            "[Epoch 45/50] [Batch 253/600] [D loss: 0.409186] [G loss: 1.699856]\n",
            "[Epoch 45/50] [Batch 254/600] [D loss: 0.422607] [G loss: 1.640247]\n",
            "[Epoch 45/50] [Batch 255/600] [D loss: 0.421456] [G loss: 1.704895]\n",
            "[Epoch 45/50] [Batch 256/600] [D loss: 0.369378] [G loss: 1.709441]\n",
            "[Epoch 45/50] [Batch 257/600] [D loss: 0.427935] [G loss: 1.496335]\n",
            "[Epoch 45/50] [Batch 258/600] [D loss: 0.492382] [G loss: 1.448016]\n",
            "[Epoch 45/50] [Batch 259/600] [D loss: 0.444399] [G loss: 1.698715]\n",
            "[Epoch 45/50] [Batch 260/600] [D loss: 0.417348] [G loss: 1.609717]\n",
            "[Epoch 45/50] [Batch 261/600] [D loss: 0.468298] [G loss: 1.737390]\n",
            "[Epoch 45/50] [Batch 262/600] [D loss: 0.449339] [G loss: 1.779773]\n",
            "[Epoch 45/50] [Batch 263/600] [D loss: 0.487369] [G loss: 1.817923]\n",
            "[Epoch 45/50] [Batch 264/600] [D loss: 0.431812] [G loss: 1.792463]\n",
            "[Epoch 45/50] [Batch 265/600] [D loss: 0.490105] [G loss: 1.633890]\n",
            "[Epoch 45/50] [Batch 266/600] [D loss: 0.444682] [G loss: 1.387708]\n",
            "[Epoch 45/50] [Batch 267/600] [D loss: 0.484722] [G loss: 1.545768]\n",
            "[Epoch 45/50] [Batch 268/600] [D loss: 0.512946] [G loss: 1.586382]\n",
            "[Epoch 45/50] [Batch 269/600] [D loss: 0.370072] [G loss: 1.500566]\n",
            "[Epoch 45/50] [Batch 270/600] [D loss: 0.389646] [G loss: 1.429435]\n",
            "[Epoch 45/50] [Batch 271/600] [D loss: 0.386430] [G loss: 1.533925]\n",
            "[Epoch 45/50] [Batch 272/600] [D loss: 0.411269] [G loss: 1.554473]\n",
            "[Epoch 45/50] [Batch 273/600] [D loss: 0.407525] [G loss: 1.639349]\n",
            "[Epoch 45/50] [Batch 274/600] [D loss: 0.412309] [G loss: 1.524390]\n",
            "[Epoch 45/50] [Batch 275/600] [D loss: 0.369412] [G loss: 2.047685]\n",
            "[Epoch 45/50] [Batch 276/600] [D loss: 0.435813] [G loss: 1.853769]\n",
            "[Epoch 45/50] [Batch 277/600] [D loss: 0.453535] [G loss: 1.999602]\n",
            "[Epoch 45/50] [Batch 278/600] [D loss: 0.471129] [G loss: 1.953991]\n",
            "[Epoch 45/50] [Batch 279/600] [D loss: 0.470199] [G loss: 2.024760]\n",
            "[Epoch 45/50] [Batch 280/600] [D loss: 0.401208] [G loss: 1.600403]\n",
            "[Epoch 45/50] [Batch 281/600] [D loss: 0.496311] [G loss: 1.465703]\n",
            "[Epoch 45/50] [Batch 282/600] [D loss: 0.382717] [G loss: 1.542568]\n",
            "[Epoch 45/50] [Batch 283/600] [D loss: 0.421266] [G loss: 1.704701]\n",
            "[Epoch 45/50] [Batch 284/600] [D loss: 0.411637] [G loss: 1.637438]\n",
            "[Epoch 45/50] [Batch 285/600] [D loss: 0.364950] [G loss: 1.637590]\n",
            "[Epoch 45/50] [Batch 286/600] [D loss: 0.389673] [G loss: 1.615424]\n",
            "[Epoch 45/50] [Batch 287/600] [D loss: 0.459006] [G loss: 1.573391]\n",
            "[Epoch 45/50] [Batch 288/600] [D loss: 0.344469] [G loss: 1.773591]\n",
            "[Epoch 45/50] [Batch 289/600] [D loss: 0.429148] [G loss: 1.875090]\n",
            "[Epoch 45/50] [Batch 290/600] [D loss: 0.477107] [G loss: 1.980009]\n",
            "[Epoch 45/50] [Batch 291/600] [D loss: 0.503595] [G loss: 1.726259]\n",
            "[Epoch 45/50] [Batch 292/600] [D loss: 0.460289] [G loss: 1.545360]\n",
            "[Epoch 45/50] [Batch 293/600] [D loss: 0.396993] [G loss: 1.621194]\n",
            "[Epoch 45/50] [Batch 294/600] [D loss: 0.445143] [G loss: 1.492999]\n",
            "[Epoch 45/50] [Batch 295/600] [D loss: 0.403191] [G loss: 1.540607]\n",
            "[Epoch 45/50] [Batch 296/600] [D loss: 0.397596] [G loss: 1.677522]\n",
            "[Epoch 45/50] [Batch 297/600] [D loss: 0.451259] [G loss: 1.752792]\n",
            "[Epoch 45/50] [Batch 298/600] [D loss: 0.587606] [G loss: 1.596308]\n",
            "[Epoch 45/50] [Batch 299/600] [D loss: 0.501470] [G loss: 1.693296]\n",
            "[Epoch 45/50] [Batch 300/600] [D loss: 0.418808] [G loss: 1.517764]\n",
            "[Epoch 45/50] [Batch 301/600] [D loss: 0.349648] [G loss: 1.786766]\n",
            "[Epoch 45/50] [Batch 302/600] [D loss: 0.420540] [G loss: 1.544611]\n",
            "[Epoch 45/50] [Batch 303/600] [D loss: 0.375620] [G loss: 1.641039]\n",
            "[Epoch 45/50] [Batch 304/600] [D loss: 0.505087] [G loss: 1.611255]\n",
            "[Epoch 45/50] [Batch 305/600] [D loss: 0.414850] [G loss: 1.706362]\n",
            "[Epoch 45/50] [Batch 306/600] [D loss: 0.438325] [G loss: 1.584089]\n",
            "[Epoch 45/50] [Batch 307/600] [D loss: 0.442697] [G loss: 1.431275]\n",
            "[Epoch 45/50] [Batch 308/600] [D loss: 0.399774] [G loss: 1.691681]\n",
            "[Epoch 45/50] [Batch 309/600] [D loss: 0.388438] [G loss: 1.729142]\n",
            "[Epoch 45/50] [Batch 310/600] [D loss: 0.427936] [G loss: 1.564205]\n",
            "[Epoch 45/50] [Batch 311/600] [D loss: 0.382717] [G loss: 1.586559]\n",
            "[Epoch 45/50] [Batch 312/600] [D loss: 0.523895] [G loss: 1.542403]\n",
            "[Epoch 45/50] [Batch 313/600] [D loss: 0.472030] [G loss: 1.692552]\n",
            "[Epoch 45/50] [Batch 314/600] [D loss: 0.476701] [G loss: 1.857013]\n",
            "[Epoch 45/50] [Batch 315/600] [D loss: 0.520059] [G loss: 1.871399]\n",
            "[Epoch 45/50] [Batch 316/600] [D loss: 0.483358] [G loss: 1.414760]\n",
            "[Epoch 45/50] [Batch 317/600] [D loss: 0.497180] [G loss: 1.456930]\n",
            "[Epoch 45/50] [Batch 318/600] [D loss: 0.409154] [G loss: 1.493493]\n",
            "[Epoch 45/50] [Batch 319/600] [D loss: 0.419407] [G loss: 1.550738]\n",
            "[Epoch 45/50] [Batch 320/600] [D loss: 0.520171] [G loss: 1.715296]\n",
            "[Epoch 45/50] [Batch 321/600] [D loss: 0.412117] [G loss: 1.501852]\n",
            "[Epoch 45/50] [Batch 322/600] [D loss: 0.345126] [G loss: 1.573552]\n",
            "[Epoch 45/50] [Batch 323/600] [D loss: 0.430200] [G loss: 1.611068]\n",
            "[Epoch 45/50] [Batch 324/600] [D loss: 0.364715] [G loss: 1.759540]\n",
            "[Epoch 45/50] [Batch 325/600] [D loss: 0.368191] [G loss: 1.601247]\n",
            "[Epoch 45/50] [Batch 326/600] [D loss: 0.372595] [G loss: 1.816410]\n",
            "[Epoch 45/50] [Batch 327/600] [D loss: 0.407933] [G loss: 1.622427]\n",
            "[Epoch 45/50] [Batch 328/600] [D loss: 0.426067] [G loss: 1.828947]\n",
            "[Epoch 45/50] [Batch 329/600] [D loss: 0.413358] [G loss: 1.946531]\n",
            "[Epoch 45/50] [Batch 330/600] [D loss: 0.358716] [G loss: 1.805338]\n",
            "[Epoch 45/50] [Batch 331/600] [D loss: 0.453438] [G loss: 1.883583]\n",
            "[Epoch 45/50] [Batch 332/600] [D loss: 0.391481] [G loss: 1.852057]\n",
            "[Epoch 45/50] [Batch 333/600] [D loss: 0.325550] [G loss: 1.996622]\n",
            "[Epoch 45/50] [Batch 334/600] [D loss: 0.390187] [G loss: 2.028283]\n",
            "[Epoch 45/50] [Batch 335/600] [D loss: 0.475786] [G loss: 1.878497]\n",
            "[Epoch 45/50] [Batch 336/600] [D loss: 0.429347] [G loss: 1.730128]\n",
            "[Epoch 45/50] [Batch 337/600] [D loss: 0.455969] [G loss: 1.944117]\n",
            "[Epoch 45/50] [Batch 338/600] [D loss: 0.375672] [G loss: 1.838415]\n",
            "[Epoch 45/50] [Batch 339/600] [D loss: 0.485856] [G loss: 1.710629]\n",
            "[Epoch 45/50] [Batch 340/600] [D loss: 0.424384] [G loss: 1.405546]\n",
            "[Epoch 45/50] [Batch 341/600] [D loss: 0.351039] [G loss: 1.984932]\n",
            "[Epoch 45/50] [Batch 342/600] [D loss: 0.370791] [G loss: 1.853007]\n",
            "[Epoch 45/50] [Batch 343/600] [D loss: 0.358233] [G loss: 1.763392]\n",
            "[Epoch 45/50] [Batch 344/600] [D loss: 0.386810] [G loss: 1.759094]\n",
            "[Epoch 45/50] [Batch 345/600] [D loss: 0.469396] [G loss: 1.810959]\n",
            "[Epoch 45/50] [Batch 346/600] [D loss: 0.475279] [G loss: 1.698148]\n",
            "[Epoch 45/50] [Batch 347/600] [D loss: 0.461937] [G loss: 1.605502]\n",
            "[Epoch 45/50] [Batch 348/600] [D loss: 0.387957] [G loss: 1.755968]\n",
            "[Epoch 45/50] [Batch 349/600] [D loss: 0.388172] [G loss: 1.680229]\n",
            "[Epoch 45/50] [Batch 350/600] [D loss: 0.368894] [G loss: 1.742484]\n",
            "[Epoch 45/50] [Batch 351/600] [D loss: 0.457220] [G loss: 1.682877]\n",
            "[Epoch 45/50] [Batch 352/600] [D loss: 0.336080] [G loss: 1.630363]\n",
            "[Epoch 45/50] [Batch 353/600] [D loss: 0.328758] [G loss: 1.688179]\n",
            "[Epoch 45/50] [Batch 354/600] [D loss: 0.398626] [G loss: 1.828898]\n",
            "[Epoch 45/50] [Batch 355/600] [D loss: 0.387534] [G loss: 1.863327]\n",
            "[Epoch 45/50] [Batch 356/600] [D loss: 0.383873] [G loss: 1.863096]\n",
            "[Epoch 45/50] [Batch 357/600] [D loss: 0.403844] [G loss: 1.910879]\n",
            "[Epoch 45/50] [Batch 358/600] [D loss: 0.473605] [G loss: 1.772899]\n",
            "[Epoch 45/50] [Batch 359/600] [D loss: 0.462543] [G loss: 1.720308]\n",
            "[Epoch 45/50] [Batch 360/600] [D loss: 0.497472] [G loss: 1.967068]\n",
            "[Epoch 45/50] [Batch 361/600] [D loss: 0.442128] [G loss: 1.646762]\n",
            "[Epoch 45/50] [Batch 362/600] [D loss: 0.391295] [G loss: 1.692698]\n",
            "[Epoch 45/50] [Batch 363/600] [D loss: 0.386971] [G loss: 1.614790]\n",
            "[Epoch 45/50] [Batch 364/600] [D loss: 0.444258] [G loss: 1.836761]\n",
            "[Epoch 45/50] [Batch 365/600] [D loss: 0.369270] [G loss: 1.656254]\n",
            "[Epoch 45/50] [Batch 366/600] [D loss: 0.386432] [G loss: 1.682665]\n",
            "[Epoch 45/50] [Batch 367/600] [D loss: 0.391229] [G loss: 1.670755]\n",
            "[Epoch 45/50] [Batch 368/600] [D loss: 0.426785] [G loss: 1.741837]\n",
            "[Epoch 45/50] [Batch 369/600] [D loss: 0.424721] [G loss: 1.919512]\n",
            "[Epoch 45/50] [Batch 370/600] [D loss: 0.409881] [G loss: 1.798903]\n",
            "[Epoch 45/50] [Batch 371/600] [D loss: 0.393840] [G loss: 1.774504]\n",
            "[Epoch 45/50] [Batch 372/600] [D loss: 0.395618] [G loss: 1.798258]\n",
            "[Epoch 45/50] [Batch 373/600] [D loss: 0.382418] [G loss: 1.854073]\n",
            "[Epoch 45/50] [Batch 374/600] [D loss: 0.409400] [G loss: 1.993905]\n",
            "[Epoch 45/50] [Batch 375/600] [D loss: 0.435114] [G loss: 1.788696]\n",
            "[Epoch 45/50] [Batch 376/600] [D loss: 0.427226] [G loss: 1.557556]\n",
            "[Epoch 45/50] [Batch 377/600] [D loss: 0.417323] [G loss: 1.598493]\n",
            "[Epoch 45/50] [Batch 378/600] [D loss: 0.363043] [G loss: 1.732571]\n",
            "[Epoch 45/50] [Batch 379/600] [D loss: 0.435452] [G loss: 1.647594]\n",
            "[Epoch 45/50] [Batch 380/600] [D loss: 0.453843] [G loss: 1.817428]\n",
            "[Epoch 45/50] [Batch 381/600] [D loss: 0.330262] [G loss: 1.954298]\n",
            "[Epoch 45/50] [Batch 382/600] [D loss: 0.376014] [G loss: 1.715311]\n",
            "[Epoch 45/50] [Batch 383/600] [D loss: 0.463077] [G loss: 1.872789]\n",
            "[Epoch 45/50] [Batch 384/600] [D loss: 0.447937] [G loss: 1.762073]\n",
            "[Epoch 45/50] [Batch 385/600] [D loss: 0.368471] [G loss: 2.001408]\n",
            "[Epoch 45/50] [Batch 386/600] [D loss: 0.480797] [G loss: 1.879969]\n",
            "[Epoch 45/50] [Batch 387/600] [D loss: 0.438891] [G loss: 1.941944]\n",
            "[Epoch 45/50] [Batch 388/600] [D loss: 0.420686] [G loss: 1.681922]\n",
            "[Epoch 45/50] [Batch 389/600] [D loss: 0.495714] [G loss: 1.553929]\n",
            "[Epoch 45/50] [Batch 390/600] [D loss: 0.400045] [G loss: 1.676579]\n",
            "[Epoch 45/50] [Batch 391/600] [D loss: 0.431101] [G loss: 1.578200]\n",
            "[Epoch 45/50] [Batch 392/600] [D loss: 0.448917] [G loss: 1.595693]\n",
            "[Epoch 45/50] [Batch 393/600] [D loss: 0.459481] [G loss: 1.621179]\n",
            "[Epoch 45/50] [Batch 394/600] [D loss: 0.387400] [G loss: 1.468548]\n",
            "[Epoch 45/50] [Batch 395/600] [D loss: 0.456440] [G loss: 1.479415]\n",
            "[Epoch 45/50] [Batch 396/600] [D loss: 0.459118] [G loss: 1.568586]\n",
            "[Epoch 45/50] [Batch 397/600] [D loss: 0.468247] [G loss: 1.624981]\n",
            "[Epoch 45/50] [Batch 398/600] [D loss: 0.414598] [G loss: 1.638284]\n",
            "[Epoch 45/50] [Batch 399/600] [D loss: 0.386751] [G loss: 1.527213]\n",
            "[Epoch 45/50] [Batch 400/600] [D loss: 0.407590] [G loss: 1.492463]\n",
            "[Epoch 45/50] [Batch 401/600] [D loss: 0.444110] [G loss: 1.486802]\n",
            "[Epoch 45/50] [Batch 402/600] [D loss: 0.402732] [G loss: 1.782817]\n",
            "[Epoch 45/50] [Batch 403/600] [D loss: 0.422791] [G loss: 1.695184]\n",
            "[Epoch 45/50] [Batch 404/600] [D loss: 0.395958] [G loss: 1.640372]\n",
            "[Epoch 45/50] [Batch 405/600] [D loss: 0.383072] [G loss: 1.747452]\n",
            "[Epoch 45/50] [Batch 406/600] [D loss: 0.369053] [G loss: 1.647487]\n",
            "[Epoch 45/50] [Batch 407/600] [D loss: 0.395876] [G loss: 1.614521]\n",
            "[Epoch 45/50] [Batch 408/600] [D loss: 0.363628] [G loss: 1.764625]\n",
            "[Epoch 45/50] [Batch 409/600] [D loss: 0.452333] [G loss: 1.834887]\n",
            "[Epoch 45/50] [Batch 410/600] [D loss: 0.459070] [G loss: 1.810995]\n",
            "[Epoch 45/50] [Batch 411/600] [D loss: 0.396536] [G loss: 1.489983]\n",
            "[Epoch 45/50] [Batch 412/600] [D loss: 0.435080] [G loss: 1.960335]\n",
            "[Epoch 45/50] [Batch 413/600] [D loss: 0.363436] [G loss: 2.007871]\n",
            "[Epoch 45/50] [Batch 414/600] [D loss: 0.335247] [G loss: 1.969805]\n",
            "[Epoch 45/50] [Batch 415/600] [D loss: 0.362510] [G loss: 1.998200]\n",
            "[Epoch 45/50] [Batch 416/600] [D loss: 0.468600] [G loss: 1.732053]\n",
            "[Epoch 45/50] [Batch 417/600] [D loss: 0.489716] [G loss: 1.792616]\n",
            "[Epoch 45/50] [Batch 418/600] [D loss: 0.402015] [G loss: 1.605959]\n",
            "[Epoch 45/50] [Batch 419/600] [D loss: 0.446761] [G loss: 1.480905]\n",
            "[Epoch 45/50] [Batch 420/600] [D loss: 0.467438] [G loss: 1.558957]\n",
            "[Epoch 45/50] [Batch 421/600] [D loss: 0.417954] [G loss: 1.853855]\n",
            "[Epoch 45/50] [Batch 422/600] [D loss: 0.398468] [G loss: 1.697619]\n",
            "[Epoch 45/50] [Batch 423/600] [D loss: 0.435541] [G loss: 1.469152]\n",
            "[Epoch 45/50] [Batch 424/600] [D loss: 0.442035] [G loss: 1.753026]\n",
            "[Epoch 45/50] [Batch 425/600] [D loss: 0.461841] [G loss: 1.703811]\n",
            "[Epoch 45/50] [Batch 426/600] [D loss: 0.459267] [G loss: 1.655229]\n",
            "[Epoch 45/50] [Batch 427/600] [D loss: 0.364257] [G loss: 1.486616]\n",
            "[Epoch 45/50] [Batch 428/600] [D loss: 0.449460] [G loss: 1.576899]\n",
            "[Epoch 45/50] [Batch 429/600] [D loss: 0.481739] [G loss: 1.627163]\n",
            "[Epoch 45/50] [Batch 430/600] [D loss: 0.470671] [G loss: 1.581191]\n",
            "[Epoch 45/50] [Batch 431/600] [D loss: 0.457704] [G loss: 1.629802]\n",
            "[Epoch 45/50] [Batch 432/600] [D loss: 0.438570] [G loss: 1.507285]\n",
            "[Epoch 45/50] [Batch 433/600] [D loss: 0.396385] [G loss: 1.203515]\n",
            "[Epoch 45/50] [Batch 434/600] [D loss: 0.403974] [G loss: 1.482377]\n",
            "[Epoch 45/50] [Batch 435/600] [D loss: 0.461993] [G loss: 1.691423]\n",
            "[Epoch 45/50] [Batch 436/600] [D loss: 0.365640] [G loss: 1.663701]\n",
            "[Epoch 45/50] [Batch 437/600] [D loss: 0.445395] [G loss: 1.737235]\n",
            "[Epoch 45/50] [Batch 438/600] [D loss: 0.417863] [G loss: 1.531261]\n",
            "[Epoch 45/50] [Batch 439/600] [D loss: 0.433369] [G loss: 1.536850]\n",
            "[Epoch 45/50] [Batch 440/600] [D loss: 0.537198] [G loss: 1.375929]\n",
            "[Epoch 45/50] [Batch 441/600] [D loss: 0.413893] [G loss: 1.624898]\n",
            "[Epoch 45/50] [Batch 442/600] [D loss: 0.373371] [G loss: 1.750521]\n",
            "[Epoch 45/50] [Batch 443/600] [D loss: 0.418365] [G loss: 1.719585]\n",
            "[Epoch 45/50] [Batch 444/600] [D loss: 0.437761] [G loss: 1.655802]\n",
            "[Epoch 45/50] [Batch 445/600] [D loss: 0.443523] [G loss: 1.752411]\n",
            "[Epoch 45/50] [Batch 446/600] [D loss: 0.382653] [G loss: 1.519135]\n",
            "[Epoch 45/50] [Batch 447/600] [D loss: 0.410206] [G loss: 1.435672]\n",
            "[Epoch 45/50] [Batch 448/600] [D loss: 0.481506] [G loss: 1.569442]\n",
            "[Epoch 45/50] [Batch 449/600] [D loss: 0.481876] [G loss: 1.611722]\n",
            "[Epoch 45/50] [Batch 450/600] [D loss: 0.411256] [G loss: 1.683627]\n",
            "[Epoch 45/50] [Batch 451/600] [D loss: 0.374435] [G loss: 1.523753]\n",
            "[Epoch 45/50] [Batch 452/600] [D loss: 0.404952] [G loss: 1.609862]\n",
            "[Epoch 45/50] [Batch 453/600] [D loss: 0.440782] [G loss: 1.808456]\n",
            "[Epoch 45/50] [Batch 454/600] [D loss: 0.448692] [G loss: 1.788187]\n",
            "[Epoch 45/50] [Batch 455/600] [D loss: 0.483427] [G loss: 1.720773]\n",
            "[Epoch 45/50] [Batch 456/600] [D loss: 0.401675] [G loss: 1.586156]\n",
            "[Epoch 45/50] [Batch 457/600] [D loss: 0.442496] [G loss: 1.636981]\n",
            "[Epoch 45/50] [Batch 458/600] [D loss: 0.494559] [G loss: 1.628815]\n",
            "[Epoch 45/50] [Batch 459/600] [D loss: 0.431184] [G loss: 1.648438]\n",
            "[Epoch 45/50] [Batch 460/600] [D loss: 0.480205] [G loss: 1.556620]\n",
            "[Epoch 45/50] [Batch 461/600] [D loss: 0.440006] [G loss: 1.596809]\n",
            "[Epoch 45/50] [Batch 462/600] [D loss: 0.430766] [G loss: 1.627494]\n",
            "[Epoch 45/50] [Batch 463/600] [D loss: 0.407053] [G loss: 1.640213]\n",
            "[Epoch 45/50] [Batch 464/600] [D loss: 0.364968] [G loss: 1.583448]\n",
            "[Epoch 45/50] [Batch 465/600] [D loss: 0.387472] [G loss: 1.583727]\n",
            "[Epoch 45/50] [Batch 466/600] [D loss: 0.456697] [G loss: 1.772338]\n",
            "[Epoch 45/50] [Batch 467/600] [D loss: 0.408353] [G loss: 1.668938]\n",
            "[Epoch 45/50] [Batch 468/600] [D loss: 0.447177] [G loss: 1.467642]\n",
            "[Epoch 45/50] [Batch 469/600] [D loss: 0.430875] [G loss: 1.835748]\n",
            "[Epoch 45/50] [Batch 470/600] [D loss: 0.404163] [G loss: 1.829972]\n",
            "[Epoch 45/50] [Batch 471/600] [D loss: 0.427591] [G loss: 1.732841]\n",
            "[Epoch 45/50] [Batch 472/600] [D loss: 0.430699] [G loss: 1.826964]\n",
            "[Epoch 45/50] [Batch 473/600] [D loss: 0.422932] [G loss: 1.647787]\n",
            "[Epoch 45/50] [Batch 474/600] [D loss: 0.435480] [G loss: 1.466277]\n",
            "[Epoch 45/50] [Batch 475/600] [D loss: 0.356166] [G loss: 1.509573]\n",
            "[Epoch 45/50] [Batch 476/600] [D loss: 0.416675] [G loss: 1.658783]\n",
            "[Epoch 45/50] [Batch 477/600] [D loss: 0.342949] [G loss: 1.674022]\n",
            "[Epoch 45/50] [Batch 478/600] [D loss: 0.431358] [G loss: 1.676164]\n",
            "[Epoch 45/50] [Batch 479/600] [D loss: 0.397357] [G loss: 1.614765]\n",
            "[Epoch 45/50] [Batch 480/600] [D loss: 0.414483] [G loss: 1.884072]\n",
            "[Epoch 45/50] [Batch 481/600] [D loss: 0.441931] [G loss: 1.798205]\n",
            "[Epoch 45/50] [Batch 482/600] [D loss: 0.404922] [G loss: 1.695574]\n",
            "[Epoch 45/50] [Batch 483/600] [D loss: 0.421431] [G loss: 1.610910]\n",
            "[Epoch 45/50] [Batch 484/600] [D loss: 0.403957] [G loss: 1.702274]\n",
            "[Epoch 45/50] [Batch 485/600] [D loss: 0.467877] [G loss: 1.676091]\n",
            "[Epoch 45/50] [Batch 486/600] [D loss: 0.431867] [G loss: 1.738166]\n",
            "[Epoch 45/50] [Batch 487/600] [D loss: 0.435167] [G loss: 1.788223]\n",
            "[Epoch 45/50] [Batch 488/600] [D loss: 0.406791] [G loss: 1.705363]\n",
            "[Epoch 45/50] [Batch 489/600] [D loss: 0.475691] [G loss: 1.670436]\n",
            "[Epoch 45/50] [Batch 490/600] [D loss: 0.509511] [G loss: 1.580555]\n",
            "[Epoch 45/50] [Batch 491/600] [D loss: 0.433887] [G loss: 1.579619]\n",
            "[Epoch 45/50] [Batch 492/600] [D loss: 0.437271] [G loss: 1.492835]\n",
            "[Epoch 45/50] [Batch 493/600] [D loss: 0.422043] [G loss: 1.560641]\n",
            "[Epoch 45/50] [Batch 494/600] [D loss: 0.433809] [G loss: 1.586574]\n",
            "[Epoch 45/50] [Batch 495/600] [D loss: 0.502510] [G loss: 1.556782]\n",
            "[Epoch 45/50] [Batch 496/600] [D loss: 0.461730] [G loss: 1.763915]\n",
            "[Epoch 45/50] [Batch 497/600] [D loss: 0.435081] [G loss: 1.649456]\n",
            "[Epoch 45/50] [Batch 498/600] [D loss: 0.408533] [G loss: 1.588598]\n",
            "[Epoch 45/50] [Batch 499/600] [D loss: 0.465730] [G loss: 1.759161]\n",
            "[Epoch 45/50] [Batch 500/600] [D loss: 0.437395] [G loss: 1.651857]\n",
            "[Epoch 45/50] [Batch 501/600] [D loss: 0.402271] [G loss: 1.479387]\n",
            "[Epoch 45/50] [Batch 502/600] [D loss: 0.407303] [G loss: 1.723617]\n",
            "[Epoch 45/50] [Batch 503/600] [D loss: 0.462738] [G loss: 1.560769]\n",
            "[Epoch 45/50] [Batch 504/600] [D loss: 0.399029] [G loss: 1.839197]\n",
            "[Epoch 45/50] [Batch 505/600] [D loss: 0.371227] [G loss: 1.673917]\n",
            "[Epoch 45/50] [Batch 506/600] [D loss: 0.419287] [G loss: 1.380122]\n",
            "[Epoch 45/50] [Batch 507/600] [D loss: 0.477811] [G loss: 1.678883]\n",
            "[Epoch 45/50] [Batch 508/600] [D loss: 0.438931] [G loss: 1.395834]\n",
            "[Epoch 45/50] [Batch 509/600] [D loss: 0.358707] [G loss: 1.742828]\n",
            "[Epoch 45/50] [Batch 510/600] [D loss: 0.413898] [G loss: 1.612167]\n",
            "[Epoch 45/50] [Batch 511/600] [D loss: 0.404157] [G loss: 1.495675]\n",
            "[Epoch 45/50] [Batch 512/600] [D loss: 0.459714] [G loss: 1.712394]\n",
            "[Epoch 45/50] [Batch 513/600] [D loss: 0.418114] [G loss: 1.742747]\n",
            "[Epoch 45/50] [Batch 514/600] [D loss: 0.386500] [G loss: 1.626624]\n",
            "[Epoch 45/50] [Batch 515/600] [D loss: 0.386075] [G loss: 1.765196]\n",
            "[Epoch 45/50] [Batch 516/600] [D loss: 0.455026] [G loss: 1.729513]\n",
            "[Epoch 45/50] [Batch 517/600] [D loss: 0.432494] [G loss: 1.608219]\n",
            "[Epoch 45/50] [Batch 518/600] [D loss: 0.437216] [G loss: 1.827290]\n",
            "[Epoch 45/50] [Batch 519/600] [D loss: 0.508121] [G loss: 1.735464]\n",
            "[Epoch 45/50] [Batch 520/600] [D loss: 0.439114] [G loss: 1.702676]\n",
            "[Epoch 45/50] [Batch 521/600] [D loss: 0.358096] [G loss: 1.788782]\n",
            "[Epoch 45/50] [Batch 522/600] [D loss: 0.517344] [G loss: 1.656929]\n",
            "[Epoch 45/50] [Batch 523/600] [D loss: 0.445271] [G loss: 1.552131]\n",
            "[Epoch 45/50] [Batch 524/600] [D loss: 0.397483] [G loss: 1.446335]\n",
            "[Epoch 45/50] [Batch 525/600] [D loss: 0.363998] [G loss: 1.681509]\n",
            "[Epoch 45/50] [Batch 526/600] [D loss: 0.409192] [G loss: 1.806980]\n",
            "[Epoch 45/50] [Batch 527/600] [D loss: 0.372950] [G loss: 1.883631]\n",
            "[Epoch 45/50] [Batch 528/600] [D loss: 0.451762] [G loss: 1.874777]\n",
            "[Epoch 45/50] [Batch 529/600] [D loss: 0.428286] [G loss: 1.789587]\n",
            "[Epoch 45/50] [Batch 530/600] [D loss: 0.459326] [G loss: 1.511439]\n",
            "[Epoch 45/50] [Batch 531/600] [D loss: 0.441805] [G loss: 1.531248]\n",
            "[Epoch 45/50] [Batch 532/600] [D loss: 0.386060] [G loss: 1.592721]\n",
            "[Epoch 45/50] [Batch 533/600] [D loss: 0.365702] [G loss: 1.652358]\n",
            "[Epoch 45/50] [Batch 534/600] [D loss: 0.444063] [G loss: 1.732584]\n",
            "[Epoch 45/50] [Batch 535/600] [D loss: 0.431875] [G loss: 1.621640]\n",
            "[Epoch 45/50] [Batch 536/600] [D loss: 0.425258] [G loss: 1.584578]\n",
            "[Epoch 45/50] [Batch 537/600] [D loss: 0.455591] [G loss: 1.722928]\n",
            "[Epoch 45/50] [Batch 538/600] [D loss: 0.429941] [G loss: 1.616424]\n",
            "[Epoch 45/50] [Batch 539/600] [D loss: 0.425733] [G loss: 1.806335]\n",
            "[Epoch 45/50] [Batch 540/600] [D loss: 0.460833] [G loss: 1.427603]\n",
            "[Epoch 45/50] [Batch 541/600] [D loss: 0.401174] [G loss: 1.549465]\n",
            "[Epoch 45/50] [Batch 542/600] [D loss: 0.419273] [G loss: 1.541338]\n",
            "[Epoch 45/50] [Batch 543/600] [D loss: 0.458485] [G loss: 1.592948]\n",
            "[Epoch 45/50] [Batch 544/600] [D loss: 0.440942] [G loss: 1.676051]\n",
            "[Epoch 45/50] [Batch 545/600] [D loss: 0.457298] [G loss: 1.678851]\n",
            "[Epoch 45/50] [Batch 546/600] [D loss: 0.441943] [G loss: 1.741300]\n",
            "[Epoch 45/50] [Batch 547/600] [D loss: 0.476010] [G loss: 1.630706]\n",
            "[Epoch 45/50] [Batch 548/600] [D loss: 0.444964] [G loss: 1.464356]\n",
            "[Epoch 45/50] [Batch 549/600] [D loss: 0.469489] [G loss: 1.600121]\n",
            "[Epoch 45/50] [Batch 550/600] [D loss: 0.368408] [G loss: 1.665766]\n",
            "[Epoch 45/50] [Batch 551/600] [D loss: 0.438978] [G loss: 1.615527]\n",
            "[Epoch 45/50] [Batch 552/600] [D loss: 0.411048] [G loss: 1.479109]\n",
            "[Epoch 45/50] [Batch 553/600] [D loss: 0.457289] [G loss: 1.485416]\n",
            "[Epoch 45/50] [Batch 554/600] [D loss: 0.450043] [G loss: 1.779212]\n",
            "[Epoch 45/50] [Batch 555/600] [D loss: 0.391692] [G loss: 1.622151]\n",
            "[Epoch 45/50] [Batch 556/600] [D loss: 0.414873] [G loss: 1.746700]\n",
            "[Epoch 45/50] [Batch 557/600] [D loss: 0.430965] [G loss: 1.733401]\n",
            "[Epoch 45/50] [Batch 558/600] [D loss: 0.412445] [G loss: 1.813731]\n",
            "[Epoch 45/50] [Batch 559/600] [D loss: 0.345716] [G loss: 1.737717]\n",
            "[Epoch 45/50] [Batch 560/600] [D loss: 0.409345] [G loss: 1.889778]\n",
            "[Epoch 45/50] [Batch 561/600] [D loss: 0.444894] [G loss: 1.681720]\n",
            "[Epoch 45/50] [Batch 562/600] [D loss: 0.537559] [G loss: 1.725160]\n",
            "[Epoch 45/50] [Batch 563/600] [D loss: 0.463697] [G loss: 1.636130]\n",
            "[Epoch 45/50] [Batch 564/600] [D loss: 0.531382] [G loss: 1.686823]\n",
            "[Epoch 45/50] [Batch 565/600] [D loss: 0.455063] [G loss: 1.290404]\n",
            "[Epoch 45/50] [Batch 566/600] [D loss: 0.396021] [G loss: 1.691573]\n",
            "[Epoch 45/50] [Batch 567/600] [D loss: 0.438258] [G loss: 1.448768]\n",
            "[Epoch 45/50] [Batch 568/600] [D loss: 0.400538] [G loss: 1.524887]\n",
            "[Epoch 45/50] [Batch 569/600] [D loss: 0.376396] [G loss: 1.484835]\n",
            "[Epoch 45/50] [Batch 570/600] [D loss: 0.446809] [G loss: 1.637217]\n",
            "[Epoch 45/50] [Batch 571/600] [D loss: 0.413042] [G loss: 1.871984]\n",
            "[Epoch 45/50] [Batch 572/600] [D loss: 0.419900] [G loss: 1.616786]\n",
            "[Epoch 45/50] [Batch 573/600] [D loss: 0.422310] [G loss: 1.808269]\n",
            "[Epoch 45/50] [Batch 574/600] [D loss: 0.493327] [G loss: 1.779968]\n",
            "[Epoch 45/50] [Batch 575/600] [D loss: 0.412506] [G loss: 1.659253]\n",
            "[Epoch 45/50] [Batch 576/600] [D loss: 0.488096] [G loss: 1.628470]\n",
            "[Epoch 45/50] [Batch 577/600] [D loss: 0.428041] [G loss: 1.590346]\n",
            "[Epoch 45/50] [Batch 578/600] [D loss: 0.438626] [G loss: 1.579879]\n",
            "[Epoch 45/50] [Batch 579/600] [D loss: 0.451555] [G loss: 1.622044]\n",
            "[Epoch 45/50] [Batch 580/600] [D loss: 0.433180] [G loss: 1.807604]\n",
            "[Epoch 45/50] [Batch 581/600] [D loss: 0.362026] [G loss: 1.710300]\n",
            "[Epoch 45/50] [Batch 582/600] [D loss: 0.401928] [G loss: 1.835708]\n",
            "[Epoch 45/50] [Batch 583/600] [D loss: 0.379857] [G loss: 1.913465]\n",
            "[Epoch 45/50] [Batch 584/600] [D loss: 0.430407] [G loss: 1.944386]\n",
            "[Epoch 45/50] [Batch 585/600] [D loss: 0.469318] [G loss: 1.727979]\n",
            "[Epoch 45/50] [Batch 586/600] [D loss: 0.465309] [G loss: 1.716041]\n",
            "[Epoch 45/50] [Batch 587/600] [D loss: 0.419881] [G loss: 1.568052]\n",
            "[Epoch 45/50] [Batch 588/600] [D loss: 0.409789] [G loss: 1.640898]\n",
            "[Epoch 45/50] [Batch 589/600] [D loss: 0.351244] [G loss: 1.455537]\n",
            "[Epoch 45/50] [Batch 590/600] [D loss: 0.334041] [G loss: 1.992316]\n",
            "[Epoch 45/50] [Batch 591/600] [D loss: 0.402875] [G loss: 1.713145]\n",
            "[Epoch 45/50] [Batch 592/600] [D loss: 0.402543] [G loss: 2.026074]\n",
            "[Epoch 45/50] [Batch 593/600] [D loss: 0.528118] [G loss: 2.187473]\n",
            "[Epoch 45/50] [Batch 594/600] [D loss: 0.364904] [G loss: 1.677981]\n",
            "[Epoch 45/50] [Batch 595/600] [D loss: 0.415039] [G loss: 1.396571]\n",
            "[Epoch 45/50] [Batch 596/600] [D loss: 0.362277] [G loss: 1.571861]\n",
            "[Epoch 45/50] [Batch 597/600] [D loss: 0.396471] [G loss: 1.636754]\n",
            "[Epoch 45/50] [Batch 598/600] [D loss: 0.439786] [G loss: 1.980013]\n",
            "[Epoch 45/50] [Batch 599/600] [D loss: 0.351530] [G loss: 1.918027]\n",
            "[Epoch 46/50] [Batch 0/600] [D loss: 0.408403] [G loss: 1.887500]\n",
            "[Epoch 46/50] [Batch 1/600] [D loss: 0.472433] [G loss: 1.788237]\n",
            "[Epoch 46/50] [Batch 2/600] [D loss: 0.327766] [G loss: 2.133592]\n",
            "[Epoch 46/50] [Batch 3/600] [D loss: 0.392235] [G loss: 1.948979]\n",
            "[Epoch 46/50] [Batch 4/600] [D loss: 0.399930] [G loss: 1.766110]\n",
            "[Epoch 46/50] [Batch 5/600] [D loss: 0.375031] [G loss: 1.882082]\n",
            "[Epoch 46/50] [Batch 6/600] [D loss: 0.375166] [G loss: 1.893767]\n",
            "[Epoch 46/50] [Batch 7/600] [D loss: 0.423555] [G loss: 1.800242]\n",
            "[Epoch 46/50] [Batch 8/600] [D loss: 0.400943] [G loss: 1.749856]\n",
            "[Epoch 46/50] [Batch 9/600] [D loss: 0.333266] [G loss: 1.889241]\n",
            "[Epoch 46/50] [Batch 10/600] [D loss: 0.445558] [G loss: 1.952885]\n",
            "[Epoch 46/50] [Batch 11/600] [D loss: 0.454002] [G loss: 1.823401]\n",
            "[Epoch 46/50] [Batch 12/600] [D loss: 0.498961] [G loss: 2.064422]\n",
            "[Epoch 46/50] [Batch 13/600] [D loss: 0.432243] [G loss: 1.521243]\n",
            "[Epoch 46/50] [Batch 14/600] [D loss: 0.421851] [G loss: 1.475586]\n",
            "[Epoch 46/50] [Batch 15/600] [D loss: 0.405484] [G loss: 1.705333]\n",
            "[Epoch 46/50] [Batch 16/600] [D loss: 0.396554] [G loss: 1.908159]\n",
            "[Epoch 46/50] [Batch 17/600] [D loss: 0.364953] [G loss: 2.069742]\n",
            "[Epoch 46/50] [Batch 18/600] [D loss: 0.422571] [G loss: 1.887568]\n",
            "[Epoch 46/50] [Batch 19/600] [D loss: 0.460423] [G loss: 1.665368]\n",
            "[Epoch 46/50] [Batch 20/600] [D loss: 0.393673] [G loss: 1.553997]\n",
            "[Epoch 46/50] [Batch 21/600] [D loss: 0.428411] [G loss: 1.719440]\n",
            "[Epoch 46/50] [Batch 22/600] [D loss: 0.363330] [G loss: 1.887708]\n",
            "[Epoch 46/50] [Batch 23/600] [D loss: 0.401403] [G loss: 1.799277]\n",
            "[Epoch 46/50] [Batch 24/600] [D loss: 0.353999] [G loss: 2.101718]\n",
            "[Epoch 46/50] [Batch 25/600] [D loss: 0.429299] [G loss: 1.796449]\n",
            "[Epoch 46/50] [Batch 26/600] [D loss: 0.447033] [G loss: 1.762795]\n",
            "[Epoch 46/50] [Batch 27/600] [D loss: 0.453102] [G loss: 2.229846]\n",
            "[Epoch 46/50] [Batch 28/600] [D loss: 0.403933] [G loss: 1.964710]\n",
            "[Epoch 46/50] [Batch 29/600] [D loss: 0.412077] [G loss: 2.012823]\n",
            "[Epoch 46/50] [Batch 30/600] [D loss: 0.411927] [G loss: 1.531195]\n",
            "[Epoch 46/50] [Batch 31/600] [D loss: 0.445645] [G loss: 1.775219]\n",
            "[Epoch 46/50] [Batch 32/600] [D loss: 0.462198] [G loss: 1.722589]\n",
            "[Epoch 46/50] [Batch 33/600] [D loss: 0.371086] [G loss: 1.611271]\n",
            "[Epoch 46/50] [Batch 34/600] [D loss: 0.418947] [G loss: 1.805813]\n",
            "[Epoch 46/50] [Batch 35/600] [D loss: 0.354018] [G loss: 1.731620]\n",
            "[Epoch 46/50] [Batch 36/600] [D loss: 0.497867] [G loss: 1.736445]\n",
            "[Epoch 46/50] [Batch 37/600] [D loss: 0.415223] [G loss: 1.799505]\n",
            "[Epoch 46/50] [Batch 38/600] [D loss: 0.420565] [G loss: 1.767657]\n",
            "[Epoch 46/50] [Batch 39/600] [D loss: 0.373063] [G loss: 1.709544]\n",
            "[Epoch 46/50] [Batch 40/600] [D loss: 0.408049] [G loss: 1.918222]\n",
            "[Epoch 46/50] [Batch 41/600] [D loss: 0.397202] [G loss: 1.624784]\n",
            "[Epoch 46/50] [Batch 42/600] [D loss: 0.433941] [G loss: 1.663044]\n",
            "[Epoch 46/50] [Batch 43/600] [D loss: 0.496107] [G loss: 1.657570]\n",
            "[Epoch 46/50] [Batch 44/600] [D loss: 0.343664] [G loss: 1.693289]\n",
            "[Epoch 46/50] [Batch 45/600] [D loss: 0.370239] [G loss: 1.862695]\n",
            "[Epoch 46/50] [Batch 46/600] [D loss: 0.453916] [G loss: 1.634322]\n",
            "[Epoch 46/50] [Batch 47/600] [D loss: 0.384986] [G loss: 1.718623]\n",
            "[Epoch 46/50] [Batch 48/600] [D loss: 0.443098] [G loss: 1.749080]\n",
            "[Epoch 46/50] [Batch 49/600] [D loss: 0.394044] [G loss: 1.847225]\n",
            "[Epoch 46/50] [Batch 50/600] [D loss: 0.388957] [G loss: 1.664341]\n",
            "[Epoch 46/50] [Batch 51/600] [D loss: 0.376161] [G loss: 1.987429]\n",
            "[Epoch 46/50] [Batch 52/600] [D loss: 0.363394] [G loss: 1.680639]\n",
            "[Epoch 46/50] [Batch 53/600] [D loss: 0.392922] [G loss: 2.018895]\n",
            "[Epoch 46/50] [Batch 54/600] [D loss: 0.411776] [G loss: 1.834441]\n",
            "[Epoch 46/50] [Batch 55/600] [D loss: 0.406546] [G loss: 2.146095]\n",
            "[Epoch 46/50] [Batch 56/600] [D loss: 0.372652] [G loss: 2.000924]\n",
            "[Epoch 46/50] [Batch 57/600] [D loss: 0.412962] [G loss: 2.060045]\n",
            "[Epoch 46/50] [Batch 58/600] [D loss: 0.420564] [G loss: 1.872616]\n",
            "[Epoch 46/50] [Batch 59/600] [D loss: 0.396661] [G loss: 1.953281]\n",
            "[Epoch 46/50] [Batch 60/600] [D loss: 0.446379] [G loss: 1.838599]\n",
            "[Epoch 46/50] [Batch 61/600] [D loss: 0.338752] [G loss: 2.077412]\n",
            "[Epoch 46/50] [Batch 62/600] [D loss: 0.441941] [G loss: 1.738259]\n",
            "[Epoch 46/50] [Batch 63/600] [D loss: 0.402580] [G loss: 1.893570]\n",
            "[Epoch 46/50] [Batch 64/600] [D loss: 0.429782] [G loss: 1.701829]\n",
            "[Epoch 46/50] [Batch 65/600] [D loss: 0.350221] [G loss: 1.624966]\n",
            "[Epoch 46/50] [Batch 66/600] [D loss: 0.427512] [G loss: 1.784585]\n",
            "[Epoch 46/50] [Batch 67/600] [D loss: 0.432424] [G loss: 2.023250]\n",
            "[Epoch 46/50] [Batch 68/600] [D loss: 0.507837] [G loss: 1.619441]\n",
            "[Epoch 46/50] [Batch 69/600] [D loss: 0.423320] [G loss: 1.564200]\n",
            "[Epoch 46/50] [Batch 70/600] [D loss: 0.480351] [G loss: 1.469184]\n",
            "[Epoch 46/50] [Batch 71/600] [D loss: 0.460218] [G loss: 1.391548]\n",
            "[Epoch 46/50] [Batch 72/600] [D loss: 0.473264] [G loss: 1.545195]\n",
            "[Epoch 46/50] [Batch 73/600] [D loss: 0.515113] [G loss: 1.951825]\n",
            "[Epoch 46/50] [Batch 74/600] [D loss: 0.422232] [G loss: 1.832025]\n",
            "[Epoch 46/50] [Batch 75/600] [D loss: 0.446683] [G loss: 1.639886]\n",
            "[Epoch 46/50] [Batch 76/600] [D loss: 0.430948] [G loss: 1.519849]\n",
            "[Epoch 46/50] [Batch 77/600] [D loss: 0.401397] [G loss: 1.685746]\n",
            "[Epoch 46/50] [Batch 78/600] [D loss: 0.361502] [G loss: 1.732521]\n",
            "[Epoch 46/50] [Batch 79/600] [D loss: 0.410675] [G loss: 1.610171]\n",
            "[Epoch 46/50] [Batch 80/600] [D loss: 0.346253] [G loss: 1.850897]\n",
            "[Epoch 46/50] [Batch 81/600] [D loss: 0.425870] [G loss: 1.699523]\n",
            "[Epoch 46/50] [Batch 82/600] [D loss: 0.422626] [G loss: 1.579008]\n",
            "[Epoch 46/50] [Batch 83/600] [D loss: 0.390809] [G loss: 1.833323]\n",
            "[Epoch 46/50] [Batch 84/600] [D loss: 0.361378] [G loss: 1.733490]\n",
            "[Epoch 46/50] [Batch 85/600] [D loss: 0.393471] [G loss: 1.847740]\n",
            "[Epoch 46/50] [Batch 86/600] [D loss: 0.428888] [G loss: 1.732632]\n",
            "[Epoch 46/50] [Batch 87/600] [D loss: 0.443021] [G loss: 1.691708]\n",
            "[Epoch 46/50] [Batch 88/600] [D loss: 0.491938] [G loss: 1.579347]\n",
            "[Epoch 46/50] [Batch 89/600] [D loss: 0.457091] [G loss: 1.632333]\n",
            "[Epoch 46/50] [Batch 90/600] [D loss: 0.410963] [G loss: 1.603049]\n",
            "[Epoch 46/50] [Batch 91/600] [D loss: 0.454096] [G loss: 1.728439]\n",
            "[Epoch 46/50] [Batch 92/600] [D loss: 0.463739] [G loss: 1.628813]\n",
            "[Epoch 46/50] [Batch 93/600] [D loss: 0.382715] [G loss: 1.769982]\n",
            "[Epoch 46/50] [Batch 94/600] [D loss: 0.407801] [G loss: 1.735856]\n",
            "[Epoch 46/50] [Batch 95/600] [D loss: 0.349971] [G loss: 1.678239]\n",
            "[Epoch 46/50] [Batch 96/600] [D loss: 0.445424] [G loss: 1.662948]\n",
            "[Epoch 46/50] [Batch 97/600] [D loss: 0.421378] [G loss: 1.471498]\n",
            "[Epoch 46/50] [Batch 98/600] [D loss: 0.376774] [G loss: 1.690023]\n",
            "[Epoch 46/50] [Batch 99/600] [D loss: 0.410185] [G loss: 1.789472]\n",
            "[Epoch 46/50] [Batch 100/600] [D loss: 0.457104] [G loss: 1.845595]\n",
            "[Epoch 46/50] [Batch 101/600] [D loss: 0.453703] [G loss: 1.707869]\n",
            "[Epoch 46/50] [Batch 102/600] [D loss: 0.410595] [G loss: 1.793884]\n",
            "[Epoch 46/50] [Batch 103/600] [D loss: 0.436206] [G loss: 1.634457]\n",
            "[Epoch 46/50] [Batch 104/600] [D loss: 0.421960] [G loss: 1.638262]\n",
            "[Epoch 46/50] [Batch 105/600] [D loss: 0.324625] [G loss: 1.798732]\n",
            "[Epoch 46/50] [Batch 106/600] [D loss: 0.427366] [G loss: 1.796434]\n",
            "[Epoch 46/50] [Batch 107/600] [D loss: 0.448011] [G loss: 1.995999]\n",
            "[Epoch 46/50] [Batch 108/600] [D loss: 0.380822] [G loss: 1.916608]\n",
            "[Epoch 46/50] [Batch 109/600] [D loss: 0.370447] [G loss: 1.753539]\n",
            "[Epoch 46/50] [Batch 110/600] [D loss: 0.461789] [G loss: 1.602194]\n",
            "[Epoch 46/50] [Batch 111/600] [D loss: 0.423913] [G loss: 1.689128]\n",
            "[Epoch 46/50] [Batch 112/600] [D loss: 0.478862] [G loss: 1.682762]\n",
            "[Epoch 46/50] [Batch 113/600] [D loss: 0.428506] [G loss: 1.752360]\n",
            "[Epoch 46/50] [Batch 114/600] [D loss: 0.436894] [G loss: 1.932415]\n",
            "[Epoch 46/50] [Batch 115/600] [D loss: 0.432811] [G loss: 1.989236]\n",
            "[Epoch 46/50] [Batch 116/600] [D loss: 0.432498] [G loss: 1.614905]\n",
            "[Epoch 46/50] [Batch 117/600] [D loss: 0.402823] [G loss: 1.704825]\n",
            "[Epoch 46/50] [Batch 118/600] [D loss: 0.500925] [G loss: 1.542951]\n",
            "[Epoch 46/50] [Batch 119/600] [D loss: 0.475668] [G loss: 1.468009]\n",
            "[Epoch 46/50] [Batch 120/600] [D loss: 0.432481] [G loss: 1.664354]\n",
            "[Epoch 46/50] [Batch 121/600] [D loss: 0.314392] [G loss: 1.691898]\n",
            "[Epoch 46/50] [Batch 122/600] [D loss: 0.406565] [G loss: 1.600443]\n",
            "[Epoch 46/50] [Batch 123/600] [D loss: 0.426221] [G loss: 1.972453]\n",
            "[Epoch 46/50] [Batch 124/600] [D loss: 0.403006] [G loss: 1.814226]\n",
            "[Epoch 46/50] [Batch 125/600] [D loss: 0.421124] [G loss: 1.825247]\n",
            "[Epoch 46/50] [Batch 126/600] [D loss: 0.392816] [G loss: 1.706429]\n",
            "[Epoch 46/50] [Batch 127/600] [D loss: 0.421537] [G loss: 1.774073]\n",
            "[Epoch 46/50] [Batch 128/600] [D loss: 0.443699] [G loss: 1.684517]\n",
            "[Epoch 46/50] [Batch 129/600] [D loss: 0.432952] [G loss: 1.654562]\n",
            "[Epoch 46/50] [Batch 130/600] [D loss: 0.435613] [G loss: 1.929350]\n",
            "[Epoch 46/50] [Batch 131/600] [D loss: 0.401185] [G loss: 1.503039]\n",
            "[Epoch 46/50] [Batch 132/600] [D loss: 0.367937] [G loss: 1.549619]\n",
            "[Epoch 46/50] [Batch 133/600] [D loss: 0.432836] [G loss: 1.820146]\n",
            "[Epoch 46/50] [Batch 134/600] [D loss: 0.424850] [G loss: 1.945996]\n",
            "[Epoch 46/50] [Batch 135/600] [D loss: 0.391469] [G loss: 1.755355]\n",
            "[Epoch 46/50] [Batch 136/600] [D loss: 0.463957] [G loss: 1.443012]\n",
            "[Epoch 46/50] [Batch 137/600] [D loss: 0.541389] [G loss: 1.577730]\n",
            "[Epoch 46/50] [Batch 138/600] [D loss: 0.399691] [G loss: 1.694687]\n",
            "[Epoch 46/50] [Batch 139/600] [D loss: 0.377398] [G loss: 1.467712]\n",
            "[Epoch 46/50] [Batch 140/600] [D loss: 0.418661] [G loss: 1.618661]\n",
            "[Epoch 46/50] [Batch 141/600] [D loss: 0.362418] [G loss: 1.740402]\n",
            "[Epoch 46/50] [Batch 142/600] [D loss: 0.393668] [G loss: 1.777272]\n",
            "[Epoch 46/50] [Batch 143/600] [D loss: 0.361992] [G loss: 2.007345]\n",
            "[Epoch 46/50] [Batch 144/600] [D loss: 0.427534] [G loss: 1.504847]\n",
            "[Epoch 46/50] [Batch 145/600] [D loss: 0.451006] [G loss: 1.893832]\n",
            "[Epoch 46/50] [Batch 146/600] [D loss: 0.481241] [G loss: 1.781587]\n",
            "[Epoch 46/50] [Batch 147/600] [D loss: 0.407300] [G loss: 1.775542]\n",
            "[Epoch 46/50] [Batch 148/600] [D loss: 0.372927] [G loss: 1.976015]\n",
            "[Epoch 46/50] [Batch 149/600] [D loss: 0.481645] [G loss: 1.794201]\n",
            "[Epoch 46/50] [Batch 150/600] [D loss: 0.431004] [G loss: 1.768970]\n",
            "[Epoch 46/50] [Batch 151/600] [D loss: 0.422123] [G loss: 1.689280]\n",
            "[Epoch 46/50] [Batch 152/600] [D loss: 0.418503] [G loss: 1.699170]\n",
            "[Epoch 46/50] [Batch 153/600] [D loss: 0.463009] [G loss: 1.782888]\n",
            "[Epoch 46/50] [Batch 154/600] [D loss: 0.416227] [G loss: 1.485321]\n",
            "[Epoch 46/50] [Batch 155/600] [D loss: 0.340005] [G loss: 1.703967]\n",
            "[Epoch 46/50] [Batch 156/600] [D loss: 0.379070] [G loss: 1.576636]\n",
            "[Epoch 46/50] [Batch 157/600] [D loss: 0.417109] [G loss: 1.509347]\n",
            "[Epoch 46/50] [Batch 158/600] [D loss: 0.446978] [G loss: 1.696674]\n",
            "[Epoch 46/50] [Batch 159/600] [D loss: 0.360544] [G loss: 2.075958]\n",
            "[Epoch 46/50] [Batch 160/600] [D loss: 0.452530] [G loss: 1.673014]\n",
            "[Epoch 46/50] [Batch 161/600] [D loss: 0.434105] [G loss: 1.620979]\n",
            "[Epoch 46/50] [Batch 162/600] [D loss: 0.374038] [G loss: 1.740936]\n",
            "[Epoch 46/50] [Batch 163/600] [D loss: 0.441426] [G loss: 2.121304]\n",
            "[Epoch 46/50] [Batch 164/600] [D loss: 0.465243] [G loss: 1.749275]\n",
            "[Epoch 46/50] [Batch 165/600] [D loss: 0.505750] [G loss: 1.609822]\n",
            "[Epoch 46/50] [Batch 166/600] [D loss: 0.355122] [G loss: 1.785989]\n",
            "[Epoch 46/50] [Batch 167/600] [D loss: 0.390192] [G loss: 1.745336]\n",
            "[Epoch 46/50] [Batch 168/600] [D loss: 0.364616] [G loss: 1.777981]\n",
            "[Epoch 46/50] [Batch 169/600] [D loss: 0.401890] [G loss: 1.631614]\n",
            "[Epoch 46/50] [Batch 170/600] [D loss: 0.446126] [G loss: 1.504336]\n",
            "[Epoch 46/50] [Batch 171/600] [D loss: 0.383545] [G loss: 1.746162]\n",
            "[Epoch 46/50] [Batch 172/600] [D loss: 0.375606] [G loss: 1.784167]\n",
            "[Epoch 46/50] [Batch 173/600] [D loss: 0.412433] [G loss: 2.019085]\n",
            "[Epoch 46/50] [Batch 174/600] [D loss: 0.429737] [G loss: 2.115274]\n",
            "[Epoch 46/50] [Batch 175/600] [D loss: 0.451038] [G loss: 1.849976]\n",
            "[Epoch 46/50] [Batch 176/600] [D loss: 0.458922] [G loss: 1.970766]\n",
            "[Epoch 46/50] [Batch 177/600] [D loss: 0.390729] [G loss: 1.856201]\n",
            "[Epoch 46/50] [Batch 178/600] [D loss: 0.456436] [G loss: 1.638939]\n",
            "[Epoch 46/50] [Batch 179/600] [D loss: 0.430514] [G loss: 1.474194]\n",
            "[Epoch 46/50] [Batch 180/600] [D loss: 0.449188] [G loss: 1.551505]\n",
            "[Epoch 46/50] [Batch 181/600] [D loss: 0.382829] [G loss: 1.756787]\n",
            "[Epoch 46/50] [Batch 182/600] [D loss: 0.368618] [G loss: 1.704119]\n",
            "[Epoch 46/50] [Batch 183/600] [D loss: 0.435743] [G loss: 1.849978]\n",
            "[Epoch 46/50] [Batch 184/600] [D loss: 0.404297] [G loss: 2.047733]\n",
            "[Epoch 46/50] [Batch 185/600] [D loss: 0.392402] [G loss: 1.603722]\n",
            "[Epoch 46/50] [Batch 186/600] [D loss: 0.417304] [G loss: 1.672199]\n",
            "[Epoch 46/50] [Batch 187/600] [D loss: 0.461372] [G loss: 1.924376]\n",
            "[Epoch 46/50] [Batch 188/600] [D loss: 0.380212] [G loss: 1.981087]\n",
            "[Epoch 46/50] [Batch 189/600] [D loss: 0.415227] [G loss: 1.942795]\n",
            "[Epoch 46/50] [Batch 190/600] [D loss: 0.390335] [G loss: 1.967712]\n",
            "[Epoch 46/50] [Batch 191/600] [D loss: 0.390287] [G loss: 1.788374]\n",
            "[Epoch 46/50] [Batch 192/600] [D loss: 0.489971] [G loss: 1.968743]\n",
            "[Epoch 46/50] [Batch 193/600] [D loss: 0.412807] [G loss: 1.790696]\n",
            "[Epoch 46/50] [Batch 194/600] [D loss: 0.407288] [G loss: 1.669814]\n",
            "[Epoch 46/50] [Batch 195/600] [D loss: 0.388189] [G loss: 1.721539]\n",
            "[Epoch 46/50] [Batch 196/600] [D loss: 0.400938] [G loss: 1.626883]\n",
            "[Epoch 46/50] [Batch 197/600] [D loss: 0.360521] [G loss: 1.805498]\n",
            "[Epoch 46/50] [Batch 198/600] [D loss: 0.383424] [G loss: 1.807499]\n",
            "[Epoch 46/50] [Batch 199/600] [D loss: 0.316791] [G loss: 1.900304]\n",
            "[Epoch 46/50] [Batch 200/600] [D loss: 0.340758] [G loss: 1.924614]\n",
            "[Epoch 46/50] [Batch 201/600] [D loss: 0.421281] [G loss: 1.795945]\n",
            "[Epoch 46/50] [Batch 202/600] [D loss: 0.517794] [G loss: 1.770555]\n",
            "[Epoch 46/50] [Batch 203/600] [D loss: 0.453540] [G loss: 1.730324]\n",
            "[Epoch 46/50] [Batch 204/600] [D loss: 0.363171] [G loss: 1.823605]\n",
            "[Epoch 46/50] [Batch 205/600] [D loss: 0.399173] [G loss: 1.763916]\n",
            "[Epoch 46/50] [Batch 206/600] [D loss: 0.431526] [G loss: 2.014974]\n",
            "[Epoch 46/50] [Batch 207/600] [D loss: 0.474155] [G loss: 1.520699]\n",
            "[Epoch 46/50] [Batch 208/600] [D loss: 0.399816] [G loss: 1.630701]\n",
            "[Epoch 46/50] [Batch 209/600] [D loss: 0.381042] [G loss: 1.627961]\n",
            "[Epoch 46/50] [Batch 210/600] [D loss: 0.388098] [G loss: 1.984780]\n",
            "[Epoch 46/50] [Batch 211/600] [D loss: 0.398673] [G loss: 1.846795]\n",
            "[Epoch 46/50] [Batch 212/600] [D loss: 0.405336] [G loss: 1.700362]\n",
            "[Epoch 46/50] [Batch 213/600] [D loss: 0.446923] [G loss: 1.987649]\n",
            "[Epoch 46/50] [Batch 214/600] [D loss: 0.375015] [G loss: 2.332078]\n",
            "[Epoch 46/50] [Batch 215/600] [D loss: 0.451998] [G loss: 2.042878]\n",
            "[Epoch 46/50] [Batch 216/600] [D loss: 0.434585] [G loss: 1.999118]\n",
            "[Epoch 46/50] [Batch 217/600] [D loss: 0.377916] [G loss: 1.969321]\n",
            "[Epoch 46/50] [Batch 218/600] [D loss: 0.429084] [G loss: 1.660239]\n",
            "[Epoch 46/50] [Batch 219/600] [D loss: 0.381117] [G loss: 1.613683]\n",
            "[Epoch 46/50] [Batch 220/600] [D loss: 0.334444] [G loss: 1.881890]\n",
            "[Epoch 46/50] [Batch 221/600] [D loss: 0.427203] [G loss: 1.869943]\n",
            "[Epoch 46/50] [Batch 222/600] [D loss: 0.448877] [G loss: 1.975038]\n",
            "[Epoch 46/50] [Batch 223/600] [D loss: 0.430843] [G loss: 1.862951]\n",
            "[Epoch 46/50] [Batch 224/600] [D loss: 0.482316] [G loss: 1.886060]\n",
            "[Epoch 46/50] [Batch 225/600] [D loss: 0.477202] [G loss: 1.490795]\n",
            "[Epoch 46/50] [Batch 226/600] [D loss: 0.339774] [G loss: 1.684703]\n",
            "[Epoch 46/50] [Batch 227/600] [D loss: 0.410342] [G loss: 1.768406]\n",
            "[Epoch 46/50] [Batch 228/600] [D loss: 0.338875] [G loss: 1.731335]\n",
            "[Epoch 46/50] [Batch 229/600] [D loss: 0.344006] [G loss: 1.891127]\n",
            "[Epoch 46/50] [Batch 230/600] [D loss: 0.363390] [G loss: 1.848021]\n",
            "[Epoch 46/50] [Batch 231/600] [D loss: 0.404646] [G loss: 1.954652]\n",
            "[Epoch 46/50] [Batch 232/600] [D loss: 0.385210] [G loss: 1.662293]\n",
            "[Epoch 46/50] [Batch 233/600] [D loss: 0.374334] [G loss: 1.798066]\n",
            "[Epoch 46/50] [Batch 234/600] [D loss: 0.383334] [G loss: 1.860715]\n",
            "[Epoch 46/50] [Batch 235/600] [D loss: 0.410465] [G loss: 1.659956]\n",
            "[Epoch 46/50] [Batch 236/600] [D loss: 0.486922] [G loss: 1.980004]\n",
            "[Epoch 46/50] [Batch 237/600] [D loss: 0.382884] [G loss: 2.214102]\n",
            "[Epoch 46/50] [Batch 238/600] [D loss: 0.409093] [G loss: 2.058944]\n",
            "[Epoch 46/50] [Batch 239/600] [D loss: 0.449109] [G loss: 1.821353]\n",
            "[Epoch 46/50] [Batch 240/600] [D loss: 0.570538] [G loss: 1.940175]\n",
            "[Epoch 46/50] [Batch 241/600] [D loss: 0.447938] [G loss: 1.685190]\n",
            "[Epoch 46/50] [Batch 242/600] [D loss: 0.383883] [G loss: 1.651129]\n",
            "[Epoch 46/50] [Batch 243/600] [D loss: 0.331946] [G loss: 1.668497]\n",
            "[Epoch 46/50] [Batch 244/600] [D loss: 0.439929] [G loss: 1.597695]\n",
            "[Epoch 46/50] [Batch 245/600] [D loss: 0.377004] [G loss: 1.632009]\n",
            "[Epoch 46/50] [Batch 246/600] [D loss: 0.356447] [G loss: 1.608186]\n",
            "[Epoch 46/50] [Batch 247/600] [D loss: 0.428578] [G loss: 1.638329]\n",
            "[Epoch 46/50] [Batch 248/600] [D loss: 0.362675] [G loss: 2.030262]\n",
            "[Epoch 46/50] [Batch 249/600] [D loss: 0.523873] [G loss: 1.714207]\n",
            "[Epoch 46/50] [Batch 250/600] [D loss: 0.489322] [G loss: 1.870534]\n",
            "[Epoch 46/50] [Batch 251/600] [D loss: 0.398553] [G loss: 1.812845]\n",
            "[Epoch 46/50] [Batch 252/600] [D loss: 0.465556] [G loss: 1.717211]\n",
            "[Epoch 46/50] [Batch 253/600] [D loss: 0.415416] [G loss: 1.770670]\n",
            "[Epoch 46/50] [Batch 254/600] [D loss: 0.377627] [G loss: 1.504703]\n",
            "[Epoch 46/50] [Batch 255/600] [D loss: 0.415864] [G loss: 1.764542]\n",
            "[Epoch 46/50] [Batch 256/600] [D loss: 0.428515] [G loss: 1.687698]\n",
            "[Epoch 46/50] [Batch 257/600] [D loss: 0.412226] [G loss: 1.840093]\n",
            "[Epoch 46/50] [Batch 258/600] [D loss: 0.428968] [G loss: 1.614030]\n",
            "[Epoch 46/50] [Batch 259/600] [D loss: 0.429590] [G loss: 1.806975]\n",
            "[Epoch 46/50] [Batch 260/600] [D loss: 0.429372] [G loss: 1.832380]\n",
            "[Epoch 46/50] [Batch 261/600] [D loss: 0.444115] [G loss: 1.565600]\n",
            "[Epoch 46/50] [Batch 262/600] [D loss: 0.431273] [G loss: 1.447788]\n",
            "[Epoch 46/50] [Batch 263/600] [D loss: 0.477309] [G loss: 1.607150]\n",
            "[Epoch 46/50] [Batch 264/600] [D loss: 0.497140] [G loss: 1.513487]\n",
            "[Epoch 46/50] [Batch 265/600] [D loss: 0.476551] [G loss: 1.734311]\n",
            "[Epoch 46/50] [Batch 266/600] [D loss: 0.423111] [G loss: 1.662951]\n",
            "[Epoch 46/50] [Batch 267/600] [D loss: 0.448918] [G loss: 1.801000]\n",
            "[Epoch 46/50] [Batch 268/600] [D loss: 0.520605] [G loss: 1.720401]\n",
            "[Epoch 46/50] [Batch 269/600] [D loss: 0.406280] [G loss: 1.481755]\n",
            "[Epoch 46/50] [Batch 270/600] [D loss: 0.423863] [G loss: 1.626806]\n",
            "[Epoch 46/50] [Batch 271/600] [D loss: 0.404081] [G loss: 1.519139]\n",
            "[Epoch 46/50] [Batch 272/600] [D loss: 0.426415] [G loss: 1.607414]\n",
            "[Epoch 46/50] [Batch 273/600] [D loss: 0.396876] [G loss: 1.810637]\n",
            "[Epoch 46/50] [Batch 274/600] [D loss: 0.380960] [G loss: 1.582489]\n",
            "[Epoch 46/50] [Batch 275/600] [D loss: 0.443802] [G loss: 1.682804]\n",
            "[Epoch 46/50] [Batch 276/600] [D loss: 0.481339] [G loss: 1.738480]\n",
            "[Epoch 46/50] [Batch 277/600] [D loss: 0.423906] [G loss: 1.641466]\n",
            "[Epoch 46/50] [Batch 278/600] [D loss: 0.389051] [G loss: 1.724247]\n",
            "[Epoch 46/50] [Batch 279/600] [D loss: 0.439064] [G loss: 1.825812]\n",
            "[Epoch 46/50] [Batch 280/600] [D loss: 0.434286] [G loss: 1.558214]\n",
            "[Epoch 46/50] [Batch 281/600] [D loss: 0.398752] [G loss: 1.405889]\n",
            "[Epoch 46/50] [Batch 282/600] [D loss: 0.447157] [G loss: 1.790677]\n",
            "[Epoch 46/50] [Batch 283/600] [D loss: 0.455437] [G loss: 1.632600]\n",
            "[Epoch 46/50] [Batch 284/600] [D loss: 0.421279] [G loss: 1.622694]\n",
            "[Epoch 46/50] [Batch 285/600] [D loss: 0.381826] [G loss: 1.610785]\n",
            "[Epoch 46/50] [Batch 286/600] [D loss: 0.468871] [G loss: 1.742382]\n",
            "[Epoch 46/50] [Batch 287/600] [D loss: 0.431466] [G loss: 1.650420]\n",
            "[Epoch 46/50] [Batch 288/600] [D loss: 0.343099] [G loss: 1.740760]\n",
            "[Epoch 46/50] [Batch 289/600] [D loss: 0.370821] [G loss: 1.788315]\n",
            "[Epoch 46/50] [Batch 290/600] [D loss: 0.457303] [G loss: 1.754443]\n",
            "[Epoch 46/50] [Batch 291/600] [D loss: 0.536141] [G loss: 1.827525]\n",
            "[Epoch 46/50] [Batch 292/600] [D loss: 0.408293] [G loss: 1.662251]\n",
            "[Epoch 46/50] [Batch 293/600] [D loss: 0.423093] [G loss: 1.514576]\n",
            "[Epoch 46/50] [Batch 294/600] [D loss: 0.452443] [G loss: 1.625127]\n",
            "[Epoch 46/50] [Batch 295/600] [D loss: 0.409296] [G loss: 1.635115]\n",
            "[Epoch 46/50] [Batch 296/600] [D loss: 0.439059] [G loss: 1.588416]\n",
            "[Epoch 46/50] [Batch 297/600] [D loss: 0.491065] [G loss: 1.611276]\n",
            "[Epoch 46/50] [Batch 298/600] [D loss: 0.530626] [G loss: 1.718030]\n",
            "[Epoch 46/50] [Batch 299/600] [D loss: 0.426339] [G loss: 1.550588]\n",
            "[Epoch 46/50] [Batch 300/600] [D loss: 0.404203] [G loss: 1.617221]\n",
            "[Epoch 46/50] [Batch 301/600] [D loss: 0.358575] [G loss: 1.600704]\n",
            "[Epoch 46/50] [Batch 302/600] [D loss: 0.409381] [G loss: 1.809179]\n",
            "[Epoch 46/50] [Batch 303/600] [D loss: 0.456104] [G loss: 1.607040]\n",
            "[Epoch 46/50] [Batch 304/600] [D loss: 0.401352] [G loss: 1.692425]\n",
            "[Epoch 46/50] [Batch 305/600] [D loss: 0.406450] [G loss: 1.637496]\n",
            "[Epoch 46/50] [Batch 306/600] [D loss: 0.444466] [G loss: 1.742970]\n",
            "[Epoch 46/50] [Batch 307/600] [D loss: 0.456784] [G loss: 1.631751]\n",
            "[Epoch 46/50] [Batch 308/600] [D loss: 0.465931] [G loss: 1.815050]\n",
            "[Epoch 46/50] [Batch 309/600] [D loss: 0.464461] [G loss: 1.581743]\n",
            "[Epoch 46/50] [Batch 310/600] [D loss: 0.411043] [G loss: 1.702217]\n",
            "[Epoch 46/50] [Batch 311/600] [D loss: 0.473137] [G loss: 1.596140]\n",
            "[Epoch 46/50] [Batch 312/600] [D loss: 0.398851] [G loss: 1.706913]\n",
            "[Epoch 46/50] [Batch 313/600] [D loss: 0.451405] [G loss: 1.853085]\n",
            "[Epoch 46/50] [Batch 314/600] [D loss: 0.443088] [G loss: 1.798525]\n",
            "[Epoch 46/50] [Batch 315/600] [D loss: 0.410928] [G loss: 1.718627]\n",
            "[Epoch 46/50] [Batch 316/600] [D loss: 0.498778] [G loss: 1.473776]\n",
            "[Epoch 46/50] [Batch 317/600] [D loss: 0.468016] [G loss: 1.608836]\n",
            "[Epoch 46/50] [Batch 318/600] [D loss: 0.396167] [G loss: 1.632762]\n",
            "[Epoch 46/50] [Batch 319/600] [D loss: 0.415174] [G loss: 1.501351]\n",
            "[Epoch 46/50] [Batch 320/600] [D loss: 0.454865] [G loss: 1.765620]\n",
            "[Epoch 46/50] [Batch 321/600] [D loss: 0.395412] [G loss: 1.600344]\n",
            "[Epoch 46/50] [Batch 322/600] [D loss: 0.376592] [G loss: 1.721667]\n",
            "[Epoch 46/50] [Batch 323/600] [D loss: 0.444645] [G loss: 1.675282]\n",
            "[Epoch 46/50] [Batch 324/600] [D loss: 0.377930] [G loss: 1.651637]\n",
            "[Epoch 46/50] [Batch 325/600] [D loss: 0.455252] [G loss: 1.742818]\n",
            "[Epoch 46/50] [Batch 326/600] [D loss: 0.451275] [G loss: 1.675347]\n",
            "[Epoch 46/50] [Batch 327/600] [D loss: 0.434798] [G loss: 1.780926]\n",
            "[Epoch 46/50] [Batch 328/600] [D loss: 0.426202] [G loss: 1.796211]\n",
            "[Epoch 46/50] [Batch 329/600] [D loss: 0.427048] [G loss: 1.655023]\n",
            "[Epoch 46/50] [Batch 330/600] [D loss: 0.342030] [G loss: 1.803501]\n",
            "[Epoch 46/50] [Batch 331/600] [D loss: 0.407891] [G loss: 1.800036]\n",
            "[Epoch 46/50] [Batch 332/600] [D loss: 0.358613] [G loss: 1.957717]\n",
            "[Epoch 46/50] [Batch 333/600] [D loss: 0.389503] [G loss: 1.896454]\n",
            "[Epoch 46/50] [Batch 334/600] [D loss: 0.395453] [G loss: 1.709044]\n",
            "[Epoch 46/50] [Batch 335/600] [D loss: 0.414518] [G loss: 1.705847]\n",
            "[Epoch 46/50] [Batch 336/600] [D loss: 0.438862] [G loss: 1.997434]\n",
            "[Epoch 46/50] [Batch 337/600] [D loss: 0.436052] [G loss: 1.785390]\n",
            "[Epoch 46/50] [Batch 338/600] [D loss: 0.423494] [G loss: 1.542609]\n",
            "[Epoch 46/50] [Batch 339/600] [D loss: 0.412874] [G loss: 1.783183]\n",
            "[Epoch 46/50] [Batch 340/600] [D loss: 0.436013] [G loss: 1.783620]\n",
            "[Epoch 46/50] [Batch 341/600] [D loss: 0.417770] [G loss: 1.808945]\n",
            "[Epoch 46/50] [Batch 342/600] [D loss: 0.376750] [G loss: 2.025820]\n",
            "[Epoch 46/50] [Batch 343/600] [D loss: 0.451715] [G loss: 1.951660]\n",
            "[Epoch 46/50] [Batch 344/600] [D loss: 0.381566] [G loss: 1.741846]\n",
            "[Epoch 46/50] [Batch 345/600] [D loss: 0.411688] [G loss: 1.634188]\n",
            "[Epoch 46/50] [Batch 346/600] [D loss: 0.507053] [G loss: 1.448013]\n",
            "[Epoch 46/50] [Batch 347/600] [D loss: 0.392207] [G loss: 1.788900]\n",
            "[Epoch 46/50] [Batch 348/600] [D loss: 0.392729] [G loss: 1.652146]\n",
            "[Epoch 46/50] [Batch 349/600] [D loss: 0.446974] [G loss: 1.637324]\n",
            "[Epoch 46/50] [Batch 350/600] [D loss: 0.386027] [G loss: 1.588503]\n",
            "[Epoch 46/50] [Batch 351/600] [D loss: 0.428336] [G loss: 1.724183]\n",
            "[Epoch 46/50] [Batch 352/600] [D loss: 0.354185] [G loss: 1.577224]\n",
            "[Epoch 46/50] [Batch 353/600] [D loss: 0.413429] [G loss: 1.892781]\n",
            "[Epoch 46/50] [Batch 354/600] [D loss: 0.376172] [G loss: 1.870988]\n",
            "[Epoch 46/50] [Batch 355/600] [D loss: 0.436861] [G loss: 2.025480]\n",
            "[Epoch 46/50] [Batch 356/600] [D loss: 0.418909] [G loss: 1.861477]\n",
            "[Epoch 46/50] [Batch 357/600] [D loss: 0.411112] [G loss: 1.757259]\n",
            "[Epoch 46/50] [Batch 358/600] [D loss: 0.478144] [G loss: 1.598109]\n",
            "[Epoch 46/50] [Batch 359/600] [D loss: 0.426748] [G loss: 1.650137]\n",
            "[Epoch 46/50] [Batch 360/600] [D loss: 0.498525] [G loss: 1.397630]\n",
            "[Epoch 46/50] [Batch 361/600] [D loss: 0.385933] [G loss: 1.511706]\n",
            "[Epoch 46/50] [Batch 362/600] [D loss: 0.465111] [G loss: 1.596316]\n",
            "[Epoch 46/50] [Batch 363/600] [D loss: 0.412010] [G loss: 1.550652]\n",
            "[Epoch 46/50] [Batch 364/600] [D loss: 0.404919] [G loss: 1.913007]\n",
            "[Epoch 46/50] [Batch 365/600] [D loss: 0.419182] [G loss: 1.679875]\n",
            "[Epoch 46/50] [Batch 366/600] [D loss: 0.400370] [G loss: 1.978017]\n",
            "[Epoch 46/50] [Batch 367/600] [D loss: 0.395611] [G loss: 1.659215]\n",
            "[Epoch 46/50] [Batch 368/600] [D loss: 0.411686] [G loss: 1.897700]\n",
            "[Epoch 46/50] [Batch 369/600] [D loss: 0.443934] [G loss: 1.856303]\n",
            "[Epoch 46/50] [Batch 370/600] [D loss: 0.415311] [G loss: 1.806386]\n",
            "[Epoch 46/50] [Batch 371/600] [D loss: 0.406804] [G loss: 1.760622]\n",
            "[Epoch 46/50] [Batch 372/600] [D loss: 0.346945] [G loss: 1.717907]\n",
            "[Epoch 46/50] [Batch 373/600] [D loss: 0.451667] [G loss: 1.723779]\n",
            "[Epoch 46/50] [Batch 374/600] [D loss: 0.406251] [G loss: 1.742044]\n",
            "[Epoch 46/50] [Batch 375/600] [D loss: 0.462822] [G loss: 1.724148]\n",
            "[Epoch 46/50] [Batch 376/600] [D loss: 0.410971] [G loss: 1.695935]\n",
            "[Epoch 46/50] [Batch 377/600] [D loss: 0.391418] [G loss: 1.642898]\n",
            "[Epoch 46/50] [Batch 378/600] [D loss: 0.368299] [G loss: 1.812381]\n",
            "[Epoch 46/50] [Batch 379/600] [D loss: 0.425787] [G loss: 1.852016]\n",
            "[Epoch 46/50] [Batch 380/600] [D loss: 0.511326] [G loss: 1.844488]\n",
            "[Epoch 46/50] [Batch 381/600] [D loss: 0.373910] [G loss: 1.763715]\n",
            "[Epoch 46/50] [Batch 382/600] [D loss: 0.400649] [G loss: 1.836566]\n",
            "[Epoch 46/50] [Batch 383/600] [D loss: 0.418739] [G loss: 1.918026]\n",
            "[Epoch 46/50] [Batch 384/600] [D loss: 0.382039] [G loss: 1.725181]\n",
            "[Epoch 46/50] [Batch 385/600] [D loss: 0.397455] [G loss: 1.800909]\n",
            "[Epoch 46/50] [Batch 386/600] [D loss: 0.387334] [G loss: 1.927198]\n",
            "[Epoch 46/50] [Batch 387/600] [D loss: 0.408810] [G loss: 1.868525]\n",
            "[Epoch 46/50] [Batch 388/600] [D loss: 0.436254] [G loss: 1.917881]\n",
            "[Epoch 46/50] [Batch 389/600] [D loss: 0.486997] [G loss: 1.970602]\n",
            "[Epoch 46/50] [Batch 390/600] [D loss: 0.350357] [G loss: 1.949124]\n",
            "[Epoch 46/50] [Batch 391/600] [D loss: 0.399553] [G loss: 1.931221]\n",
            "[Epoch 46/50] [Batch 392/600] [D loss: 0.352892] [G loss: 1.781308]\n",
            "[Epoch 46/50] [Batch 393/600] [D loss: 0.346385] [G loss: 1.669525]\n",
            "[Epoch 46/50] [Batch 394/600] [D loss: 0.351668] [G loss: 1.780697]\n",
            "[Epoch 46/50] [Batch 395/600] [D loss: 0.354907] [G loss: 1.640296]\n",
            "[Epoch 46/50] [Batch 396/600] [D loss: 0.385430] [G loss: 1.760254]\n",
            "[Epoch 46/50] [Batch 397/600] [D loss: 0.415890] [G loss: 1.965606]\n",
            "[Epoch 46/50] [Batch 398/600] [D loss: 0.481725] [G loss: 1.860999]\n",
            "[Epoch 46/50] [Batch 399/600] [D loss: 0.479801] [G loss: 1.995610]\n",
            "[Epoch 46/50] [Batch 400/600] [D loss: 0.450128] [G loss: 1.743198]\n",
            "[Epoch 46/50] [Batch 401/600] [D loss: 0.517270] [G loss: 1.756867]\n",
            "[Epoch 46/50] [Batch 402/600] [D loss: 0.455395] [G loss: 1.863368]\n",
            "[Epoch 46/50] [Batch 403/600] [D loss: 0.455416] [G loss: 1.624977]\n",
            "[Epoch 46/50] [Batch 404/600] [D loss: 0.382938] [G loss: 1.619496]\n",
            "[Epoch 46/50] [Batch 405/600] [D loss: 0.367571] [G loss: 1.647918]\n",
            "[Epoch 46/50] [Batch 406/600] [D loss: 0.395887] [G loss: 1.472612]\n",
            "[Epoch 46/50] [Batch 407/600] [D loss: 0.337710] [G loss: 2.081692]\n",
            "[Epoch 46/50] [Batch 408/600] [D loss: 0.341606] [G loss: 1.954765]\n",
            "[Epoch 46/50] [Batch 409/600] [D loss: 0.371464] [G loss: 1.824154]\n",
            "[Epoch 46/50] [Batch 410/600] [D loss: 0.374775] [G loss: 2.030639]\n",
            "[Epoch 46/50] [Batch 411/600] [D loss: 0.482823] [G loss: 1.563280]\n",
            "[Epoch 46/50] [Batch 412/600] [D loss: 0.426048] [G loss: 1.592033]\n",
            "[Epoch 46/50] [Batch 413/600] [D loss: 0.405603] [G loss: 1.895550]\n",
            "[Epoch 46/50] [Batch 414/600] [D loss: 0.384281] [G loss: 2.063561]\n",
            "[Epoch 46/50] [Batch 415/600] [D loss: 0.397133] [G loss: 2.018280]\n",
            "[Epoch 46/50] [Batch 416/600] [D loss: 0.439141] [G loss: 1.698705]\n",
            "[Epoch 46/50] [Batch 417/600] [D loss: 0.449072] [G loss: 1.965732]\n",
            "[Epoch 46/50] [Batch 418/600] [D loss: 0.371968] [G loss: 1.632211]\n",
            "[Epoch 46/50] [Batch 419/600] [D loss: 0.465242] [G loss: 1.834429]\n",
            "[Epoch 46/50] [Batch 420/600] [D loss: 0.346022] [G loss: 1.838724]\n",
            "[Epoch 46/50] [Batch 421/600] [D loss: 0.372101] [G loss: 1.861530]\n",
            "[Epoch 46/50] [Batch 422/600] [D loss: 0.358678] [G loss: 1.773399]\n",
            "[Epoch 46/50] [Batch 423/600] [D loss: 0.354895] [G loss: 2.029775]\n",
            "[Epoch 46/50] [Batch 424/600] [D loss: 0.423887] [G loss: 1.961097]\n",
            "[Epoch 46/50] [Batch 425/600] [D loss: 0.471393] [G loss: 1.662798]\n",
            "[Epoch 46/50] [Batch 426/600] [D loss: 0.406267] [G loss: 1.891525]\n",
            "[Epoch 46/50] [Batch 427/600] [D loss: 0.421309] [G loss: 1.659754]\n",
            "[Epoch 46/50] [Batch 428/600] [D loss: 0.417580] [G loss: 1.936130]\n",
            "[Epoch 46/50] [Batch 429/600] [D loss: 0.463494] [G loss: 1.657864]\n",
            "[Epoch 46/50] [Batch 430/600] [D loss: 0.502274] [G loss: 1.675128]\n",
            "[Epoch 46/50] [Batch 431/600] [D loss: 0.430120] [G loss: 1.577264]\n",
            "[Epoch 46/50] [Batch 432/600] [D loss: 0.416080] [G loss: 1.416072]\n",
            "[Epoch 46/50] [Batch 433/600] [D loss: 0.388735] [G loss: 1.399382]\n",
            "[Epoch 46/50] [Batch 434/600] [D loss: 0.471655] [G loss: 1.735542]\n",
            "[Epoch 46/50] [Batch 435/600] [D loss: 0.387729] [G loss: 1.717233]\n",
            "[Epoch 46/50] [Batch 436/600] [D loss: 0.351891] [G loss: 1.697832]\n",
            "[Epoch 46/50] [Batch 437/600] [D loss: 0.437455] [G loss: 1.751252]\n",
            "[Epoch 46/50] [Batch 438/600] [D loss: 0.346238] [G loss: 1.619946]\n",
            "[Epoch 46/50] [Batch 439/600] [D loss: 0.473464] [G loss: 1.454595]\n",
            "[Epoch 46/50] [Batch 440/600] [D loss: 0.450551] [G loss: 1.573068]\n",
            "[Epoch 46/50] [Batch 441/600] [D loss: 0.389793] [G loss: 1.736334]\n",
            "[Epoch 46/50] [Batch 442/600] [D loss: 0.460714] [G loss: 1.967193]\n",
            "[Epoch 46/50] [Batch 443/600] [D loss: 0.352650] [G loss: 2.002828]\n",
            "[Epoch 46/50] [Batch 444/600] [D loss: 0.428926] [G loss: 1.776910]\n",
            "[Epoch 46/50] [Batch 445/600] [D loss: 0.436169] [G loss: 1.808812]\n",
            "[Epoch 46/50] [Batch 446/600] [D loss: 0.400848] [G loss: 1.558429]\n",
            "[Epoch 46/50] [Batch 447/600] [D loss: 0.429038] [G loss: 1.819002]\n",
            "[Epoch 46/50] [Batch 448/600] [D loss: 0.429271] [G loss: 1.813955]\n",
            "[Epoch 46/50] [Batch 449/600] [D loss: 0.434494] [G loss: 1.593764]\n",
            "[Epoch 46/50] [Batch 450/600] [D loss: 0.400369] [G loss: 1.653545]\n",
            "[Epoch 46/50] [Batch 451/600] [D loss: 0.391501] [G loss: 1.387864]\n",
            "[Epoch 46/50] [Batch 452/600] [D loss: 0.341828] [G loss: 1.724549]\n",
            "[Epoch 46/50] [Batch 453/600] [D loss: 0.385350] [G loss: 1.642213]\n",
            "[Epoch 46/50] [Batch 454/600] [D loss: 0.438483] [G loss: 2.049114]\n",
            "[Epoch 46/50] [Batch 455/600] [D loss: 0.479529] [G loss: 1.920828]\n",
            "[Epoch 46/50] [Batch 456/600] [D loss: 0.376259] [G loss: 1.616279]\n",
            "[Epoch 46/50] [Batch 457/600] [D loss: 0.442535] [G loss: 1.894318]\n",
            "[Epoch 46/50] [Batch 458/600] [D loss: 0.429414] [G loss: 1.762672]\n",
            "[Epoch 46/50] [Batch 459/600] [D loss: 0.438640] [G loss: 1.667497]\n",
            "[Epoch 46/50] [Batch 460/600] [D loss: 0.418886] [G loss: 1.685388]\n",
            "[Epoch 46/50] [Batch 461/600] [D loss: 0.429605] [G loss: 1.551604]\n",
            "[Epoch 46/50] [Batch 462/600] [D loss: 0.454281] [G loss: 1.521585]\n",
            "[Epoch 46/50] [Batch 463/600] [D loss: 0.365143] [G loss: 1.782476]\n",
            "[Epoch 46/50] [Batch 464/600] [D loss: 0.375304] [G loss: 1.899346]\n",
            "[Epoch 46/50] [Batch 465/600] [D loss: 0.394306] [G loss: 1.774961]\n",
            "[Epoch 46/50] [Batch 466/600] [D loss: 0.481386] [G loss: 1.629791]\n",
            "[Epoch 46/50] [Batch 467/600] [D loss: 0.412064] [G loss: 1.875352]\n",
            "[Epoch 46/50] [Batch 468/600] [D loss: 0.371992] [G loss: 1.671814]\n",
            "[Epoch 46/50] [Batch 469/600] [D loss: 0.416501] [G loss: 1.684947]\n",
            "[Epoch 46/50] [Batch 470/600] [D loss: 0.392172] [G loss: 1.532869]\n",
            "[Epoch 46/50] [Batch 471/600] [D loss: 0.443981] [G loss: 1.740527]\n",
            "[Epoch 46/50] [Batch 472/600] [D loss: 0.467255] [G loss: 1.668320]\n",
            "[Epoch 46/50] [Batch 473/600] [D loss: 0.439613] [G loss: 1.653718]\n",
            "[Epoch 46/50] [Batch 474/600] [D loss: 0.408802] [G loss: 1.643695]\n",
            "[Epoch 46/50] [Batch 475/600] [D loss: 0.413966] [G loss: 1.632568]\n",
            "[Epoch 46/50] [Batch 476/600] [D loss: 0.372405] [G loss: 1.540872]\n",
            "[Epoch 46/50] [Batch 477/600] [D loss: 0.303474] [G loss: 1.707866]\n",
            "[Epoch 46/50] [Batch 478/600] [D loss: 0.411922] [G loss: 1.955930]\n",
            "[Epoch 46/50] [Batch 479/600] [D loss: 0.365108] [G loss: 1.945798]\n",
            "[Epoch 46/50] [Batch 480/600] [D loss: 0.392611] [G loss: 1.909328]\n",
            "[Epoch 46/50] [Batch 481/600] [D loss: 0.376677] [G loss: 1.910462]\n",
            "[Epoch 46/50] [Batch 482/600] [D loss: 0.366153] [G loss: 1.809334]\n",
            "[Epoch 46/50] [Batch 483/600] [D loss: 0.367707] [G loss: 1.765384]\n",
            "[Epoch 46/50] [Batch 484/600] [D loss: 0.372187] [G loss: 2.096481]\n",
            "[Epoch 46/50] [Batch 485/600] [D loss: 0.412058] [G loss: 1.857031]\n",
            "[Epoch 46/50] [Batch 486/600] [D loss: 0.429847] [G loss: 1.888771]\n",
            "[Epoch 46/50] [Batch 487/600] [D loss: 0.510321] [G loss: 1.910245]\n",
            "[Epoch 46/50] [Batch 488/600] [D loss: 0.406784] [G loss: 1.626819]\n",
            "[Epoch 46/50] [Batch 489/600] [D loss: 0.495288] [G loss: 1.781213]\n",
            "[Epoch 46/50] [Batch 490/600] [D loss: 0.512136] [G loss: 1.684614]\n",
            "[Epoch 46/50] [Batch 491/600] [D loss: 0.388970] [G loss: 1.428209]\n",
            "[Epoch 46/50] [Batch 492/600] [D loss: 0.405859] [G loss: 1.717625]\n",
            "[Epoch 46/50] [Batch 493/600] [D loss: 0.440614] [G loss: 1.322640]\n",
            "[Epoch 46/50] [Batch 494/600] [D loss: 0.414559] [G loss: 1.675437]\n",
            "[Epoch 46/50] [Batch 495/600] [D loss: 0.465858] [G loss: 1.694569]\n",
            "[Epoch 46/50] [Batch 496/600] [D loss: 0.421038] [G loss: 2.003499]\n",
            "[Epoch 46/50] [Batch 497/600] [D loss: 0.355152] [G loss: 1.667189]\n",
            "[Epoch 46/50] [Batch 498/600] [D loss: 0.428804] [G loss: 1.561399]\n",
            "[Epoch 46/50] [Batch 499/600] [D loss: 0.412988] [G loss: 1.660172]\n",
            "[Epoch 46/50] [Batch 500/600] [D loss: 0.480226] [G loss: 1.508220]\n",
            "[Epoch 46/50] [Batch 501/600] [D loss: 0.372239] [G loss: 2.026859]\n",
            "[Epoch 46/50] [Batch 502/600] [D loss: 0.414303] [G loss: 1.898690]\n",
            "[Epoch 46/50] [Batch 503/600] [D loss: 0.465963] [G loss: 1.859530]\n",
            "[Epoch 46/50] [Batch 504/600] [D loss: 0.430182] [G loss: 1.709967]\n",
            "[Epoch 46/50] [Batch 505/600] [D loss: 0.415786] [G loss: 1.501769]\n",
            "[Epoch 46/50] [Batch 506/600] [D loss: 0.440009] [G loss: 1.404899]\n",
            "[Epoch 46/50] [Batch 507/600] [D loss: 0.470925] [G loss: 1.638535]\n",
            "[Epoch 46/50] [Batch 508/600] [D loss: 0.499710] [G loss: 1.564027]\n",
            "[Epoch 46/50] [Batch 509/600] [D loss: 0.409152] [G loss: 1.477631]\n",
            "[Epoch 46/50] [Batch 510/600] [D loss: 0.433472] [G loss: 1.565793]\n",
            "[Epoch 46/50] [Batch 511/600] [D loss: 0.436654] [G loss: 1.744092]\n",
            "[Epoch 46/50] [Batch 512/600] [D loss: 0.421221] [G loss: 1.756884]\n",
            "[Epoch 46/50] [Batch 513/600] [D loss: 0.368484] [G loss: 1.789462]\n",
            "[Epoch 46/50] [Batch 514/600] [D loss: 0.397364] [G loss: 1.605062]\n",
            "[Epoch 46/50] [Batch 515/600] [D loss: 0.367477] [G loss: 1.565366]\n",
            "[Epoch 46/50] [Batch 516/600] [D loss: 0.410321] [G loss: 1.631848]\n",
            "[Epoch 46/50] [Batch 517/600] [D loss: 0.463611] [G loss: 1.879163]\n",
            "[Epoch 46/50] [Batch 518/600] [D loss: 0.399526] [G loss: 1.914421]\n",
            "[Epoch 46/50] [Batch 519/600] [D loss: 0.440510] [G loss: 1.611415]\n",
            "[Epoch 46/50] [Batch 520/600] [D loss: 0.425083] [G loss: 1.817732]\n",
            "[Epoch 46/50] [Batch 521/600] [D loss: 0.462642] [G loss: 1.713439]\n",
            "[Epoch 46/50] [Batch 522/600] [D loss: 0.496863] [G loss: 1.714940]\n",
            "[Epoch 46/50] [Batch 523/600] [D loss: 0.481961] [G loss: 1.670833]\n",
            "[Epoch 46/50] [Batch 524/600] [D loss: 0.519245] [G loss: 1.593051]\n",
            "[Epoch 46/50] [Batch 525/600] [D loss: 0.386903] [G loss: 1.602527]\n",
            "[Epoch 46/50] [Batch 526/600] [D loss: 0.428707] [G loss: 1.501968]\n",
            "[Epoch 46/50] [Batch 527/600] [D loss: 0.393706] [G loss: 1.951061]\n",
            "[Epoch 46/50] [Batch 528/600] [D loss: 0.416011] [G loss: 1.826125]\n",
            "[Epoch 46/50] [Batch 529/600] [D loss: 0.449391] [G loss: 1.711701]\n",
            "[Epoch 46/50] [Batch 530/600] [D loss: 0.466904] [G loss: 1.421873]\n",
            "[Epoch 46/50] [Batch 531/600] [D loss: 0.446630] [G loss: 1.508152]\n",
            "[Epoch 46/50] [Batch 532/600] [D loss: 0.396563] [G loss: 1.629133]\n",
            "[Epoch 46/50] [Batch 533/600] [D loss: 0.381961] [G loss: 1.584290]\n",
            "[Epoch 46/50] [Batch 534/600] [D loss: 0.418983] [G loss: 1.658736]\n",
            "[Epoch 46/50] [Batch 535/600] [D loss: 0.433287] [G loss: 1.817871]\n",
            "[Epoch 46/50] [Batch 536/600] [D loss: 0.427048] [G loss: 1.690141]\n",
            "[Epoch 46/50] [Batch 537/600] [D loss: 0.519932] [G loss: 1.805514]\n",
            "[Epoch 46/50] [Batch 538/600] [D loss: 0.456259] [G loss: 1.771147]\n",
            "[Epoch 46/50] [Batch 539/600] [D loss: 0.482186] [G loss: 1.721844]\n",
            "[Epoch 46/50] [Batch 540/600] [D loss: 0.440681] [G loss: 1.592219]\n",
            "[Epoch 46/50] [Batch 541/600] [D loss: 0.413004] [G loss: 1.701887]\n",
            "[Epoch 46/50] [Batch 542/600] [D loss: 0.462594] [G loss: 1.482519]\n",
            "[Epoch 46/50] [Batch 543/600] [D loss: 0.480678] [G loss: 1.783240]\n",
            "[Epoch 46/50] [Batch 544/600] [D loss: 0.375755] [G loss: 1.630607]\n",
            "[Epoch 46/50] [Batch 545/600] [D loss: 0.465092] [G loss: 1.573575]\n",
            "[Epoch 46/50] [Batch 546/600] [D loss: 0.432268] [G loss: 1.597341]\n",
            "[Epoch 46/50] [Batch 547/600] [D loss: 0.466296] [G loss: 1.538355]\n",
            "[Epoch 46/50] [Batch 548/600] [D loss: 0.460015] [G loss: 1.698487]\n",
            "[Epoch 46/50] [Batch 549/600] [D loss: 0.486884] [G loss: 1.619573]\n",
            "[Epoch 46/50] [Batch 550/600] [D loss: 0.434239] [G loss: 1.451879]\n",
            "[Epoch 46/50] [Batch 551/600] [D loss: 0.356399] [G loss: 1.612846]\n",
            "[Epoch 46/50] [Batch 552/600] [D loss: 0.442819] [G loss: 1.741928]\n",
            "[Epoch 46/50] [Batch 553/600] [D loss: 0.421323] [G loss: 1.781723]\n",
            "[Epoch 46/50] [Batch 554/600] [D loss: 0.472881] [G loss: 1.422059]\n",
            "[Epoch 46/50] [Batch 555/600] [D loss: 0.455819] [G loss: 1.496948]\n",
            "[Epoch 46/50] [Batch 556/600] [D loss: 0.369644] [G loss: 1.579855]\n",
            "[Epoch 46/50] [Batch 557/600] [D loss: 0.399836] [G loss: 1.768356]\n",
            "[Epoch 46/50] [Batch 558/600] [D loss: 0.479513] [G loss: 1.813425]\n",
            "[Epoch 46/50] [Batch 559/600] [D loss: 0.389566] [G loss: 1.435052]\n",
            "[Epoch 46/50] [Batch 560/600] [D loss: 0.417516] [G loss: 1.686944]\n",
            "[Epoch 46/50] [Batch 561/600] [D loss: 0.452454] [G loss: 1.540266]\n",
            "[Epoch 46/50] [Batch 562/600] [D loss: 0.463065] [G loss: 1.686160]\n",
            "[Epoch 46/50] [Batch 563/600] [D loss: 0.501241] [G loss: 1.691178]\n",
            "[Epoch 46/50] [Batch 564/600] [D loss: 0.495193] [G loss: 1.741431]\n",
            "[Epoch 46/50] [Batch 565/600] [D loss: 0.402721] [G loss: 1.507679]\n",
            "[Epoch 46/50] [Batch 566/600] [D loss: 0.392091] [G loss: 1.629113]\n",
            "[Epoch 46/50] [Batch 567/600] [D loss: 0.386413] [G loss: 1.476457]\n",
            "[Epoch 46/50] [Batch 568/600] [D loss: 0.403419] [G loss: 1.597879]\n",
            "[Epoch 46/50] [Batch 569/600] [D loss: 0.362463] [G loss: 1.598110]\n",
            "[Epoch 46/50] [Batch 570/600] [D loss: 0.503906] [G loss: 1.837116]\n",
            "[Epoch 46/50] [Batch 571/600] [D loss: 0.420705] [G loss: 1.691063]\n",
            "[Epoch 46/50] [Batch 572/600] [D loss: 0.412194] [G loss: 1.863171]\n",
            "[Epoch 46/50] [Batch 573/600] [D loss: 0.421852] [G loss: 2.125339]\n",
            "[Epoch 46/50] [Batch 574/600] [D loss: 0.399477] [G loss: 1.874910]\n",
            "[Epoch 46/50] [Batch 575/600] [D loss: 0.360590] [G loss: 1.791413]\n",
            "[Epoch 46/50] [Batch 576/600] [D loss: 0.411735] [G loss: 1.806186]\n",
            "[Epoch 46/50] [Batch 577/600] [D loss: 0.401526] [G loss: 1.715290]\n",
            "[Epoch 46/50] [Batch 578/600] [D loss: 0.455622] [G loss: 1.680488]\n",
            "[Epoch 46/50] [Batch 579/600] [D loss: 0.359519] [G loss: 1.804638]\n",
            "[Epoch 46/50] [Batch 580/600] [D loss: 0.499864] [G loss: 1.574566]\n",
            "[Epoch 46/50] [Batch 581/600] [D loss: 0.314360] [G loss: 1.824026]\n",
            "[Epoch 46/50] [Batch 582/600] [D loss: 0.379845] [G loss: 1.832091]\n",
            "[Epoch 46/50] [Batch 583/600] [D loss: 0.364686] [G loss: 2.150963]\n",
            "[Epoch 46/50] [Batch 584/600] [D loss: 0.356991] [G loss: 2.043340]\n",
            "[Epoch 46/50] [Batch 585/600] [D loss: 0.454272] [G loss: 2.012044]\n",
            "[Epoch 46/50] [Batch 586/600] [D loss: 0.493939] [G loss: 1.774353]\n",
            "[Epoch 46/50] [Batch 587/600] [D loss: 0.385528] [G loss: 1.607954]\n",
            "[Epoch 46/50] [Batch 588/600] [D loss: 0.430768] [G loss: 1.672782]\n",
            "[Epoch 46/50] [Batch 589/600] [D loss: 0.407241] [G loss: 1.803459]\n",
            "[Epoch 46/50] [Batch 590/600] [D loss: 0.374616] [G loss: 1.882021]\n",
            "[Epoch 46/50] [Batch 591/600] [D loss: 0.345305] [G loss: 1.856854]\n",
            "[Epoch 46/50] [Batch 592/600] [D loss: 0.363160] [G loss: 1.968055]\n",
            "[Epoch 46/50] [Batch 593/600] [D loss: 0.466759] [G loss: 2.058141]\n",
            "[Epoch 46/50] [Batch 594/600] [D loss: 0.438169] [G loss: 1.532368]\n",
            "[Epoch 46/50] [Batch 595/600] [D loss: 0.456304] [G loss: 1.287704]\n",
            "[Epoch 46/50] [Batch 596/600] [D loss: 0.371735] [G loss: 1.567825]\n",
            "[Epoch 46/50] [Batch 597/600] [D loss: 0.394875] [G loss: 1.817476]\n",
            "[Epoch 46/50] [Batch 598/600] [D loss: 0.407927] [G loss: 1.868467]\n",
            "[Epoch 46/50] [Batch 599/600] [D loss: 0.410605] [G loss: 1.582022]\n",
            "[Epoch 47/50] [Batch 0/600] [D loss: 0.430519] [G loss: 1.900862]\n",
            "[Epoch 47/50] [Batch 1/600] [D loss: 0.388227] [G loss: 2.061988]\n",
            "[Epoch 47/50] [Batch 2/600] [D loss: 0.350063] [G loss: 2.040101]\n",
            "[Epoch 47/50] [Batch 3/600] [D loss: 0.477157] [G loss: 1.847779]\n",
            "[Epoch 47/50] [Batch 4/600] [D loss: 0.366456] [G loss: 1.807613]\n",
            "[Epoch 47/50] [Batch 5/600] [D loss: 0.458869] [G loss: 1.593764]\n",
            "[Epoch 47/50] [Batch 6/600] [D loss: 0.392294] [G loss: 1.773874]\n",
            "[Epoch 47/50] [Batch 7/600] [D loss: 0.386602] [G loss: 1.918727]\n",
            "[Epoch 47/50] [Batch 8/600] [D loss: 0.417783] [G loss: 1.736852]\n",
            "[Epoch 47/50] [Batch 9/600] [D loss: 0.391406] [G loss: 1.540242]\n",
            "[Epoch 47/50] [Batch 10/600] [D loss: 0.515577] [G loss: 1.848334]\n",
            "[Epoch 47/50] [Batch 11/600] [D loss: 0.459122] [G loss: 1.896778]\n",
            "[Epoch 47/50] [Batch 12/600] [D loss: 0.445466] [G loss: 1.834106]\n",
            "[Epoch 47/50] [Batch 13/600] [D loss: 0.406899] [G loss: 1.708368]\n",
            "[Epoch 47/50] [Batch 14/600] [D loss: 0.408310] [G loss: 1.409725]\n",
            "[Epoch 47/50] [Batch 15/600] [D loss: 0.375504] [G loss: 1.473485]\n",
            "[Epoch 47/50] [Batch 16/600] [D loss: 0.410728] [G loss: 1.540646]\n",
            "[Epoch 47/50] [Batch 17/600] [D loss: 0.372171] [G loss: 1.749440]\n",
            "[Epoch 47/50] [Batch 18/600] [D loss: 0.374013] [G loss: 1.856402]\n",
            "[Epoch 47/50] [Batch 19/600] [D loss: 0.497496] [G loss: 1.749436]\n",
            "[Epoch 47/50] [Batch 20/600] [D loss: 0.429823] [G loss: 1.724603]\n",
            "[Epoch 47/50] [Batch 21/600] [D loss: 0.407030] [G loss: 1.628516]\n",
            "[Epoch 47/50] [Batch 22/600] [D loss: 0.379023] [G loss: 1.759791]\n",
            "[Epoch 47/50] [Batch 23/600] [D loss: 0.427902] [G loss: 1.570216]\n",
            "[Epoch 47/50] [Batch 24/600] [D loss: 0.395548] [G loss: 1.663701]\n",
            "[Epoch 47/50] [Batch 25/600] [D loss: 0.358437] [G loss: 1.704999]\n",
            "[Epoch 47/50] [Batch 26/600] [D loss: 0.386506] [G loss: 1.877139]\n",
            "[Epoch 47/50] [Batch 27/600] [D loss: 0.468246] [G loss: 2.018940]\n",
            "[Epoch 47/50] [Batch 28/600] [D loss: 0.414000] [G loss: 2.025909]\n",
            "[Epoch 47/50] [Batch 29/600] [D loss: 0.433411] [G loss: 1.809196]\n",
            "[Epoch 47/50] [Batch 30/600] [D loss: 0.445058] [G loss: 1.692247]\n",
            "[Epoch 47/50] [Batch 31/600] [D loss: 0.393963] [G loss: 1.651946]\n",
            "[Epoch 47/50] [Batch 32/600] [D loss: 0.434700] [G loss: 1.700344]\n",
            "[Epoch 47/50] [Batch 33/600] [D loss: 0.402628] [G loss: 1.609657]\n",
            "[Epoch 47/50] [Batch 34/600] [D loss: 0.432643] [G loss: 1.680892]\n",
            "[Epoch 47/50] [Batch 35/600] [D loss: 0.388142] [G loss: 1.728852]\n",
            "[Epoch 47/50] [Batch 36/600] [D loss: 0.384182] [G loss: 1.798786]\n",
            "[Epoch 47/50] [Batch 37/600] [D loss: 0.414608] [G loss: 2.052567]\n",
            "[Epoch 47/50] [Batch 38/600] [D loss: 0.431810] [G loss: 1.777803]\n",
            "[Epoch 47/50] [Batch 39/600] [D loss: 0.418516] [G loss: 1.883208]\n",
            "[Epoch 47/50] [Batch 40/600] [D loss: 0.375330] [G loss: 1.785591]\n",
            "[Epoch 47/50] [Batch 41/600] [D loss: 0.451723] [G loss: 1.714873]\n",
            "[Epoch 47/50] [Batch 42/600] [D loss: 0.416819] [G loss: 1.797931]\n",
            "[Epoch 47/50] [Batch 43/600] [D loss: 0.391514] [G loss: 1.967639]\n",
            "[Epoch 47/50] [Batch 44/600] [D loss: 0.404645] [G loss: 1.919074]\n",
            "[Epoch 47/50] [Batch 45/600] [D loss: 0.359571] [G loss: 2.058485]\n",
            "[Epoch 47/50] [Batch 46/600] [D loss: 0.396750] [G loss: 1.624173]\n",
            "[Epoch 47/50] [Batch 47/600] [D loss: 0.356615] [G loss: 1.671875]\n",
            "[Epoch 47/50] [Batch 48/600] [D loss: 0.380835] [G loss: 2.024856]\n",
            "[Epoch 47/50] [Batch 49/600] [D loss: 0.384594] [G loss: 1.863506]\n",
            "[Epoch 47/50] [Batch 50/600] [D loss: 0.336877] [G loss: 2.306406]\n",
            "[Epoch 47/50] [Batch 51/600] [D loss: 0.397179] [G loss: 2.078063]\n",
            "[Epoch 47/50] [Batch 52/600] [D loss: 0.357044] [G loss: 1.747941]\n",
            "[Epoch 47/50] [Batch 53/600] [D loss: 0.360462] [G loss: 1.661070]\n",
            "[Epoch 47/50] [Batch 54/600] [D loss: 0.415678] [G loss: 1.746043]\n",
            "[Epoch 47/50] [Batch 55/600] [D loss: 0.444761] [G loss: 1.769288]\n",
            "[Epoch 47/50] [Batch 56/600] [D loss: 0.376314] [G loss: 1.893597]\n",
            "[Epoch 47/50] [Batch 57/600] [D loss: 0.380361] [G loss: 1.910878]\n",
            "[Epoch 47/50] [Batch 58/600] [D loss: 0.410065] [G loss: 1.796207]\n",
            "[Epoch 47/50] [Batch 59/600] [D loss: 0.404319] [G loss: 1.782299]\n",
            "[Epoch 47/50] [Batch 60/600] [D loss: 0.370587] [G loss: 1.837304]\n",
            "[Epoch 47/50] [Batch 61/600] [D loss: 0.314131] [G loss: 1.788407]\n",
            "[Epoch 47/50] [Batch 62/600] [D loss: 0.412839] [G loss: 2.078745]\n",
            "[Epoch 47/50] [Batch 63/600] [D loss: 0.409464] [G loss: 1.760554]\n",
            "[Epoch 47/50] [Batch 64/600] [D loss: 0.339816] [G loss: 1.795998]\n",
            "[Epoch 47/50] [Batch 65/600] [D loss: 0.411706] [G loss: 1.678725]\n",
            "[Epoch 47/50] [Batch 66/600] [D loss: 0.416383] [G loss: 2.076872]\n",
            "[Epoch 47/50] [Batch 67/600] [D loss: 0.452184] [G loss: 2.205867]\n",
            "[Epoch 47/50] [Batch 68/600] [D loss: 0.443136] [G loss: 2.128169]\n",
            "[Epoch 47/50] [Batch 69/600] [D loss: 0.382515] [G loss: 1.761662]\n",
            "[Epoch 47/50] [Batch 70/600] [D loss: 0.410346] [G loss: 1.636512]\n",
            "[Epoch 47/50] [Batch 71/600] [D loss: 0.471362] [G loss: 1.699169]\n",
            "[Epoch 47/50] [Batch 72/600] [D loss: 0.467461] [G loss: 1.970893]\n",
            "[Epoch 47/50] [Batch 73/600] [D loss: 0.481438] [G loss: 1.811365]\n",
            "[Epoch 47/50] [Batch 74/600] [D loss: 0.474219] [G loss: 1.651187]\n",
            "[Epoch 47/50] [Batch 75/600] [D loss: 0.384413] [G loss: 1.556812]\n",
            "[Epoch 47/50] [Batch 76/600] [D loss: 0.386202] [G loss: 1.620813]\n",
            "[Epoch 47/50] [Batch 77/600] [D loss: 0.394770] [G loss: 1.663595]\n",
            "[Epoch 47/50] [Batch 78/600] [D loss: 0.396015] [G loss: 1.755856]\n",
            "[Epoch 47/50] [Batch 79/600] [D loss: 0.363626] [G loss: 2.057586]\n",
            "[Epoch 47/50] [Batch 80/600] [D loss: 0.359302] [G loss: 2.171023]\n",
            "[Epoch 47/50] [Batch 81/600] [D loss: 0.433928] [G loss: 1.894063]\n",
            "[Epoch 47/50] [Batch 82/600] [D loss: 0.398585] [G loss: 1.731001]\n",
            "[Epoch 47/50] [Batch 83/600] [D loss: 0.342426] [G loss: 1.851384]\n",
            "[Epoch 47/50] [Batch 84/600] [D loss: 0.441416] [G loss: 1.743431]\n",
            "[Epoch 47/50] [Batch 85/600] [D loss: 0.483053] [G loss: 1.632781]\n",
            "[Epoch 47/50] [Batch 86/600] [D loss: 0.439658] [G loss: 1.764011]\n",
            "[Epoch 47/50] [Batch 87/600] [D loss: 0.444005] [G loss: 1.801660]\n",
            "[Epoch 47/50] [Batch 88/600] [D loss: 0.524186] [G loss: 1.614873]\n",
            "[Epoch 47/50] [Batch 89/600] [D loss: 0.397062] [G loss: 1.843185]\n",
            "[Epoch 47/50] [Batch 90/600] [D loss: 0.424304] [G loss: 1.566829]\n",
            "[Epoch 47/50] [Batch 91/600] [D loss: 0.507282] [G loss: 1.600113]\n",
            "[Epoch 47/50] [Batch 92/600] [D loss: 0.441612] [G loss: 1.480932]\n",
            "[Epoch 47/50] [Batch 93/600] [D loss: 0.426692] [G loss: 1.590263]\n",
            "[Epoch 47/50] [Batch 94/600] [D loss: 0.420950] [G loss: 1.606603]\n",
            "[Epoch 47/50] [Batch 95/600] [D loss: 0.411650] [G loss: 1.706708]\n",
            "[Epoch 47/50] [Batch 96/600] [D loss: 0.460358] [G loss: 1.728972]\n",
            "[Epoch 47/50] [Batch 97/600] [D loss: 0.438590] [G loss: 1.699083]\n",
            "[Epoch 47/50] [Batch 98/600] [D loss: 0.395730] [G loss: 1.703336]\n",
            "[Epoch 47/50] [Batch 99/600] [D loss: 0.375349] [G loss: 1.897121]\n",
            "[Epoch 47/50] [Batch 100/600] [D loss: 0.408982] [G loss: 1.849169]\n",
            "[Epoch 47/50] [Batch 101/600] [D loss: 0.511581] [G loss: 1.808312]\n",
            "[Epoch 47/50] [Batch 102/600] [D loss: 0.455265] [G loss: 1.742228]\n",
            "[Epoch 47/50] [Batch 103/600] [D loss: 0.433543] [G loss: 1.558981]\n",
            "[Epoch 47/50] [Batch 104/600] [D loss: 0.467436] [G loss: 1.395532]\n",
            "[Epoch 47/50] [Batch 105/600] [D loss: 0.423472] [G loss: 1.511305]\n",
            "[Epoch 47/50] [Batch 106/600] [D loss: 0.420265] [G loss: 1.615801]\n",
            "[Epoch 47/50] [Batch 107/600] [D loss: 0.440921] [G loss: 1.569358]\n",
            "[Epoch 47/50] [Batch 108/600] [D loss: 0.445933] [G loss: 1.640519]\n",
            "[Epoch 47/50] [Batch 109/600] [D loss: 0.355792] [G loss: 1.613290]\n",
            "[Epoch 47/50] [Batch 110/600] [D loss: 0.439821] [G loss: 1.698646]\n",
            "[Epoch 47/50] [Batch 111/600] [D loss: 0.475383] [G loss: 1.940590]\n",
            "[Epoch 47/50] [Batch 112/600] [D loss: 0.421085] [G loss: 1.623887]\n",
            "[Epoch 47/50] [Batch 113/600] [D loss: 0.394463] [G loss: 1.628035]\n",
            "[Epoch 47/50] [Batch 114/600] [D loss: 0.385436] [G loss: 1.743353]\n",
            "[Epoch 47/50] [Batch 115/600] [D loss: 0.431154] [G loss: 1.799216]\n",
            "[Epoch 47/50] [Batch 116/600] [D loss: 0.420898] [G loss: 1.815493]\n",
            "[Epoch 47/50] [Batch 117/600] [D loss: 0.400067] [G loss: 1.803272]\n",
            "[Epoch 47/50] [Batch 118/600] [D loss: 0.474900] [G loss: 1.764847]\n",
            "[Epoch 47/50] [Batch 119/600] [D loss: 0.429404] [G loss: 1.721466]\n",
            "[Epoch 47/50] [Batch 120/600] [D loss: 0.435665] [G loss: 1.623812]\n",
            "[Epoch 47/50] [Batch 121/600] [D loss: 0.401473] [G loss: 1.631349]\n",
            "[Epoch 47/50] [Batch 122/600] [D loss: 0.379324] [G loss: 1.675494]\n",
            "[Epoch 47/50] [Batch 123/600] [D loss: 0.430212] [G loss: 1.757184]\n",
            "[Epoch 47/50] [Batch 124/600] [D loss: 0.406075] [G loss: 1.830240]\n",
            "[Epoch 47/50] [Batch 125/600] [D loss: 0.407687] [G loss: 1.923140]\n",
            "[Epoch 47/50] [Batch 126/600] [D loss: 0.383655] [G loss: 1.800767]\n",
            "[Epoch 47/50] [Batch 127/600] [D loss: 0.443642] [G loss: 1.709832]\n",
            "[Epoch 47/50] [Batch 128/600] [D loss: 0.479767] [G loss: 1.570150]\n",
            "[Epoch 47/50] [Batch 129/600] [D loss: 0.415170] [G loss: 1.534643]\n",
            "[Epoch 47/50] [Batch 130/600] [D loss: 0.418170] [G loss: 1.613564]\n",
            "[Epoch 47/50] [Batch 131/600] [D loss: 0.395702] [G loss: 1.715842]\n",
            "[Epoch 47/50] [Batch 132/600] [D loss: 0.396241] [G loss: 1.565247]\n",
            "[Epoch 47/50] [Batch 133/600] [D loss: 0.448769] [G loss: 1.780014]\n",
            "[Epoch 47/50] [Batch 134/600] [D loss: 0.444479] [G loss: 1.725966]\n",
            "[Epoch 47/50] [Batch 135/600] [D loss: 0.406491] [G loss: 1.634426]\n",
            "[Epoch 47/50] [Batch 136/600] [D loss: 0.409858] [G loss: 1.675537]\n",
            "[Epoch 47/50] [Batch 137/600] [D loss: 0.506347] [G loss: 1.826954]\n",
            "[Epoch 47/50] [Batch 138/600] [D loss: 0.389012] [G loss: 1.636693]\n",
            "[Epoch 47/50] [Batch 139/600] [D loss: 0.331331] [G loss: 1.680254]\n",
            "[Epoch 47/50] [Batch 140/600] [D loss: 0.379306] [G loss: 1.891554]\n",
            "[Epoch 47/50] [Batch 141/600] [D loss: 0.375043] [G loss: 1.594509]\n",
            "[Epoch 47/50] [Batch 142/600] [D loss: 0.389128] [G loss: 1.796356]\n",
            "[Epoch 47/50] [Batch 143/600] [D loss: 0.368715] [G loss: 1.964111]\n",
            "[Epoch 47/50] [Batch 144/600] [D loss: 0.402557] [G loss: 1.921161]\n",
            "[Epoch 47/50] [Batch 145/600] [D loss: 0.416186] [G loss: 1.707705]\n",
            "[Epoch 47/50] [Batch 146/600] [D loss: 0.451579] [G loss: 1.679871]\n",
            "[Epoch 47/50] [Batch 147/600] [D loss: 0.415133] [G loss: 1.644395]\n",
            "[Epoch 47/50] [Batch 148/600] [D loss: 0.419690] [G loss: 1.557719]\n",
            "[Epoch 47/50] [Batch 149/600] [D loss: 0.468197] [G loss: 1.812842]\n",
            "[Epoch 47/50] [Batch 150/600] [D loss: 0.428533] [G loss: 1.974558]\n",
            "[Epoch 47/50] [Batch 151/600] [D loss: 0.468349] [G loss: 1.910415]\n",
            "[Epoch 47/50] [Batch 152/600] [D loss: 0.394022] [G loss: 2.058187]\n",
            "[Epoch 47/50] [Batch 153/600] [D loss: 0.504129] [G loss: 1.796119]\n",
            "[Epoch 47/50] [Batch 154/600] [D loss: 0.427986] [G loss: 1.606119]\n",
            "[Epoch 47/50] [Batch 155/600] [D loss: 0.419088] [G loss: 1.671459]\n",
            "[Epoch 47/50] [Batch 156/600] [D loss: 0.382085] [G loss: 1.507717]\n",
            "[Epoch 47/50] [Batch 157/600] [D loss: 0.436233] [G loss: 1.777484]\n",
            "[Epoch 47/50] [Batch 158/600] [D loss: 0.427447] [G loss: 1.760249]\n",
            "[Epoch 47/50] [Batch 159/600] [D loss: 0.381631] [G loss: 1.688942]\n",
            "[Epoch 47/50] [Batch 160/600] [D loss: 0.385921] [G loss: 1.506852]\n",
            "[Epoch 47/50] [Batch 161/600] [D loss: 0.380605] [G loss: 1.565446]\n",
            "[Epoch 47/50] [Batch 162/600] [D loss: 0.365515] [G loss: 1.660732]\n",
            "[Epoch 47/50] [Batch 163/600] [D loss: 0.454831] [G loss: 1.617386]\n",
            "[Epoch 47/50] [Batch 164/600] [D loss: 0.464461] [G loss: 1.906921]\n",
            "[Epoch 47/50] [Batch 165/600] [D loss: 0.433349] [G loss: 1.581674]\n",
            "[Epoch 47/50] [Batch 166/600] [D loss: 0.439680] [G loss: 1.772601]\n",
            "[Epoch 47/50] [Batch 167/600] [D loss: 0.406500] [G loss: 1.761560]\n",
            "[Epoch 47/50] [Batch 168/600] [D loss: 0.436459] [G loss: 1.632998]\n",
            "[Epoch 47/50] [Batch 169/600] [D loss: 0.482860] [G loss: 2.005289]\n",
            "[Epoch 47/50] [Batch 170/600] [D loss: 0.389777] [G loss: 1.811020]\n",
            "[Epoch 47/50] [Batch 171/600] [D loss: 0.442617] [G loss: 1.596617]\n",
            "[Epoch 47/50] [Batch 172/600] [D loss: 0.387668] [G loss: 1.583098]\n",
            "[Epoch 47/50] [Batch 173/600] [D loss: 0.403915] [G loss: 1.587779]\n",
            "[Epoch 47/50] [Batch 174/600] [D loss: 0.434867] [G loss: 1.691458]\n",
            "[Epoch 47/50] [Batch 175/600] [D loss: 0.465674] [G loss: 1.756204]\n",
            "[Epoch 47/50] [Batch 176/600] [D loss: 0.446136] [G loss: 1.560334]\n",
            "[Epoch 47/50] [Batch 177/600] [D loss: 0.513099] [G loss: 1.636901]\n",
            "[Epoch 47/50] [Batch 178/600] [D loss: 0.455722] [G loss: 1.542420]\n",
            "[Epoch 47/50] [Batch 179/600] [D loss: 0.465030] [G loss: 1.557299]\n",
            "[Epoch 47/50] [Batch 180/600] [D loss: 0.424436] [G loss: 1.717698]\n",
            "[Epoch 47/50] [Batch 181/600] [D loss: 0.402701] [G loss: 1.604869]\n",
            "[Epoch 47/50] [Batch 182/600] [D loss: 0.399058] [G loss: 1.559146]\n",
            "[Epoch 47/50] [Batch 183/600] [D loss: 0.440668] [G loss: 1.561961]\n",
            "[Epoch 47/50] [Batch 184/600] [D loss: 0.430898] [G loss: 1.610935]\n",
            "[Epoch 47/50] [Batch 185/600] [D loss: 0.403933] [G loss: 1.656677]\n",
            "[Epoch 47/50] [Batch 186/600] [D loss: 0.410077] [G loss: 1.414730]\n",
            "[Epoch 47/50] [Batch 187/600] [D loss: 0.449735] [G loss: 1.583859]\n",
            "[Epoch 47/50] [Batch 188/600] [D loss: 0.433961] [G loss: 1.595465]\n",
            "[Epoch 47/50] [Batch 189/600] [D loss: 0.418257] [G loss: 1.752332]\n",
            "[Epoch 47/50] [Batch 190/600] [D loss: 0.406028] [G loss: 1.695729]\n",
            "[Epoch 47/50] [Batch 191/600] [D loss: 0.481888] [G loss: 1.847312]\n",
            "[Epoch 47/50] [Batch 192/600] [D loss: 0.386273] [G loss: 1.819704]\n",
            "[Epoch 47/50] [Batch 193/600] [D loss: 0.432499] [G loss: 1.484149]\n",
            "[Epoch 47/50] [Batch 194/600] [D loss: 0.479259] [G loss: 1.526664]\n",
            "[Epoch 47/50] [Batch 195/600] [D loss: 0.467301] [G loss: 1.439997]\n",
            "[Epoch 47/50] [Batch 196/600] [D loss: 0.351504] [G loss: 1.681011]\n",
            "[Epoch 47/50] [Batch 197/600] [D loss: 0.354323] [G loss: 1.731808]\n",
            "[Epoch 47/50] [Batch 198/600] [D loss: 0.408287] [G loss: 1.550357]\n",
            "[Epoch 47/50] [Batch 199/600] [D loss: 0.365750] [G loss: 1.605215]\n",
            "[Epoch 47/50] [Batch 200/600] [D loss: 0.390590] [G loss: 1.744916]\n",
            "[Epoch 47/50] [Batch 201/600] [D loss: 0.423623] [G loss: 1.689917]\n",
            "[Epoch 47/50] [Batch 202/600] [D loss: 0.452844] [G loss: 1.942186]\n",
            "[Epoch 47/50] [Batch 203/600] [D loss: 0.400954] [G loss: 1.989245]\n",
            "[Epoch 47/50] [Batch 204/600] [D loss: 0.424817] [G loss: 1.469260]\n",
            "[Epoch 47/50] [Batch 205/600] [D loss: 0.405970] [G loss: 1.799820]\n",
            "[Epoch 47/50] [Batch 206/600] [D loss: 0.455600] [G loss: 1.785694]\n",
            "[Epoch 47/50] [Batch 207/600] [D loss: 0.417043] [G loss: 1.789286]\n",
            "[Epoch 47/50] [Batch 208/600] [D loss: 0.438171] [G loss: 1.618302]\n",
            "[Epoch 47/50] [Batch 209/600] [D loss: 0.405411] [G loss: 1.525865]\n",
            "[Epoch 47/50] [Batch 210/600] [D loss: 0.399838] [G loss: 1.765923]\n",
            "[Epoch 47/50] [Batch 211/600] [D loss: 0.385581] [G loss: 2.004951]\n",
            "[Epoch 47/50] [Batch 212/600] [D loss: 0.411527] [G loss: 1.954532]\n",
            "[Epoch 47/50] [Batch 213/600] [D loss: 0.425767] [G loss: 2.043602]\n",
            "[Epoch 47/50] [Batch 214/600] [D loss: 0.407269] [G loss: 1.866253]\n",
            "[Epoch 47/50] [Batch 215/600] [D loss: 0.419747] [G loss: 1.683112]\n",
            "[Epoch 47/50] [Batch 216/600] [D loss: 0.428753] [G loss: 1.697452]\n",
            "[Epoch 47/50] [Batch 217/600] [D loss: 0.413771] [G loss: 1.687696]\n",
            "[Epoch 47/50] [Batch 218/600] [D loss: 0.387559] [G loss: 1.624332]\n",
            "[Epoch 47/50] [Batch 219/600] [D loss: 0.309653] [G loss: 1.849907]\n",
            "[Epoch 47/50] [Batch 220/600] [D loss: 0.337020] [G loss: 1.809175]\n",
            "[Epoch 47/50] [Batch 221/600] [D loss: 0.481967] [G loss: 2.031899]\n",
            "[Epoch 47/50] [Batch 222/600] [D loss: 0.387440] [G loss: 1.898816]\n",
            "[Epoch 47/50] [Batch 223/600] [D loss: 0.446718] [G loss: 1.762494]\n",
            "[Epoch 47/50] [Batch 224/600] [D loss: 0.445684] [G loss: 1.642718]\n",
            "[Epoch 47/50] [Batch 225/600] [D loss: 0.478036] [G loss: 1.623525]\n",
            "[Epoch 47/50] [Batch 226/600] [D loss: 0.336908] [G loss: 1.828302]\n",
            "[Epoch 47/50] [Batch 227/600] [D loss: 0.442980] [G loss: 1.842983]\n",
            "[Epoch 47/50] [Batch 228/600] [D loss: 0.370335] [G loss: 1.856764]\n",
            "[Epoch 47/50] [Batch 229/600] [D loss: 0.368982] [G loss: 1.911731]\n",
            "[Epoch 47/50] [Batch 230/600] [D loss: 0.380402] [G loss: 1.764862]\n",
            "[Epoch 47/50] [Batch 231/600] [D loss: 0.395720] [G loss: 1.636751]\n",
            "[Epoch 47/50] [Batch 232/600] [D loss: 0.421442] [G loss: 1.691674]\n",
            "[Epoch 47/50] [Batch 233/600] [D loss: 0.426803] [G loss: 1.818534]\n",
            "[Epoch 47/50] [Batch 234/600] [D loss: 0.391643] [G loss: 1.837666]\n",
            "[Epoch 47/50] [Batch 235/600] [D loss: 0.466896] [G loss: 1.807875]\n",
            "[Epoch 47/50] [Batch 236/600] [D loss: 0.493644] [G loss: 1.908373]\n",
            "[Epoch 47/50] [Batch 237/600] [D loss: 0.406124] [G loss: 1.717572]\n",
            "[Epoch 47/50] [Batch 238/600] [D loss: 0.448967] [G loss: 1.719437]\n",
            "[Epoch 47/50] [Batch 239/600] [D loss: 0.376027] [G loss: 1.823280]\n",
            "[Epoch 47/50] [Batch 240/600] [D loss: 0.514092] [G loss: 1.604990]\n",
            "[Epoch 47/50] [Batch 241/600] [D loss: 0.453452] [G loss: 1.742940]\n",
            "[Epoch 47/50] [Batch 242/600] [D loss: 0.425066] [G loss: 1.406624]\n",
            "[Epoch 47/50] [Batch 243/600] [D loss: 0.437328] [G loss: 1.673891]\n",
            "[Epoch 47/50] [Batch 244/600] [D loss: 0.421894] [G loss: 1.619794]\n",
            "[Epoch 47/50] [Batch 245/600] [D loss: 0.398166] [G loss: 1.574899]\n",
            "[Epoch 47/50] [Batch 246/600] [D loss: 0.342861] [G loss: 1.788072]\n",
            "[Epoch 47/50] [Batch 247/600] [D loss: 0.440137] [G loss: 1.898017]\n",
            "[Epoch 47/50] [Batch 248/600] [D loss: 0.373044] [G loss: 1.687521]\n",
            "[Epoch 47/50] [Batch 249/600] [D loss: 0.432413] [G loss: 1.794488]\n",
            "[Epoch 47/50] [Batch 250/600] [D loss: 0.435707] [G loss: 1.665584]\n",
            "[Epoch 47/50] [Batch 251/600] [D loss: 0.468788] [G loss: 1.848172]\n",
            "[Epoch 47/50] [Batch 252/600] [D loss: 0.437203] [G loss: 2.144310]\n",
            "[Epoch 47/50] [Batch 253/600] [D loss: 0.412583] [G loss: 1.848883]\n",
            "[Epoch 47/50] [Batch 254/600] [D loss: 0.382359] [G loss: 1.766991]\n",
            "[Epoch 47/50] [Batch 255/600] [D loss: 0.389125] [G loss: 1.622908]\n",
            "[Epoch 47/50] [Batch 256/600] [D loss: 0.459188] [G loss: 1.331794]\n",
            "[Epoch 47/50] [Batch 257/600] [D loss: 0.418304] [G loss: 1.562905]\n",
            "[Epoch 47/50] [Batch 258/600] [D loss: 0.447630] [G loss: 1.801324]\n",
            "[Epoch 47/50] [Batch 259/600] [D loss: 0.431232] [G loss: 1.795371]\n",
            "[Epoch 47/50] [Batch 260/600] [D loss: 0.441878] [G loss: 1.651388]\n",
            "[Epoch 47/50] [Batch 261/600] [D loss: 0.429118] [G loss: 1.571245]\n",
            "[Epoch 47/50] [Batch 262/600] [D loss: 0.537677] [G loss: 1.428877]\n",
            "[Epoch 47/50] [Batch 263/600] [D loss: 0.476838] [G loss: 1.488214]\n",
            "[Epoch 47/50] [Batch 264/600] [D loss: 0.481115] [G loss: 1.625238]\n",
            "[Epoch 47/50] [Batch 265/600] [D loss: 0.438961] [G loss: 1.521092]\n",
            "[Epoch 47/50] [Batch 266/600] [D loss: 0.416124] [G loss: 1.647520]\n",
            "[Epoch 47/50] [Batch 267/600] [D loss: 0.408498] [G loss: 1.547759]\n",
            "[Epoch 47/50] [Batch 268/600] [D loss: 0.538901] [G loss: 1.528326]\n",
            "[Epoch 47/50] [Batch 269/600] [D loss: 0.400424] [G loss: 1.582528]\n",
            "[Epoch 47/50] [Batch 270/600] [D loss: 0.415424] [G loss: 1.476201]\n",
            "[Epoch 47/50] [Batch 271/600] [D loss: 0.388868] [G loss: 1.634624]\n",
            "[Epoch 47/50] [Batch 272/600] [D loss: 0.446087] [G loss: 1.701315]\n",
            "[Epoch 47/50] [Batch 273/600] [D loss: 0.416932] [G loss: 1.775900]\n",
            "[Epoch 47/50] [Batch 274/600] [D loss: 0.428902] [G loss: 1.843397]\n",
            "[Epoch 47/50] [Batch 275/600] [D loss: 0.403342] [G loss: 1.675170]\n",
            "[Epoch 47/50] [Batch 276/600] [D loss: 0.413817] [G loss: 1.628585]\n",
            "[Epoch 47/50] [Batch 277/600] [D loss: 0.381830] [G loss: 1.927610]\n",
            "[Epoch 47/50] [Batch 278/600] [D loss: 0.399372] [G loss: 1.898118]\n",
            "[Epoch 47/50] [Batch 279/600] [D loss: 0.487520] [G loss: 1.857896]\n",
            "[Epoch 47/50] [Batch 280/600] [D loss: 0.401586] [G loss: 1.716730]\n",
            "[Epoch 47/50] [Batch 281/600] [D loss: 0.393227] [G loss: 1.641743]\n",
            "[Epoch 47/50] [Batch 282/600] [D loss: 0.357020] [G loss: 1.766331]\n",
            "[Epoch 47/50] [Batch 283/600] [D loss: 0.439377] [G loss: 1.481305]\n",
            "[Epoch 47/50] [Batch 284/600] [D loss: 0.352572] [G loss: 1.784623]\n",
            "[Epoch 47/50] [Batch 285/600] [D loss: 0.359553] [G loss: 1.809886]\n",
            "[Epoch 47/50] [Batch 286/600] [D loss: 0.397891] [G loss: 1.952774]\n",
            "[Epoch 47/50] [Batch 287/600] [D loss: 0.409263] [G loss: 1.755816]\n",
            "[Epoch 47/50] [Batch 288/600] [D loss: 0.329396] [G loss: 1.735615]\n",
            "[Epoch 47/50] [Batch 289/600] [D loss: 0.395923] [G loss: 2.062893]\n",
            "[Epoch 47/50] [Batch 290/600] [D loss: 0.455543] [G loss: 2.089916]\n",
            "[Epoch 47/50] [Batch 291/600] [D loss: 0.520450] [G loss: 2.100228]\n",
            "[Epoch 47/50] [Batch 292/600] [D loss: 0.386338] [G loss: 1.823823]\n",
            "[Epoch 47/50] [Batch 293/600] [D loss: 0.440534] [G loss: 1.512148]\n",
            "[Epoch 47/50] [Batch 294/600] [D loss: 0.359285] [G loss: 1.517431]\n",
            "[Epoch 47/50] [Batch 295/600] [D loss: 0.472519] [G loss: 1.461773]\n",
            "[Epoch 47/50] [Batch 296/600] [D loss: 0.409158] [G loss: 1.511111]\n",
            "[Epoch 47/50] [Batch 297/600] [D loss: 0.483746] [G loss: 1.734977]\n",
            "[Epoch 47/50] [Batch 298/600] [D loss: 0.499542] [G loss: 1.639724]\n",
            "[Epoch 47/50] [Batch 299/600] [D loss: 0.412500] [G loss: 1.656803]\n",
            "[Epoch 47/50] [Batch 300/600] [D loss: 0.420763] [G loss: 1.613701]\n",
            "[Epoch 47/50] [Batch 301/600] [D loss: 0.378142] [G loss: 1.479590]\n",
            "[Epoch 47/50] [Batch 302/600] [D loss: 0.411302] [G loss: 1.704578]\n",
            "[Epoch 47/50] [Batch 303/600] [D loss: 0.406948] [G loss: 1.769885]\n",
            "[Epoch 47/50] [Batch 304/600] [D loss: 0.429706] [G loss: 1.782348]\n",
            "[Epoch 47/50] [Batch 305/600] [D loss: 0.464539] [G loss: 1.757450]\n",
            "[Epoch 47/50] [Batch 306/600] [D loss: 0.465154] [G loss: 1.668474]\n",
            "[Epoch 47/50] [Batch 307/600] [D loss: 0.448882] [G loss: 1.518809]\n",
            "[Epoch 47/50] [Batch 308/600] [D loss: 0.483927] [G loss: 1.630194]\n",
            "[Epoch 47/50] [Batch 309/600] [D loss: 0.474517] [G loss: 1.579764]\n",
            "[Epoch 47/50] [Batch 310/600] [D loss: 0.420743] [G loss: 1.663765]\n",
            "[Epoch 47/50] [Batch 311/600] [D loss: 0.350955] [G loss: 1.722931]\n",
            "[Epoch 47/50] [Batch 312/600] [D loss: 0.391586] [G loss: 1.556552]\n",
            "[Epoch 47/50] [Batch 313/600] [D loss: 0.440455] [G loss: 1.652238]\n",
            "[Epoch 47/50] [Batch 314/600] [D loss: 0.435073] [G loss: 1.848424]\n",
            "[Epoch 47/50] [Batch 315/600] [D loss: 0.467147] [G loss: 1.633726]\n",
            "[Epoch 47/50] [Batch 316/600] [D loss: 0.447820] [G loss: 1.532417]\n",
            "[Epoch 47/50] [Batch 317/600] [D loss: 0.490590] [G loss: 1.687291]\n",
            "[Epoch 47/50] [Batch 318/600] [D loss: 0.469796] [G loss: 1.514676]\n",
            "[Epoch 47/50] [Batch 319/600] [D loss: 0.384492] [G loss: 1.517649]\n",
            "[Epoch 47/50] [Batch 320/600] [D loss: 0.400426] [G loss: 1.584007]\n",
            "[Epoch 47/50] [Batch 321/600] [D loss: 0.393812] [G loss: 1.586915]\n",
            "[Epoch 47/50] [Batch 322/600] [D loss: 0.353213] [G loss: 1.704587]\n",
            "[Epoch 47/50] [Batch 323/600] [D loss: 0.424065] [G loss: 1.694314]\n",
            "[Epoch 47/50] [Batch 324/600] [D loss: 0.396922] [G loss: 1.840965]\n",
            "[Epoch 47/50] [Batch 325/600] [D loss: 0.424877] [G loss: 1.464754]\n",
            "[Epoch 47/50] [Batch 326/600] [D loss: 0.399199] [G loss: 1.728337]\n",
            "[Epoch 47/50] [Batch 327/600] [D loss: 0.479989] [G loss: 1.698667]\n",
            "[Epoch 47/50] [Batch 328/600] [D loss: 0.395965] [G loss: 1.931875]\n",
            "[Epoch 47/50] [Batch 329/600] [D loss: 0.430417] [G loss: 1.738687]\n",
            "[Epoch 47/50] [Batch 330/600] [D loss: 0.342878] [G loss: 1.862726]\n",
            "[Epoch 47/50] [Batch 331/600] [D loss: 0.387590] [G loss: 1.825662]\n",
            "[Epoch 47/50] [Batch 332/600] [D loss: 0.399920] [G loss: 1.849730]\n",
            "[Epoch 47/50] [Batch 333/600] [D loss: 0.364185] [G loss: 1.887285]\n",
            "[Epoch 47/50] [Batch 334/600] [D loss: 0.380097] [G loss: 1.709128]\n",
            "[Epoch 47/50] [Batch 335/600] [D loss: 0.395593] [G loss: 1.659719]\n",
            "[Epoch 47/50] [Batch 336/600] [D loss: 0.466690] [G loss: 1.839275]\n",
            "[Epoch 47/50] [Batch 337/600] [D loss: 0.511142] [G loss: 1.833194]\n",
            "[Epoch 47/50] [Batch 338/600] [D loss: 0.516821] [G loss: 1.808937]\n",
            "[Epoch 47/50] [Batch 339/600] [D loss: 0.440845] [G loss: 1.375656]\n",
            "[Epoch 47/50] [Batch 340/600] [D loss: 0.464312] [G loss: 1.740411]\n",
            "[Epoch 47/50] [Batch 341/600] [D loss: 0.344408] [G loss: 1.723477]\n",
            "[Epoch 47/50] [Batch 342/600] [D loss: 0.373980] [G loss: 1.531795]\n",
            "[Epoch 47/50] [Batch 343/600] [D loss: 0.445061] [G loss: 1.823346]\n",
            "[Epoch 47/50] [Batch 344/600] [D loss: 0.380421] [G loss: 1.598316]\n",
            "[Epoch 47/50] [Batch 345/600] [D loss: 0.445582] [G loss: 1.551973]\n",
            "[Epoch 47/50] [Batch 346/600] [D loss: 0.416833] [G loss: 1.508575]\n",
            "[Epoch 47/50] [Batch 347/600] [D loss: 0.385952] [G loss: 1.592122]\n",
            "[Epoch 47/50] [Batch 348/600] [D loss: 0.397572] [G loss: 1.738120]\n",
            "[Epoch 47/50] [Batch 349/600] [D loss: 0.409325] [G loss: 1.866154]\n",
            "[Epoch 47/50] [Batch 350/600] [D loss: 0.401482] [G loss: 1.640075]\n",
            "[Epoch 47/50] [Batch 351/600] [D loss: 0.464822] [G loss: 1.807481]\n",
            "[Epoch 47/50] [Batch 352/600] [D loss: 0.371421] [G loss: 1.755127]\n",
            "[Epoch 47/50] [Batch 353/600] [D loss: 0.370106] [G loss: 1.900882]\n",
            "[Epoch 47/50] [Batch 354/600] [D loss: 0.331851] [G loss: 1.911245]\n",
            "[Epoch 47/50] [Batch 355/600] [D loss: 0.409648] [G loss: 1.838587]\n",
            "[Epoch 47/50] [Batch 356/600] [D loss: 0.408540] [G loss: 1.910160]\n",
            "[Epoch 47/50] [Batch 357/600] [D loss: 0.442911] [G loss: 1.807567]\n",
            "[Epoch 47/50] [Batch 358/600] [D loss: 0.450715] [G loss: 1.611753]\n",
            "[Epoch 47/50] [Batch 359/600] [D loss: 0.418122] [G loss: 1.566923]\n",
            "[Epoch 47/50] [Batch 360/600] [D loss: 0.481471] [G loss: 1.545993]\n",
            "[Epoch 47/50] [Batch 361/600] [D loss: 0.436901] [G loss: 1.610768]\n",
            "[Epoch 47/50] [Batch 362/600] [D loss: 0.425020] [G loss: 1.619703]\n",
            "[Epoch 47/50] [Batch 363/600] [D loss: 0.373395] [G loss: 1.547507]\n",
            "[Epoch 47/50] [Batch 364/600] [D loss: 0.443820] [G loss: 1.835660]\n",
            "[Epoch 47/50] [Batch 365/600] [D loss: 0.429147] [G loss: 1.808460]\n",
            "[Epoch 47/50] [Batch 366/600] [D loss: 0.366733] [G loss: 1.789242]\n",
            "[Epoch 47/50] [Batch 367/600] [D loss: 0.347544] [G loss: 1.773799]\n",
            "[Epoch 47/50] [Batch 368/600] [D loss: 0.449778] [G loss: 1.865024]\n",
            "[Epoch 47/50] [Batch 369/600] [D loss: 0.442048] [G loss: 1.500956]\n",
            "[Epoch 47/50] [Batch 370/600] [D loss: 0.386567] [G loss: 1.563880]\n",
            "[Epoch 47/50] [Batch 371/600] [D loss: 0.385837] [G loss: 1.974170]\n",
            "[Epoch 47/50] [Batch 372/600] [D loss: 0.369249] [G loss: 1.602082]\n",
            "[Epoch 47/50] [Batch 373/600] [D loss: 0.422986] [G loss: 1.989988]\n",
            "[Epoch 47/50] [Batch 374/600] [D loss: 0.461988] [G loss: 1.901686]\n",
            "[Epoch 47/50] [Batch 375/600] [D loss: 0.439298] [G loss: 1.876649]\n",
            "[Epoch 47/50] [Batch 376/600] [D loss: 0.446365] [G loss: 1.659104]\n",
            "[Epoch 47/50] [Batch 377/600] [D loss: 0.532227] [G loss: 1.608682]\n",
            "[Epoch 47/50] [Batch 378/600] [D loss: 0.418589] [G loss: 1.757570]\n",
            "[Epoch 47/50] [Batch 379/600] [D loss: 0.394420] [G loss: 1.583137]\n",
            "[Epoch 47/50] [Batch 380/600] [D loss: 0.372870] [G loss: 1.683315]\n",
            "[Epoch 47/50] [Batch 381/600] [D loss: 0.356706] [G loss: 1.735699]\n",
            "[Epoch 47/50] [Batch 382/600] [D loss: 0.426067] [G loss: 1.839760]\n",
            "[Epoch 47/50] [Batch 383/600] [D loss: 0.495481] [G loss: 1.567649]\n",
            "[Epoch 47/50] [Batch 384/600] [D loss: 0.374444] [G loss: 1.743662]\n",
            "[Epoch 47/50] [Batch 385/600] [D loss: 0.446983] [G loss: 1.872554]\n",
            "[Epoch 47/50] [Batch 386/600] [D loss: 0.396859] [G loss: 1.741034]\n",
            "[Epoch 47/50] [Batch 387/600] [D loss: 0.439559] [G loss: 1.976855]\n",
            "[Epoch 47/50] [Batch 388/600] [D loss: 0.400385] [G loss: 1.793955]\n",
            "[Epoch 47/50] [Batch 389/600] [D loss: 0.483331] [G loss: 1.599748]\n",
            "[Epoch 47/50] [Batch 390/600] [D loss: 0.366530] [G loss: 1.547055]\n",
            "[Epoch 47/50] [Batch 391/600] [D loss: 0.376977] [G loss: 1.772436]\n",
            "[Epoch 47/50] [Batch 392/600] [D loss: 0.377592] [G loss: 1.654616]\n",
            "[Epoch 47/50] [Batch 393/600] [D loss: 0.482656] [G loss: 1.725916]\n",
            "[Epoch 47/50] [Batch 394/600] [D loss: 0.422274] [G loss: 1.639351]\n",
            "[Epoch 47/50] [Batch 395/600] [D loss: 0.414998] [G loss: 1.406623]\n",
            "[Epoch 47/50] [Batch 396/600] [D loss: 0.448934] [G loss: 1.570529]\n",
            "[Epoch 47/50] [Batch 397/600] [D loss: 0.437373] [G loss: 1.621237]\n",
            "[Epoch 47/50] [Batch 398/600] [D loss: 0.423701] [G loss: 1.669086]\n",
            "[Epoch 47/50] [Batch 399/600] [D loss: 0.438370] [G loss: 1.741560]\n",
            "[Epoch 47/50] [Batch 400/600] [D loss: 0.428289] [G loss: 1.477023]\n",
            "[Epoch 47/50] [Batch 401/600] [D loss: 0.452263] [G loss: 1.672030]\n",
            "[Epoch 47/50] [Batch 402/600] [D loss: 0.458420] [G loss: 1.605719]\n",
            "[Epoch 47/50] [Batch 403/600] [D loss: 0.450049] [G loss: 1.748525]\n",
            "[Epoch 47/50] [Batch 404/600] [D loss: 0.390211] [G loss: 1.740989]\n",
            "[Epoch 47/50] [Batch 405/600] [D loss: 0.322235] [G loss: 1.737605]\n",
            "[Epoch 47/50] [Batch 406/600] [D loss: 0.379614] [G loss: 1.833879]\n",
            "[Epoch 47/50] [Batch 407/600] [D loss: 0.428444] [G loss: 1.778192]\n",
            "[Epoch 47/50] [Batch 408/600] [D loss: 0.365701] [G loss: 1.676344]\n",
            "[Epoch 47/50] [Batch 409/600] [D loss: 0.449169] [G loss: 1.869121]\n",
            "[Epoch 47/50] [Batch 410/600] [D loss: 0.470737] [G loss: 1.762742]\n",
            "[Epoch 47/50] [Batch 411/600] [D loss: 0.428045] [G loss: 1.603198]\n",
            "[Epoch 47/50] [Batch 412/600] [D loss: 0.461554] [G loss: 1.482534]\n",
            "[Epoch 47/50] [Batch 413/600] [D loss: 0.455020] [G loss: 1.711908]\n",
            "[Epoch 47/50] [Batch 414/600] [D loss: 0.430006] [G loss: 1.824937]\n",
            "[Epoch 47/50] [Batch 415/600] [D loss: 0.379910] [G loss: 1.623498]\n",
            "[Epoch 47/50] [Batch 416/600] [D loss: 0.478489] [G loss: 1.529768]\n",
            "[Epoch 47/50] [Batch 417/600] [D loss: 0.446520] [G loss: 1.693719]\n",
            "[Epoch 47/50] [Batch 418/600] [D loss: 0.386110] [G loss: 1.553032]\n",
            "[Epoch 47/50] [Batch 419/600] [D loss: 0.468685] [G loss: 1.919998]\n",
            "[Epoch 47/50] [Batch 420/600] [D loss: 0.414864] [G loss: 1.542436]\n",
            "[Epoch 47/50] [Batch 421/600] [D loss: 0.434551] [G loss: 1.523409]\n",
            "[Epoch 47/50] [Batch 422/600] [D loss: 0.358433] [G loss: 1.526973]\n",
            "[Epoch 47/50] [Batch 423/600] [D loss: 0.386820] [G loss: 1.440202]\n",
            "[Epoch 47/50] [Batch 424/600] [D loss: 0.441827] [G loss: 1.623227]\n",
            "[Epoch 47/50] [Batch 425/600] [D loss: 0.514615] [G loss: 1.668589]\n",
            "[Epoch 47/50] [Batch 426/600] [D loss: 0.380112] [G loss: 1.564793]\n",
            "[Epoch 47/50] [Batch 427/600] [D loss: 0.359594] [G loss: 1.798235]\n",
            "[Epoch 47/50] [Batch 428/600] [D loss: 0.439061] [G loss: 1.911391]\n",
            "[Epoch 47/50] [Batch 429/600] [D loss: 0.401668] [G loss: 1.448243]\n",
            "[Epoch 47/50] [Batch 430/600] [D loss: 0.538193] [G loss: 1.478192]\n",
            "[Epoch 47/50] [Batch 431/600] [D loss: 0.448354] [G loss: 1.484693]\n",
            "[Epoch 47/50] [Batch 432/600] [D loss: 0.405106] [G loss: 1.376694]\n",
            "[Epoch 47/50] [Batch 433/600] [D loss: 0.451770] [G loss: 1.519779]\n",
            "[Epoch 47/50] [Batch 434/600] [D loss: 0.445880] [G loss: 1.426849]\n",
            "[Epoch 47/50] [Batch 435/600] [D loss: 0.379424] [G loss: 1.687238]\n",
            "[Epoch 47/50] [Batch 436/600] [D loss: 0.385183] [G loss: 1.667615]\n",
            "[Epoch 47/50] [Batch 437/600] [D loss: 0.421726] [G loss: 1.628123]\n",
            "[Epoch 47/50] [Batch 438/600] [D loss: 0.445754] [G loss: 1.848056]\n",
            "[Epoch 47/50] [Batch 439/600] [D loss: 0.493339] [G loss: 1.624441]\n",
            "[Epoch 47/50] [Batch 440/600] [D loss: 0.410596] [G loss: 1.772064]\n",
            "[Epoch 47/50] [Batch 441/600] [D loss: 0.414594] [G loss: 1.671226]\n",
            "[Epoch 47/50] [Batch 442/600] [D loss: 0.378758] [G loss: 1.615168]\n",
            "[Epoch 47/50] [Batch 443/600] [D loss: 0.373125] [G loss: 1.840683]\n",
            "[Epoch 47/50] [Batch 444/600] [D loss: 0.425770] [G loss: 1.824647]\n",
            "[Epoch 47/50] [Batch 445/600] [D loss: 0.461677] [G loss: 1.770395]\n",
            "[Epoch 47/50] [Batch 446/600] [D loss: 0.417241] [G loss: 1.738397]\n",
            "[Epoch 47/50] [Batch 447/600] [D loss: 0.430317] [G loss: 1.632014]\n",
            "[Epoch 47/50] [Batch 448/600] [D loss: 0.401412] [G loss: 1.766757]\n",
            "[Epoch 47/50] [Batch 449/600] [D loss: 0.486596] [G loss: 1.574322]\n",
            "[Epoch 47/50] [Batch 450/600] [D loss: 0.426073] [G loss: 1.798921]\n",
            "[Epoch 47/50] [Batch 451/600] [D loss: 0.422098] [G loss: 1.565009]\n",
            "[Epoch 47/50] [Batch 452/600] [D loss: 0.432705] [G loss: 1.561003]\n",
            "[Epoch 47/50] [Batch 453/600] [D loss: 0.414184] [G loss: 1.769838]\n",
            "[Epoch 47/50] [Batch 454/600] [D loss: 0.442686] [G loss: 1.562014]\n",
            "[Epoch 47/50] [Batch 455/600] [D loss: 0.391540] [G loss: 1.505261]\n",
            "[Epoch 47/50] [Batch 456/600] [D loss: 0.389789] [G loss: 1.768029]\n",
            "[Epoch 47/50] [Batch 457/600] [D loss: 0.462085] [G loss: 1.481694]\n",
            "[Epoch 47/50] [Batch 458/600] [D loss: 0.481627] [G loss: 1.932538]\n",
            "[Epoch 47/50] [Batch 459/600] [D loss: 0.455360] [G loss: 1.574782]\n",
            "[Epoch 47/50] [Batch 460/600] [D loss: 0.506763] [G loss: 1.653664]\n",
            "[Epoch 47/50] [Batch 461/600] [D loss: 0.438625] [G loss: 1.508202]\n",
            "[Epoch 47/50] [Batch 462/600] [D loss: 0.391169] [G loss: 1.773093]\n",
            "[Epoch 47/50] [Batch 463/600] [D loss: 0.437315] [G loss: 1.580615]\n",
            "[Epoch 47/50] [Batch 464/600] [D loss: 0.332243] [G loss: 1.681489]\n",
            "[Epoch 47/50] [Batch 465/600] [D loss: 0.325606] [G loss: 1.923315]\n",
            "[Epoch 47/50] [Batch 466/600] [D loss: 0.425591] [G loss: 1.652233]\n",
            "[Epoch 47/50] [Batch 467/600] [D loss: 0.360608] [G loss: 1.559685]\n",
            "[Epoch 47/50] [Batch 468/600] [D loss: 0.405925] [G loss: 1.810743]\n",
            "[Epoch 47/50] [Batch 469/600] [D loss: 0.373425] [G loss: 1.846974]\n",
            "[Epoch 47/50] [Batch 470/600] [D loss: 0.344207] [G loss: 1.990297]\n",
            "[Epoch 47/50] [Batch 471/600] [D loss: 0.458625] [G loss: 1.994791]\n",
            "[Epoch 47/50] [Batch 472/600] [D loss: 0.466083] [G loss: 1.806646]\n",
            "[Epoch 47/50] [Batch 473/600] [D loss: 0.398644] [G loss: 1.950315]\n",
            "[Epoch 47/50] [Batch 474/600] [D loss: 0.401084] [G loss: 1.606501]\n",
            "[Epoch 47/50] [Batch 475/600] [D loss: 0.319054] [G loss: 1.741142]\n",
            "[Epoch 47/50] [Batch 476/600] [D loss: 0.418105] [G loss: 1.728754]\n",
            "[Epoch 47/50] [Batch 477/600] [D loss: 0.353148] [G loss: 1.573427]\n",
            "[Epoch 47/50] [Batch 478/600] [D loss: 0.379306] [G loss: 2.039489]\n",
            "[Epoch 47/50] [Batch 479/600] [D loss: 0.324549] [G loss: 2.189677]\n",
            "[Epoch 47/50] [Batch 480/600] [D loss: 0.387574] [G loss: 1.835335]\n",
            "[Epoch 47/50] [Batch 481/600] [D loss: 0.372461] [G loss: 1.920017]\n",
            "[Epoch 47/50] [Batch 482/600] [D loss: 0.409616] [G loss: 1.681258]\n",
            "[Epoch 47/50] [Batch 483/600] [D loss: 0.404833] [G loss: 1.620744]\n",
            "[Epoch 47/50] [Batch 484/600] [D loss: 0.374823] [G loss: 1.736225]\n",
            "[Epoch 47/50] [Batch 485/600] [D loss: 0.459635] [G loss: 2.068009]\n",
            "[Epoch 47/50] [Batch 486/600] [D loss: 0.401035] [G loss: 1.996120]\n",
            "[Epoch 47/50] [Batch 487/600] [D loss: 0.412139] [G loss: 1.835338]\n",
            "[Epoch 47/50] [Batch 488/600] [D loss: 0.424925] [G loss: 1.626486]\n",
            "[Epoch 47/50] [Batch 489/600] [D loss: 0.505723] [G loss: 1.747738]\n",
            "[Epoch 47/50] [Batch 490/600] [D loss: 0.455498] [G loss: 1.880645]\n",
            "[Epoch 47/50] [Batch 491/600] [D loss: 0.368302] [G loss: 1.636656]\n",
            "[Epoch 47/50] [Batch 492/600] [D loss: 0.406121] [G loss: 1.756515]\n",
            "[Epoch 47/50] [Batch 493/600] [D loss: 0.422650] [G loss: 1.747253]\n",
            "[Epoch 47/50] [Batch 494/600] [D loss: 0.386501] [G loss: 1.904550]\n",
            "[Epoch 47/50] [Batch 495/600] [D loss: 0.383443] [G loss: 1.720382]\n",
            "[Epoch 47/50] [Batch 496/600] [D loss: 0.421319] [G loss: 1.813624]\n",
            "[Epoch 47/50] [Batch 497/600] [D loss: 0.404093] [G loss: 1.857290]\n",
            "[Epoch 47/50] [Batch 498/600] [D loss: 0.377863] [G loss: 1.691114]\n",
            "[Epoch 47/50] [Batch 499/600] [D loss: 0.458057] [G loss: 1.554587]\n",
            "[Epoch 47/50] [Batch 500/600] [D loss: 0.456623] [G loss: 2.079564]\n",
            "[Epoch 47/50] [Batch 501/600] [D loss: 0.483570] [G loss: 1.593344]\n",
            "[Epoch 47/50] [Batch 502/600] [D loss: 0.406033] [G loss: 1.814631]\n",
            "[Epoch 47/50] [Batch 503/600] [D loss: 0.497421] [G loss: 1.678951]\n",
            "[Epoch 47/50] [Batch 504/600] [D loss: 0.409451] [G loss: 1.586486]\n",
            "[Epoch 47/50] [Batch 505/600] [D loss: 0.410473] [G loss: 1.587006]\n",
            "[Epoch 47/50] [Batch 506/600] [D loss: 0.437253] [G loss: 1.668260]\n",
            "[Epoch 47/50] [Batch 507/600] [D loss: 0.506204] [G loss: 1.722540]\n",
            "[Epoch 47/50] [Batch 508/600] [D loss: 0.471816] [G loss: 1.729987]\n",
            "[Epoch 47/50] [Batch 509/600] [D loss: 0.406441] [G loss: 1.633801]\n",
            "[Epoch 47/50] [Batch 510/600] [D loss: 0.468908] [G loss: 1.621083]\n",
            "[Epoch 47/50] [Batch 511/600] [D loss: 0.420292] [G loss: 1.713553]\n",
            "[Epoch 47/50] [Batch 512/600] [D loss: 0.452087] [G loss: 1.582841]\n",
            "[Epoch 47/50] [Batch 513/600] [D loss: 0.367940] [G loss: 1.530573]\n",
            "[Epoch 47/50] [Batch 514/600] [D loss: 0.390202] [G loss: 1.486874]\n",
            "[Epoch 47/50] [Batch 515/600] [D loss: 0.347724] [G loss: 1.641724]\n",
            "[Epoch 47/50] [Batch 516/600] [D loss: 0.382275] [G loss: 1.732971]\n",
            "[Epoch 47/50] [Batch 517/600] [D loss: 0.402479] [G loss: 1.997425]\n",
            "[Epoch 47/50] [Batch 518/600] [D loss: 0.423624] [G loss: 1.731588]\n",
            "[Epoch 47/50] [Batch 519/600] [D loss: 0.487041] [G loss: 1.770996]\n",
            "[Epoch 47/50] [Batch 520/600] [D loss: 0.378477] [G loss: 1.829133]\n",
            "[Epoch 47/50] [Batch 521/600] [D loss: 0.402064] [G loss: 1.598726]\n",
            "[Epoch 47/50] [Batch 522/600] [D loss: 0.546992] [G loss: 1.733326]\n",
            "[Epoch 47/50] [Batch 523/600] [D loss: 0.377407] [G loss: 1.782891]\n",
            "[Epoch 47/50] [Batch 524/600] [D loss: 0.472042] [G loss: 1.636222]\n",
            "[Epoch 47/50] [Batch 525/600] [D loss: 0.394964] [G loss: 1.552358]\n",
            "[Epoch 47/50] [Batch 526/600] [D loss: 0.384348] [G loss: 1.709514]\n",
            "[Epoch 47/50] [Batch 527/600] [D loss: 0.432487] [G loss: 1.742034]\n",
            "[Epoch 47/50] [Batch 528/600] [D loss: 0.459180] [G loss: 1.782539]\n",
            "[Epoch 47/50] [Batch 529/600] [D loss: 0.453032] [G loss: 1.707757]\n",
            "[Epoch 47/50] [Batch 530/600] [D loss: 0.466787] [G loss: 1.647946]\n",
            "[Epoch 47/50] [Batch 531/600] [D loss: 0.403725] [G loss: 1.763929]\n",
            "[Epoch 47/50] [Batch 532/600] [D loss: 0.406542] [G loss: 1.570559]\n",
            "[Epoch 47/50] [Batch 533/600] [D loss: 0.401661] [G loss: 1.594636]\n",
            "[Epoch 47/50] [Batch 534/600] [D loss: 0.391552] [G loss: 1.732679]\n",
            "[Epoch 47/50] [Batch 535/600] [D loss: 0.373578] [G loss: 1.829940]\n",
            "[Epoch 47/50] [Batch 536/600] [D loss: 0.458328] [G loss: 1.699889]\n",
            "[Epoch 47/50] [Batch 537/600] [D loss: 0.461213] [G loss: 1.833276]\n",
            "[Epoch 47/50] [Batch 538/600] [D loss: 0.405536] [G loss: 1.456925]\n",
            "[Epoch 47/50] [Batch 539/600] [D loss: 0.467392] [G loss: 1.597081]\n",
            "[Epoch 47/50] [Batch 540/600] [D loss: 0.469476] [G loss: 1.696728]\n",
            "[Epoch 47/50] [Batch 541/600] [D loss: 0.393542] [G loss: 1.723375]\n",
            "[Epoch 47/50] [Batch 542/600] [D loss: 0.476417] [G loss: 1.678670]\n",
            "[Epoch 47/50] [Batch 543/600] [D loss: 0.405901] [G loss: 1.803640]\n",
            "[Epoch 47/50] [Batch 544/600] [D loss: 0.446671] [G loss: 1.750249]\n",
            "[Epoch 47/50] [Batch 545/600] [D loss: 0.449475] [G loss: 1.860424]\n",
            "[Epoch 47/50] [Batch 546/600] [D loss: 0.351381] [G loss: 1.729802]\n",
            "[Epoch 47/50] [Batch 547/600] [D loss: 0.372728] [G loss: 1.662448]\n",
            "[Epoch 47/50] [Batch 548/600] [D loss: 0.417493] [G loss: 1.672408]\n",
            "[Epoch 47/50] [Batch 549/600] [D loss: 0.477709] [G loss: 1.704146]\n",
            "[Epoch 47/50] [Batch 550/600] [D loss: 0.478509] [G loss: 1.783448]\n",
            "[Epoch 47/50] [Batch 551/600] [D loss: 0.363675] [G loss: 1.651208]\n",
            "[Epoch 47/50] [Batch 552/600] [D loss: 0.388336] [G loss: 1.861995]\n",
            "[Epoch 47/50] [Batch 553/600] [D loss: 0.456110] [G loss: 1.603040]\n",
            "[Epoch 47/50] [Batch 554/600] [D loss: 0.449092] [G loss: 1.719342]\n",
            "[Epoch 47/50] [Batch 555/600] [D loss: 0.427478] [G loss: 1.664500]\n",
            "[Epoch 47/50] [Batch 556/600] [D loss: 0.421604] [G loss: 1.529192]\n",
            "[Epoch 47/50] [Batch 557/600] [D loss: 0.378136] [G loss: 1.819471]\n",
            "[Epoch 47/50] [Batch 558/600] [D loss: 0.432405] [G loss: 1.765463]\n",
            "[Epoch 47/50] [Batch 559/600] [D loss: 0.416338] [G loss: 1.545367]\n",
            "[Epoch 47/50] [Batch 560/600] [D loss: 0.451109] [G loss: 1.706661]\n",
            "[Epoch 47/50] [Batch 561/600] [D loss: 0.421612] [G loss: 1.664006]\n",
            "[Epoch 47/50] [Batch 562/600] [D loss: 0.487716] [G loss: 1.612001]\n",
            "[Epoch 47/50] [Batch 563/600] [D loss: 0.462944] [G loss: 1.863766]\n",
            "[Epoch 47/50] [Batch 564/600] [D loss: 0.477050] [G loss: 1.746355]\n",
            "[Epoch 47/50] [Batch 565/600] [D loss: 0.375232] [G loss: 1.518771]\n",
            "[Epoch 47/50] [Batch 566/600] [D loss: 0.442632] [G loss: 1.682288]\n",
            "[Epoch 47/50] [Batch 567/600] [D loss: 0.398580] [G loss: 1.686083]\n",
            "[Epoch 47/50] [Batch 568/600] [D loss: 0.367570] [G loss: 1.841289]\n",
            "[Epoch 47/50] [Batch 569/600] [D loss: 0.371311] [G loss: 1.815441]\n",
            "[Epoch 47/50] [Batch 570/600] [D loss: 0.534072] [G loss: 1.716169]\n",
            "[Epoch 47/50] [Batch 571/600] [D loss: 0.426127] [G loss: 1.701443]\n",
            "[Epoch 47/50] [Batch 572/600] [D loss: 0.408550] [G loss: 1.653441]\n",
            "[Epoch 47/50] [Batch 573/600] [D loss: 0.414722] [G loss: 1.514121]\n",
            "[Epoch 47/50] [Batch 574/600] [D loss: 0.490048] [G loss: 1.708169]\n",
            "[Epoch 47/50] [Batch 575/600] [D loss: 0.364483] [G loss: 1.671923]\n",
            "[Epoch 47/50] [Batch 576/600] [D loss: 0.456422] [G loss: 1.739871]\n",
            "[Epoch 47/50] [Batch 577/600] [D loss: 0.430029] [G loss: 1.655861]\n",
            "[Epoch 47/50] [Batch 578/600] [D loss: 0.418716] [G loss: 1.659205]\n",
            "[Epoch 47/50] [Batch 579/600] [D loss: 0.466434] [G loss: 1.538958]\n",
            "[Epoch 47/50] [Batch 580/600] [D loss: 0.439970] [G loss: 1.777891]\n",
            "[Epoch 47/50] [Batch 581/600] [D loss: 0.402069] [G loss: 1.722362]\n",
            "[Epoch 47/50] [Batch 582/600] [D loss: 0.343870] [G loss: 1.887777]\n",
            "[Epoch 47/50] [Batch 583/600] [D loss: 0.405648] [G loss: 1.785155]\n",
            "[Epoch 47/50] [Batch 584/600] [D loss: 0.400920] [G loss: 1.865117]\n",
            "[Epoch 47/50] [Batch 585/600] [D loss: 0.410561] [G loss: 1.779518]\n",
            "[Epoch 47/50] [Batch 586/600] [D loss: 0.533715] [G loss: 1.500413]\n",
            "[Epoch 47/50] [Batch 587/600] [D loss: 0.445038] [G loss: 1.510401]\n",
            "[Epoch 47/50] [Batch 588/600] [D loss: 0.419262] [G loss: 1.584154]\n",
            "[Epoch 47/50] [Batch 589/600] [D loss: 0.404973] [G loss: 1.674507]\n",
            "[Epoch 47/50] [Batch 590/600] [D loss: 0.336559] [G loss: 1.837784]\n",
            "[Epoch 47/50] [Batch 591/600] [D loss: 0.338884] [G loss: 1.774717]\n",
            "[Epoch 47/50] [Batch 592/600] [D loss: 0.404621] [G loss: 1.793333]\n",
            "[Epoch 47/50] [Batch 593/600] [D loss: 0.415079] [G loss: 2.085415]\n",
            "[Epoch 47/50] [Batch 594/600] [D loss: 0.418595] [G loss: 1.672281]\n",
            "[Epoch 47/50] [Batch 595/600] [D loss: 0.358517] [G loss: 1.647679]\n",
            "[Epoch 47/50] [Batch 596/600] [D loss: 0.314809] [G loss: 1.763439]\n",
            "[Epoch 47/50] [Batch 597/600] [D loss: 0.376990] [G loss: 1.928016]\n",
            "[Epoch 47/50] [Batch 598/600] [D loss: 0.419079] [G loss: 1.876804]\n",
            "[Epoch 47/50] [Batch 599/600] [D loss: 0.334672] [G loss: 2.176535]\n",
            "[Epoch 48/50] [Batch 0/600] [D loss: 0.384740] [G loss: 2.058071]\n",
            "[Epoch 48/50] [Batch 1/600] [D loss: 0.411005] [G loss: 2.062542]\n",
            "[Epoch 48/50] [Batch 2/600] [D loss: 0.406275] [G loss: 1.933178]\n",
            "[Epoch 48/50] [Batch 3/600] [D loss: 0.479845] [G loss: 1.915714]\n",
            "[Epoch 48/50] [Batch 4/600] [D loss: 0.385262] [G loss: 1.762847]\n",
            "[Epoch 48/50] [Batch 5/600] [D loss: 0.451992] [G loss: 1.583283]\n",
            "[Epoch 48/50] [Batch 6/600] [D loss: 0.370309] [G loss: 1.846692]\n",
            "[Epoch 48/50] [Batch 7/600] [D loss: 0.454927] [G loss: 1.794064]\n",
            "[Epoch 48/50] [Batch 8/600] [D loss: 0.396177] [G loss: 1.628956]\n",
            "[Epoch 48/50] [Batch 9/600] [D loss: 0.326264] [G loss: 1.802046]\n",
            "[Epoch 48/50] [Batch 10/600] [D loss: 0.438065] [G loss: 1.886619]\n",
            "[Epoch 48/50] [Batch 11/600] [D loss: 0.381880] [G loss: 1.914961]\n",
            "[Epoch 48/50] [Batch 12/600] [D loss: 0.499317] [G loss: 1.612179]\n",
            "[Epoch 48/50] [Batch 13/600] [D loss: 0.374939] [G loss: 1.762356]\n",
            "[Epoch 48/50] [Batch 14/600] [D loss: 0.462119] [G loss: 1.584569]\n",
            "[Epoch 48/50] [Batch 15/600] [D loss: 0.383726] [G loss: 1.641478]\n",
            "[Epoch 48/50] [Batch 16/600] [D loss: 0.352294] [G loss: 1.938541]\n",
            "[Epoch 48/50] [Batch 17/600] [D loss: 0.403716] [G loss: 1.677595]\n",
            "[Epoch 48/50] [Batch 18/600] [D loss: 0.343382] [G loss: 1.719622]\n",
            "[Epoch 48/50] [Batch 19/600] [D loss: 0.521770] [G loss: 1.764123]\n",
            "[Epoch 48/50] [Batch 20/600] [D loss: 0.399287] [G loss: 1.745015]\n",
            "[Epoch 48/50] [Batch 21/600] [D loss: 0.412223] [G loss: 1.640486]\n",
            "[Epoch 48/50] [Batch 22/600] [D loss: 0.477693] [G loss: 1.841488]\n",
            "[Epoch 48/50] [Batch 23/600] [D loss: 0.407590] [G loss: 1.691038]\n",
            "[Epoch 48/50] [Batch 24/600] [D loss: 0.393012] [G loss: 1.746057]\n",
            "[Epoch 48/50] [Batch 25/600] [D loss: 0.351327] [G loss: 1.818718]\n",
            "[Epoch 48/50] [Batch 26/600] [D loss: 0.422335] [G loss: 1.494354]\n",
            "[Epoch 48/50] [Batch 27/600] [D loss: 0.412821] [G loss: 1.863834]\n",
            "[Epoch 48/50] [Batch 28/600] [D loss: 0.342229] [G loss: 2.099996]\n",
            "[Epoch 48/50] [Batch 29/600] [D loss: 0.418504] [G loss: 1.903111]\n",
            "[Epoch 48/50] [Batch 30/600] [D loss: 0.450864] [G loss: 1.747923]\n",
            "[Epoch 48/50] [Batch 31/600] [D loss: 0.384178] [G loss: 2.034687]\n",
            "[Epoch 48/50] [Batch 32/600] [D loss: 0.453385] [G loss: 1.694590]\n",
            "[Epoch 48/50] [Batch 33/600] [D loss: 0.407513] [G loss: 1.509517]\n",
            "[Epoch 48/50] [Batch 34/600] [D loss: 0.440745] [G loss: 1.642373]\n",
            "[Epoch 48/50] [Batch 35/600] [D loss: 0.458830] [G loss: 1.588240]\n",
            "[Epoch 48/50] [Batch 36/600] [D loss: 0.422702] [G loss: 1.737390]\n",
            "[Epoch 48/50] [Batch 37/600] [D loss: 0.460252] [G loss: 1.822411]\n",
            "[Epoch 48/50] [Batch 38/600] [D loss: 0.407990] [G loss: 1.858839]\n",
            "[Epoch 48/50] [Batch 39/600] [D loss: 0.433715] [G loss: 1.668426]\n",
            "[Epoch 48/50] [Batch 40/600] [D loss: 0.450717] [G loss: 1.523873]\n",
            "[Epoch 48/50] [Batch 41/600] [D loss: 0.446672] [G loss: 1.552826]\n",
            "[Epoch 48/50] [Batch 42/600] [D loss: 0.404580] [G loss: 1.728480]\n",
            "[Epoch 48/50] [Batch 43/600] [D loss: 0.450728] [G loss: 1.764523]\n",
            "[Epoch 48/50] [Batch 44/600] [D loss: 0.390805] [G loss: 1.811843]\n",
            "[Epoch 48/50] [Batch 45/600] [D loss: 0.414667] [G loss: 1.409974]\n",
            "[Epoch 48/50] [Batch 46/600] [D loss: 0.402823] [G loss: 1.873231]\n",
            "[Epoch 48/50] [Batch 47/600] [D loss: 0.337422] [G loss: 1.917160]\n",
            "[Epoch 48/50] [Batch 48/600] [D loss: 0.437173] [G loss: 1.858547]\n",
            "[Epoch 48/50] [Batch 49/600] [D loss: 0.399968] [G loss: 1.758654]\n",
            "[Epoch 48/50] [Batch 50/600] [D loss: 0.371844] [G loss: 1.977503]\n",
            "[Epoch 48/50] [Batch 51/600] [D loss: 0.364870] [G loss: 1.878393]\n",
            "[Epoch 48/50] [Batch 52/600] [D loss: 0.375269] [G loss: 2.123569]\n",
            "[Epoch 48/50] [Batch 53/600] [D loss: 0.407654] [G loss: 1.747293]\n",
            "[Epoch 48/50] [Batch 54/600] [D loss: 0.398920] [G loss: 1.799252]\n",
            "[Epoch 48/50] [Batch 55/600] [D loss: 0.434366] [G loss: 2.153980]\n",
            "[Epoch 48/50] [Batch 56/600] [D loss: 0.355142] [G loss: 1.881335]\n",
            "[Epoch 48/50] [Batch 57/600] [D loss: 0.508611] [G loss: 1.977356]\n",
            "[Epoch 48/50] [Batch 58/600] [D loss: 0.427998] [G loss: 1.968819]\n",
            "[Epoch 48/50] [Batch 59/600] [D loss: 0.358837] [G loss: 1.780303]\n",
            "[Epoch 48/50] [Batch 60/600] [D loss: 0.358428] [G loss: 1.800644]\n",
            "[Epoch 48/50] [Batch 61/600] [D loss: 0.321256] [G loss: 1.840834]\n",
            "[Epoch 48/50] [Batch 62/600] [D loss: 0.390894] [G loss: 1.915213]\n",
            "[Epoch 48/50] [Batch 63/600] [D loss: 0.421347] [G loss: 1.820492]\n",
            "[Epoch 48/50] [Batch 64/600] [D loss: 0.403303] [G loss: 1.796339]\n",
            "[Epoch 48/50] [Batch 65/600] [D loss: 0.404605] [G loss: 1.806621]\n",
            "[Epoch 48/50] [Batch 66/600] [D loss: 0.442679] [G loss: 1.828380]\n",
            "[Epoch 48/50] [Batch 67/600] [D loss: 0.438262] [G loss: 1.912929]\n",
            "[Epoch 48/50] [Batch 68/600] [D loss: 0.477606] [G loss: 2.032851]\n",
            "[Epoch 48/50] [Batch 69/600] [D loss: 0.430836] [G loss: 1.751957]\n",
            "[Epoch 48/50] [Batch 70/600] [D loss: 0.453702] [G loss: 1.635393]\n",
            "[Epoch 48/50] [Batch 71/600] [D loss: 0.426485] [G loss: 1.818239]\n",
            "[Epoch 48/50] [Batch 72/600] [D loss: 0.510100] [G loss: 1.512755]\n",
            "[Epoch 48/50] [Batch 73/600] [D loss: 0.429080] [G loss: 1.719466]\n",
            "[Epoch 48/50] [Batch 74/600] [D loss: 0.418982] [G loss: 1.895100]\n",
            "[Epoch 48/50] [Batch 75/600] [D loss: 0.427055] [G loss: 1.838421]\n",
            "[Epoch 48/50] [Batch 76/600] [D loss: 0.471830] [G loss: 1.595559]\n",
            "[Epoch 48/50] [Batch 77/600] [D loss: 0.382285] [G loss: 1.900140]\n",
            "[Epoch 48/50] [Batch 78/600] [D loss: 0.380873] [G loss: 1.879174]\n",
            "[Epoch 48/50] [Batch 79/600] [D loss: 0.420899] [G loss: 1.603716]\n",
            "[Epoch 48/50] [Batch 80/600] [D loss: 0.389658] [G loss: 1.751391]\n",
            "[Epoch 48/50] [Batch 81/600] [D loss: 0.414013] [G loss: 1.760305]\n",
            "[Epoch 48/50] [Batch 82/600] [D loss: 0.428160] [G loss: 1.571004]\n",
            "[Epoch 48/50] [Batch 83/600] [D loss: 0.383712] [G loss: 1.576146]\n",
            "[Epoch 48/50] [Batch 84/600] [D loss: 0.417557] [G loss: 1.706398]\n",
            "[Epoch 48/50] [Batch 85/600] [D loss: 0.364487] [G loss: 1.841772]\n",
            "[Epoch 48/50] [Batch 86/600] [D loss: 0.443023] [G loss: 1.734455]\n",
            "[Epoch 48/50] [Batch 87/600] [D loss: 0.455577] [G loss: 1.807622]\n",
            "[Epoch 48/50] [Batch 88/600] [D loss: 0.375575] [G loss: 1.633849]\n",
            "[Epoch 48/50] [Batch 89/600] [D loss: 0.457540] [G loss: 1.644830]\n",
            "[Epoch 48/50] [Batch 90/600] [D loss: 0.437321] [G loss: 1.663973]\n",
            "[Epoch 48/50] [Batch 91/600] [D loss: 0.454624] [G loss: 1.774132]\n",
            "[Epoch 48/50] [Batch 92/600] [D loss: 0.445071] [G loss: 1.922440]\n",
            "[Epoch 48/50] [Batch 93/600] [D loss: 0.373546] [G loss: 1.859544]\n",
            "[Epoch 48/50] [Batch 94/600] [D loss: 0.496292] [G loss: 1.651273]\n",
            "[Epoch 48/50] [Batch 95/600] [D loss: 0.409011] [G loss: 1.603786]\n",
            "[Epoch 48/50] [Batch 96/600] [D loss: 0.416297] [G loss: 1.704147]\n",
            "[Epoch 48/50] [Batch 97/600] [D loss: 0.401506] [G loss: 1.498336]\n",
            "[Epoch 48/50] [Batch 98/600] [D loss: 0.350729] [G loss: 1.942458]\n",
            "[Epoch 48/50] [Batch 99/600] [D loss: 0.432086] [G loss: 1.838688]\n",
            "[Epoch 48/50] [Batch 100/600] [D loss: 0.430510] [G loss: 1.794957]\n",
            "[Epoch 48/50] [Batch 101/600] [D loss: 0.470506] [G loss: 1.656213]\n",
            "[Epoch 48/50] [Batch 102/600] [D loss: 0.452676] [G loss: 1.801540]\n",
            "[Epoch 48/50] [Batch 103/600] [D loss: 0.401686] [G loss: 1.599170]\n",
            "[Epoch 48/50] [Batch 104/600] [D loss: 0.410451] [G loss: 1.605351]\n",
            "[Epoch 48/50] [Batch 105/600] [D loss: 0.372328] [G loss: 1.737981]\n",
            "[Epoch 48/50] [Batch 106/600] [D loss: 0.358802] [G loss: 1.748325]\n",
            "[Epoch 48/50] [Batch 107/600] [D loss: 0.472902] [G loss: 1.654135]\n",
            "[Epoch 48/50] [Batch 108/600] [D loss: 0.368665] [G loss: 1.865402]\n",
            "[Epoch 48/50] [Batch 109/600] [D loss: 0.359171] [G loss: 1.710844]\n",
            "[Epoch 48/50] [Batch 110/600] [D loss: 0.395309] [G loss: 1.737367]\n",
            "[Epoch 48/50] [Batch 111/600] [D loss: 0.376478] [G loss: 1.739221]\n",
            "[Epoch 48/50] [Batch 112/600] [D loss: 0.514971] [G loss: 1.649678]\n",
            "[Epoch 48/50] [Batch 113/600] [D loss: 0.400693] [G loss: 1.698219]\n",
            "[Epoch 48/50] [Batch 114/600] [D loss: 0.466377] [G loss: 1.773813]\n",
            "[Epoch 48/50] [Batch 115/600] [D loss: 0.478285] [G loss: 1.668032]\n",
            "[Epoch 48/50] [Batch 116/600] [D loss: 0.406394] [G loss: 1.728070]\n",
            "[Epoch 48/50] [Batch 117/600] [D loss: 0.386441] [G loss: 1.606286]\n",
            "[Epoch 48/50] [Batch 118/600] [D loss: 0.468598] [G loss: 1.780961]\n",
            "[Epoch 48/50] [Batch 119/600] [D loss: 0.478107] [G loss: 1.983769]\n",
            "[Epoch 48/50] [Batch 120/600] [D loss: 0.408983] [G loss: 1.804041]\n",
            "[Epoch 48/50] [Batch 121/600] [D loss: 0.380200] [G loss: 1.617195]\n",
            "[Epoch 48/50] [Batch 122/600] [D loss: 0.318781] [G loss: 1.624549]\n",
            "[Epoch 48/50] [Batch 123/600] [D loss: 0.463740] [G loss: 1.691916]\n",
            "[Epoch 48/50] [Batch 124/600] [D loss: 0.336004] [G loss: 1.942103]\n",
            "[Epoch 48/50] [Batch 125/600] [D loss: 0.411271] [G loss: 1.838809]\n",
            "[Epoch 48/50] [Batch 126/600] [D loss: 0.349084] [G loss: 1.757225]\n",
            "[Epoch 48/50] [Batch 127/600] [D loss: 0.498819] [G loss: 1.773792]\n",
            "[Epoch 48/50] [Batch 128/600] [D loss: 0.471433] [G loss: 2.022582]\n",
            "[Epoch 48/50] [Batch 129/600] [D loss: 0.454423] [G loss: 1.933374]\n",
            "[Epoch 48/50] [Batch 130/600] [D loss: 0.442458] [G loss: 1.702642]\n",
            "[Epoch 48/50] [Batch 131/600] [D loss: 0.359749] [G loss: 1.638776]\n",
            "[Epoch 48/50] [Batch 132/600] [D loss: 0.376111] [G loss: 1.525604]\n",
            "[Epoch 48/50] [Batch 133/600] [D loss: 0.376251] [G loss: 1.684808]\n",
            "[Epoch 48/50] [Batch 134/600] [D loss: 0.412978] [G loss: 1.892693]\n",
            "[Epoch 48/50] [Batch 135/600] [D loss: 0.365808] [G loss: 1.783533]\n",
            "[Epoch 48/50] [Batch 136/600] [D loss: 0.482392] [G loss: 1.875720]\n",
            "[Epoch 48/50] [Batch 137/600] [D loss: 0.507909] [G loss: 1.505650]\n",
            "[Epoch 48/50] [Batch 138/600] [D loss: 0.420287] [G loss: 1.646165]\n",
            "[Epoch 48/50] [Batch 139/600] [D loss: 0.366885] [G loss: 1.706820]\n",
            "[Epoch 48/50] [Batch 140/600] [D loss: 0.392047] [G loss: 1.776320]\n",
            "[Epoch 48/50] [Batch 141/600] [D loss: 0.346890] [G loss: 1.741523]\n",
            "[Epoch 48/50] [Batch 142/600] [D loss: 0.415351] [G loss: 1.678266]\n",
            "[Epoch 48/50] [Batch 143/600] [D loss: 0.372202] [G loss: 1.771137]\n",
            "[Epoch 48/50] [Batch 144/600] [D loss: 0.440591] [G loss: 1.793384]\n",
            "[Epoch 48/50] [Batch 145/600] [D loss: 0.402089] [G loss: 1.803008]\n",
            "[Epoch 48/50] [Batch 146/600] [D loss: 0.410190] [G loss: 1.841771]\n",
            "[Epoch 48/50] [Batch 147/600] [D loss: 0.410096] [G loss: 1.370298]\n",
            "[Epoch 48/50] [Batch 148/600] [D loss: 0.450110] [G loss: 1.637976]\n",
            "[Epoch 48/50] [Batch 149/600] [D loss: 0.389290] [G loss: 1.734741]\n",
            "[Epoch 48/50] [Batch 150/600] [D loss: 0.410959] [G loss: 2.001180]\n",
            "[Epoch 48/50] [Batch 151/600] [D loss: 0.442341] [G loss: 1.887017]\n",
            "[Epoch 48/50] [Batch 152/600] [D loss: 0.445931] [G loss: 1.759880]\n",
            "[Epoch 48/50] [Batch 153/600] [D loss: 0.462242] [G loss: 1.704234]\n",
            "[Epoch 48/50] [Batch 154/600] [D loss: 0.397592] [G loss: 1.694799]\n",
            "[Epoch 48/50] [Batch 155/600] [D loss: 0.341645] [G loss: 1.537025]\n",
            "[Epoch 48/50] [Batch 156/600] [D loss: 0.389015] [G loss: 1.869772]\n",
            "[Epoch 48/50] [Batch 157/600] [D loss: 0.386337] [G loss: 1.707513]\n",
            "[Epoch 48/50] [Batch 158/600] [D loss: 0.368667] [G loss: 1.790526]\n",
            "[Epoch 48/50] [Batch 159/600] [D loss: 0.471569] [G loss: 1.474412]\n",
            "[Epoch 48/50] [Batch 160/600] [D loss: 0.362410] [G loss: 1.454136]\n",
            "[Epoch 48/50] [Batch 161/600] [D loss: 0.429395] [G loss: 1.681463]\n",
            "[Epoch 48/50] [Batch 162/600] [D loss: 0.390142] [G loss: 1.752526]\n",
            "[Epoch 48/50] [Batch 163/600] [D loss: 0.396803] [G loss: 1.806403]\n",
            "[Epoch 48/50] [Batch 164/600] [D loss: 0.425965] [G loss: 1.994316]\n",
            "[Epoch 48/50] [Batch 165/600] [D loss: 0.340454] [G loss: 1.655506]\n",
            "[Epoch 48/50] [Batch 166/600] [D loss: 0.472601] [G loss: 1.693792]\n",
            "[Epoch 48/50] [Batch 167/600] [D loss: 0.414775] [G loss: 1.746349]\n",
            "[Epoch 48/50] [Batch 168/600] [D loss: 0.406946] [G loss: 1.904871]\n",
            "[Epoch 48/50] [Batch 169/600] [D loss: 0.432051] [G loss: 1.884150]\n",
            "[Epoch 48/50] [Batch 170/600] [D loss: 0.514471] [G loss: 1.797571]\n",
            "[Epoch 48/50] [Batch 171/600] [D loss: 0.432044] [G loss: 1.670229]\n",
            "[Epoch 48/50] [Batch 172/600] [D loss: 0.368835] [G loss: 1.615555]\n",
            "[Epoch 48/50] [Batch 173/600] [D loss: 0.418007] [G loss: 1.875693]\n",
            "[Epoch 48/50] [Batch 174/600] [D loss: 0.409538] [G loss: 1.565036]\n",
            "[Epoch 48/50] [Batch 175/600] [D loss: 0.409459] [G loss: 1.978854]\n",
            "[Epoch 48/50] [Batch 176/600] [D loss: 0.434837] [G loss: 1.684442]\n",
            "[Epoch 48/50] [Batch 177/600] [D loss: 0.458942] [G loss: 1.892029]\n",
            "[Epoch 48/50] [Batch 178/600] [D loss: 0.481587] [G loss: 1.757132]\n",
            "[Epoch 48/50] [Batch 179/600] [D loss: 0.483097] [G loss: 1.447253]\n",
            "[Epoch 48/50] [Batch 180/600] [D loss: 0.425038] [G loss: 1.959596]\n",
            "[Epoch 48/50] [Batch 181/600] [D loss: 0.387575] [G loss: 1.825593]\n",
            "[Epoch 48/50] [Batch 182/600] [D loss: 0.402334] [G loss: 1.650062]\n",
            "[Epoch 48/50] [Batch 183/600] [D loss: 0.456609] [G loss: 1.787794]\n",
            "[Epoch 48/50] [Batch 184/600] [D loss: 0.488212] [G loss: 1.679895]\n",
            "[Epoch 48/50] [Batch 185/600] [D loss: 0.410077] [G loss: 1.730747]\n",
            "[Epoch 48/50] [Batch 186/600] [D loss: 0.430442] [G loss: 1.497169]\n",
            "[Epoch 48/50] [Batch 187/600] [D loss: 0.439881] [G loss: 1.676285]\n",
            "[Epoch 48/50] [Batch 188/600] [D loss: 0.427647] [G loss: 1.659252]\n",
            "[Epoch 48/50] [Batch 189/600] [D loss: 0.390011] [G loss: 1.601076]\n",
            "[Epoch 48/50] [Batch 190/600] [D loss: 0.348016] [G loss: 1.896771]\n",
            "[Epoch 48/50] [Batch 191/600] [D loss: 0.499700] [G loss: 1.614717]\n",
            "[Epoch 48/50] [Batch 192/600] [D loss: 0.404893] [G loss: 1.859894]\n",
            "[Epoch 48/50] [Batch 193/600] [D loss: 0.425303] [G loss: 1.735252]\n",
            "[Epoch 48/50] [Batch 194/600] [D loss: 0.380311] [G loss: 1.647556]\n",
            "[Epoch 48/50] [Batch 195/600] [D loss: 0.426319] [G loss: 1.693633]\n",
            "[Epoch 48/50] [Batch 196/600] [D loss: 0.355245] [G loss: 1.759878]\n",
            "[Epoch 48/50] [Batch 197/600] [D loss: 0.412997] [G loss: 1.496541]\n",
            "[Epoch 48/50] [Batch 198/600] [D loss: 0.410363] [G loss: 1.823046]\n",
            "[Epoch 48/50] [Batch 199/600] [D loss: 0.369610] [G loss: 1.626613]\n",
            "[Epoch 48/50] [Batch 200/600] [D loss: 0.362689] [G loss: 1.662144]\n",
            "[Epoch 48/50] [Batch 201/600] [D loss: 0.358913] [G loss: 1.604584]\n",
            "[Epoch 48/50] [Batch 202/600] [D loss: 0.385730] [G loss: 1.792803]\n",
            "[Epoch 48/50] [Batch 203/600] [D loss: 0.417379] [G loss: 1.696136]\n",
            "[Epoch 48/50] [Batch 204/600] [D loss: 0.355150] [G loss: 1.688982]\n",
            "[Epoch 48/50] [Batch 205/600] [D loss: 0.388532] [G loss: 1.665654]\n",
            "[Epoch 48/50] [Batch 206/600] [D loss: 0.414677] [G loss: 2.040571]\n",
            "[Epoch 48/50] [Batch 207/600] [D loss: 0.391549] [G loss: 1.888789]\n",
            "[Epoch 48/50] [Batch 208/600] [D loss: 0.330340] [G loss: 2.012234]\n",
            "[Epoch 48/50] [Batch 209/600] [D loss: 0.362988] [G loss: 2.005811]\n",
            "[Epoch 48/50] [Batch 210/600] [D loss: 0.416816] [G loss: 1.915678]\n",
            "[Epoch 48/50] [Batch 211/600] [D loss: 0.439700] [G loss: 1.937149]\n",
            "[Epoch 48/50] [Batch 212/600] [D loss: 0.352340] [G loss: 1.976258]\n",
            "[Epoch 48/50] [Batch 213/600] [D loss: 0.423928] [G loss: 1.864324]\n",
            "[Epoch 48/50] [Batch 214/600] [D loss: 0.347202] [G loss: 1.744990]\n",
            "[Epoch 48/50] [Batch 215/600] [D loss: 0.377252] [G loss: 1.969043]\n",
            "[Epoch 48/50] [Batch 216/600] [D loss: 0.469901] [G loss: 1.753872]\n",
            "[Epoch 48/50] [Batch 217/600] [D loss: 0.427965] [G loss: 1.817065]\n",
            "[Epoch 48/50] [Batch 218/600] [D loss: 0.415788] [G loss: 1.884498]\n",
            "[Epoch 48/50] [Batch 219/600] [D loss: 0.379800] [G loss: 1.687423]\n",
            "[Epoch 48/50] [Batch 220/600] [D loss: 0.395929] [G loss: 1.554187]\n",
            "[Epoch 48/50] [Batch 221/600] [D loss: 0.395821] [G loss: 1.880971]\n",
            "[Epoch 48/50] [Batch 222/600] [D loss: 0.449785] [G loss: 1.796262]\n",
            "[Epoch 48/50] [Batch 223/600] [D loss: 0.463383] [G loss: 1.973644]\n",
            "[Epoch 48/50] [Batch 224/600] [D loss: 0.473961] [G loss: 1.655067]\n",
            "[Epoch 48/50] [Batch 225/600] [D loss: 0.467366] [G loss: 1.663426]\n",
            "[Epoch 48/50] [Batch 226/600] [D loss: 0.370340] [G loss: 1.636785]\n",
            "[Epoch 48/50] [Batch 227/600] [D loss: 0.391182] [G loss: 1.689003]\n",
            "[Epoch 48/50] [Batch 228/600] [D loss: 0.324228] [G loss: 1.783912]\n",
            "[Epoch 48/50] [Batch 229/600] [D loss: 0.327615] [G loss: 1.965496]\n",
            "[Epoch 48/50] [Batch 230/600] [D loss: 0.367478] [G loss: 1.953557]\n",
            "[Epoch 48/50] [Batch 231/600] [D loss: 0.355179] [G loss: 2.022081]\n",
            "[Epoch 48/50] [Batch 232/600] [D loss: 0.351999] [G loss: 1.723258]\n",
            "[Epoch 48/50] [Batch 233/600] [D loss: 0.430033] [G loss: 1.989092]\n",
            "[Epoch 48/50] [Batch 234/600] [D loss: 0.422475] [G loss: 1.796467]\n",
            "[Epoch 48/50] [Batch 235/600] [D loss: 0.412655] [G loss: 1.933820]\n",
            "[Epoch 48/50] [Batch 236/600] [D loss: 0.482447] [G loss: 2.045120]\n",
            "[Epoch 48/50] [Batch 237/600] [D loss: 0.472620] [G loss: 1.688031]\n",
            "[Epoch 48/50] [Batch 238/600] [D loss: 0.476822] [G loss: 1.723188]\n",
            "[Epoch 48/50] [Batch 239/600] [D loss: 0.426169] [G loss: 1.641112]\n",
            "[Epoch 48/50] [Batch 240/600] [D loss: 0.407915] [G loss: 1.408825]\n",
            "[Epoch 48/50] [Batch 241/600] [D loss: 0.424076] [G loss: 1.611044]\n",
            "[Epoch 48/50] [Batch 242/600] [D loss: 0.438225] [G loss: 1.584834]\n",
            "[Epoch 48/50] [Batch 243/600] [D loss: 0.413755] [G loss: 1.689774]\n",
            "[Epoch 48/50] [Batch 244/600] [D loss: 0.362970] [G loss: 1.525476]\n",
            "[Epoch 48/50] [Batch 245/600] [D loss: 0.433924] [G loss: 1.713712]\n",
            "[Epoch 48/50] [Batch 246/600] [D loss: 0.431691] [G loss: 1.600578]\n",
            "[Epoch 48/50] [Batch 247/600] [D loss: 0.404928] [G loss: 1.753745]\n",
            "[Epoch 48/50] [Batch 248/600] [D loss: 0.385709] [G loss: 1.731060]\n",
            "[Epoch 48/50] [Batch 249/600] [D loss: 0.408536] [G loss: 1.824477]\n",
            "[Epoch 48/50] [Batch 250/600] [D loss: 0.416536] [G loss: 1.901785]\n",
            "[Epoch 48/50] [Batch 251/600] [D loss: 0.412506] [G loss: 1.868893]\n",
            "[Epoch 48/50] [Batch 252/600] [D loss: 0.495178] [G loss: 1.798782]\n",
            "[Epoch 48/50] [Batch 253/600] [D loss: 0.386113] [G loss: 1.681234]\n",
            "[Epoch 48/50] [Batch 254/600] [D loss: 0.369054] [G loss: 1.716140]\n",
            "[Epoch 48/50] [Batch 255/600] [D loss: 0.397353] [G loss: 1.752095]\n",
            "[Epoch 48/50] [Batch 256/600] [D loss: 0.396691] [G loss: 1.720221]\n",
            "[Epoch 48/50] [Batch 257/600] [D loss: 0.417146] [G loss: 1.864259]\n",
            "[Epoch 48/50] [Batch 258/600] [D loss: 0.498847] [G loss: 1.801253]\n",
            "[Epoch 48/50] [Batch 259/600] [D loss: 0.512142] [G loss: 1.607488]\n",
            "[Epoch 48/50] [Batch 260/600] [D loss: 0.423997] [G loss: 1.799447]\n",
            "[Epoch 48/50] [Batch 261/600] [D loss: 0.427094] [G loss: 1.870324]\n",
            "[Epoch 48/50] [Batch 262/600] [D loss: 0.456154] [G loss: 1.836418]\n",
            "[Epoch 48/50] [Batch 263/600] [D loss: 0.524758] [G loss: 1.708171]\n",
            "[Epoch 48/50] [Batch 264/600] [D loss: 0.464001] [G loss: 1.467289]\n",
            "[Epoch 48/50] [Batch 265/600] [D loss: 0.458575] [G loss: 1.528387]\n",
            "[Epoch 48/50] [Batch 266/600] [D loss: 0.442178] [G loss: 1.563016]\n",
            "[Epoch 48/50] [Batch 267/600] [D loss: 0.496083] [G loss: 1.526428]\n",
            "[Epoch 48/50] [Batch 268/600] [D loss: 0.462456] [G loss: 1.478545]\n",
            "[Epoch 48/50] [Batch 269/600] [D loss: 0.400439] [G loss: 1.515717]\n",
            "[Epoch 48/50] [Batch 270/600] [D loss: 0.425238] [G loss: 1.568871]\n",
            "[Epoch 48/50] [Batch 271/600] [D loss: 0.352208] [G loss: 1.892114]\n",
            "[Epoch 48/50] [Batch 272/600] [D loss: 0.377726] [G loss: 1.691565]\n",
            "[Epoch 48/50] [Batch 273/600] [D loss: 0.394976] [G loss: 1.624397]\n",
            "[Epoch 48/50] [Batch 274/600] [D loss: 0.418674] [G loss: 1.706313]\n",
            "[Epoch 48/50] [Batch 275/600] [D loss: 0.381553] [G loss: 2.092984]\n",
            "[Epoch 48/50] [Batch 276/600] [D loss: 0.455850] [G loss: 1.879910]\n",
            "[Epoch 48/50] [Batch 277/600] [D loss: 0.380782] [G loss: 1.845396]\n",
            "[Epoch 48/50] [Batch 278/600] [D loss: 0.427082] [G loss: 1.946174]\n",
            "[Epoch 48/50] [Batch 279/600] [D loss: 0.440832] [G loss: 1.925246]\n",
            "[Epoch 48/50] [Batch 280/600] [D loss: 0.425294] [G loss: 1.573994]\n",
            "[Epoch 48/50] [Batch 281/600] [D loss: 0.379923] [G loss: 1.689277]\n",
            "[Epoch 48/50] [Batch 282/600] [D loss: 0.392925] [G loss: 1.842164]\n",
            "[Epoch 48/50] [Batch 283/600] [D loss: 0.409602] [G loss: 1.702801]\n",
            "[Epoch 48/50] [Batch 284/600] [D loss: 0.386921] [G loss: 1.744141]\n",
            "[Epoch 48/50] [Batch 285/600] [D loss: 0.391949] [G loss: 1.944223]\n",
            "[Epoch 48/50] [Batch 286/600] [D loss: 0.395230] [G loss: 1.885680]\n",
            "[Epoch 48/50] [Batch 287/600] [D loss: 0.435348] [G loss: 1.571689]\n",
            "[Epoch 48/50] [Batch 288/600] [D loss: 0.333796] [G loss: 1.613104]\n",
            "[Epoch 48/50] [Batch 289/600] [D loss: 0.459858] [G loss: 1.710666]\n",
            "[Epoch 48/50] [Batch 290/600] [D loss: 0.462769] [G loss: 1.757307]\n",
            "[Epoch 48/50] [Batch 291/600] [D loss: 0.487465] [G loss: 1.721261]\n",
            "[Epoch 48/50] [Batch 292/600] [D loss: 0.443778] [G loss: 1.586509]\n",
            "[Epoch 48/50] [Batch 293/600] [D loss: 0.391518] [G loss: 1.563427]\n",
            "[Epoch 48/50] [Batch 294/600] [D loss: 0.392320] [G loss: 1.440859]\n",
            "[Epoch 48/50] [Batch 295/600] [D loss: 0.436994] [G loss: 1.489703]\n",
            "[Epoch 48/50] [Batch 296/600] [D loss: 0.388403] [G loss: 1.753964]\n",
            "[Epoch 48/50] [Batch 297/600] [D loss: 0.471657] [G loss: 1.459890]\n",
            "[Epoch 48/50] [Batch 298/600] [D loss: 0.502525] [G loss: 1.774883]\n",
            "[Epoch 48/50] [Batch 299/600] [D loss: 0.468461] [G loss: 1.560441]\n",
            "[Epoch 48/50] [Batch 300/600] [D loss: 0.410020] [G loss: 1.474927]\n",
            "[Epoch 48/50] [Batch 301/600] [D loss: 0.323578] [G loss: 1.691063]\n",
            "[Epoch 48/50] [Batch 302/600] [D loss: 0.423775] [G loss: 1.747861]\n",
            "[Epoch 48/50] [Batch 303/600] [D loss: 0.450323] [G loss: 1.633245]\n",
            "[Epoch 48/50] [Batch 304/600] [D loss: 0.368017] [G loss: 1.473966]\n",
            "[Epoch 48/50] [Batch 305/600] [D loss: 0.466259] [G loss: 1.316410]\n",
            "[Epoch 48/50] [Batch 306/600] [D loss: 0.457834] [G loss: 1.608191]\n",
            "[Epoch 48/50] [Batch 307/600] [D loss: 0.378626] [G loss: 1.808811]\n",
            "[Epoch 48/50] [Batch 308/600] [D loss: 0.460948] [G loss: 1.688207]\n",
            "[Epoch 48/50] [Batch 309/600] [D loss: 0.439383] [G loss: 1.695691]\n",
            "[Epoch 48/50] [Batch 310/600] [D loss: 0.424240] [G loss: 1.778766]\n",
            "[Epoch 48/50] [Batch 311/600] [D loss: 0.358704] [G loss: 1.756434]\n",
            "[Epoch 48/50] [Batch 312/600] [D loss: 0.459020] [G loss: 1.863809]\n",
            "[Epoch 48/50] [Batch 313/600] [D loss: 0.460515] [G loss: 1.655510]\n",
            "[Epoch 48/50] [Batch 314/600] [D loss: 0.444823] [G loss: 1.985416]\n",
            "[Epoch 48/50] [Batch 315/600] [D loss: 0.431459] [G loss: 1.704152]\n",
            "[Epoch 48/50] [Batch 316/600] [D loss: 0.409662] [G loss: 1.615862]\n",
            "[Epoch 48/50] [Batch 317/600] [D loss: 0.498824] [G loss: 1.411716]\n",
            "[Epoch 48/50] [Batch 318/600] [D loss: 0.439374] [G loss: 1.625628]\n",
            "[Epoch 48/50] [Batch 319/600] [D loss: 0.387454] [G loss: 1.777711]\n",
            "[Epoch 48/50] [Batch 320/600] [D loss: 0.409049] [G loss: 1.630928]\n",
            "[Epoch 48/50] [Batch 321/600] [D loss: 0.393161] [G loss: 1.517735]\n",
            "[Epoch 48/50] [Batch 322/600] [D loss: 0.402847] [G loss: 1.583308]\n",
            "[Epoch 48/50] [Batch 323/600] [D loss: 0.485186] [G loss: 1.626897]\n",
            "[Epoch 48/50] [Batch 324/600] [D loss: 0.423687] [G loss: 1.664295]\n",
            "[Epoch 48/50] [Batch 325/600] [D loss: 0.427839] [G loss: 1.727479]\n",
            "[Epoch 48/50] [Batch 326/600] [D loss: 0.435553] [G loss: 1.629433]\n",
            "[Epoch 48/50] [Batch 327/600] [D loss: 0.438418] [G loss: 1.825874]\n",
            "[Epoch 48/50] [Batch 328/600] [D loss: 0.384453] [G loss: 1.795285]\n",
            "[Epoch 48/50] [Batch 329/600] [D loss: 0.359273] [G loss: 1.783450]\n",
            "[Epoch 48/50] [Batch 330/600] [D loss: 0.361226] [G loss: 2.020956]\n",
            "[Epoch 48/50] [Batch 331/600] [D loss: 0.374137] [G loss: 1.740119]\n",
            "[Epoch 48/50] [Batch 332/600] [D loss: 0.458115] [G loss: 1.919906]\n",
            "[Epoch 48/50] [Batch 333/600] [D loss: 0.369854] [G loss: 1.676745]\n",
            "[Epoch 48/50] [Batch 334/600] [D loss: 0.396787] [G loss: 1.890802]\n",
            "[Epoch 48/50] [Batch 335/600] [D loss: 0.418610] [G loss: 1.901157]\n",
            "[Epoch 48/50] [Batch 336/600] [D loss: 0.407792] [G loss: 2.218031]\n",
            "[Epoch 48/50] [Batch 337/600] [D loss: 0.505610] [G loss: 1.863041]\n",
            "[Epoch 48/50] [Batch 338/600] [D loss: 0.447737] [G loss: 1.524307]\n",
            "[Epoch 48/50] [Batch 339/600] [D loss: 0.403352] [G loss: 1.726677]\n",
            "[Epoch 48/50] [Batch 340/600] [D loss: 0.460932] [G loss: 1.626006]\n",
            "[Epoch 48/50] [Batch 341/600] [D loss: 0.344833] [G loss: 1.858546]\n",
            "[Epoch 48/50] [Batch 342/600] [D loss: 0.398826] [G loss: 1.855558]\n",
            "[Epoch 48/50] [Batch 343/600] [D loss: 0.450200] [G loss: 1.977202]\n",
            "[Epoch 48/50] [Batch 344/600] [D loss: 0.393792] [G loss: 1.762296]\n",
            "[Epoch 48/50] [Batch 345/600] [D loss: 0.412879] [G loss: 1.878365]\n",
            "[Epoch 48/50] [Batch 346/600] [D loss: 0.449793] [G loss: 1.516720]\n",
            "[Epoch 48/50] [Batch 347/600] [D loss: 0.387430] [G loss: 1.499471]\n",
            "[Epoch 48/50] [Batch 348/600] [D loss: 0.445579] [G loss: 1.599024]\n",
            "[Epoch 48/50] [Batch 349/600] [D loss: 0.364694] [G loss: 1.468284]\n",
            "[Epoch 48/50] [Batch 350/600] [D loss: 0.431450] [G loss: 1.508578]\n",
            "[Epoch 48/50] [Batch 351/600] [D loss: 0.439884] [G loss: 1.687876]\n",
            "[Epoch 48/50] [Batch 352/600] [D loss: 0.426652] [G loss: 1.825104]\n",
            "[Epoch 48/50] [Batch 353/600] [D loss: 0.405973] [G loss: 1.913981]\n",
            "[Epoch 48/50] [Batch 354/600] [D loss: 0.388302] [G loss: 1.925174]\n",
            "[Epoch 48/50] [Batch 355/600] [D loss: 0.396611] [G loss: 1.837748]\n",
            "[Epoch 48/50] [Batch 356/600] [D loss: 0.403942] [G loss: 1.869280]\n",
            "[Epoch 48/50] [Batch 357/600] [D loss: 0.398555] [G loss: 1.814155]\n",
            "[Epoch 48/50] [Batch 358/600] [D loss: 0.423483] [G loss: 1.900603]\n",
            "[Epoch 48/50] [Batch 359/600] [D loss: 0.447904] [G loss: 1.776590]\n",
            "[Epoch 48/50] [Batch 360/600] [D loss: 0.475042] [G loss: 1.812883]\n",
            "[Epoch 48/50] [Batch 361/600] [D loss: 0.383378] [G loss: 1.627876]\n",
            "[Epoch 48/50] [Batch 362/600] [D loss: 0.353154] [G loss: 1.703064]\n",
            "[Epoch 48/50] [Batch 363/600] [D loss: 0.456255] [G loss: 1.716234]\n",
            "[Epoch 48/50] [Batch 364/600] [D loss: 0.398427] [G loss: 1.743148]\n",
            "[Epoch 48/50] [Batch 365/600] [D loss: 0.408245] [G loss: 1.863684]\n",
            "[Epoch 48/50] [Batch 366/600] [D loss: 0.390391] [G loss: 1.946604]\n",
            "[Epoch 48/50] [Batch 367/600] [D loss: 0.386986] [G loss: 2.032244]\n",
            "[Epoch 48/50] [Batch 368/600] [D loss: 0.439562] [G loss: 1.965701]\n",
            "[Epoch 48/50] [Batch 369/600] [D loss: 0.374078] [G loss: 1.710538]\n",
            "[Epoch 48/50] [Batch 370/600] [D loss: 0.447442] [G loss: 1.514751]\n",
            "[Epoch 48/50] [Batch 371/600] [D loss: 0.378016] [G loss: 1.756272]\n",
            "[Epoch 48/50] [Batch 372/600] [D loss: 0.339602] [G loss: 1.739419]\n",
            "[Epoch 48/50] [Batch 373/600] [D loss: 0.405167] [G loss: 1.803545]\n",
            "[Epoch 48/50] [Batch 374/600] [D loss: 0.413938] [G loss: 2.129871]\n",
            "[Epoch 48/50] [Batch 375/600] [D loss: 0.494527] [G loss: 2.038936]\n",
            "[Epoch 48/50] [Batch 376/600] [D loss: 0.458435] [G loss: 1.739916]\n",
            "[Epoch 48/50] [Batch 377/600] [D loss: 0.454236] [G loss: 1.688715]\n",
            "[Epoch 48/50] [Batch 378/600] [D loss: 0.344266] [G loss: 1.838258]\n",
            "[Epoch 48/50] [Batch 379/600] [D loss: 0.386192] [G loss: 1.851088]\n",
            "[Epoch 48/50] [Batch 380/600] [D loss: 0.446168] [G loss: 2.007686]\n",
            "[Epoch 48/50] [Batch 381/600] [D loss: 0.335557] [G loss: 1.796977]\n",
            "[Epoch 48/50] [Batch 382/600] [D loss: 0.416226] [G loss: 1.516793]\n",
            "[Epoch 48/50] [Batch 383/600] [D loss: 0.395562] [G loss: 1.932445]\n",
            "[Epoch 48/50] [Batch 384/600] [D loss: 0.411371] [G loss: 1.564965]\n",
            "[Epoch 48/50] [Batch 385/600] [D loss: 0.379253] [G loss: 1.877860]\n",
            "[Epoch 48/50] [Batch 386/600] [D loss: 0.394257] [G loss: 2.012873]\n",
            "[Epoch 48/50] [Batch 387/600] [D loss: 0.424806] [G loss: 1.823264]\n",
            "[Epoch 48/50] [Batch 388/600] [D loss: 0.396194] [G loss: 1.648859]\n",
            "[Epoch 48/50] [Batch 389/600] [D loss: 0.386892] [G loss: 1.900028]\n",
            "[Epoch 48/50] [Batch 390/600] [D loss: 0.353233] [G loss: 1.703430]\n",
            "[Epoch 48/50] [Batch 391/600] [D loss: 0.488174] [G loss: 1.716382]\n",
            "[Epoch 48/50] [Batch 392/600] [D loss: 0.407737] [G loss: 1.765110]\n",
            "[Epoch 48/50] [Batch 393/600] [D loss: 0.448524] [G loss: 1.774676]\n",
            "[Epoch 48/50] [Batch 394/600] [D loss: 0.458782] [G loss: 1.667901]\n",
            "[Epoch 48/50] [Batch 395/600] [D loss: 0.433818] [G loss: 1.625339]\n",
            "[Epoch 48/50] [Batch 396/600] [D loss: 0.409855] [G loss: 1.559135]\n",
            "[Epoch 48/50] [Batch 397/600] [D loss: 0.461066] [G loss: 1.761077]\n",
            "[Epoch 48/50] [Batch 398/600] [D loss: 0.433575] [G loss: 1.826352]\n",
            "[Epoch 48/50] [Batch 399/600] [D loss: 0.486933] [G loss: 1.500980]\n",
            "[Epoch 48/50] [Batch 400/600] [D loss: 0.369951] [G loss: 1.683271]\n",
            "[Epoch 48/50] [Batch 401/600] [D loss: 0.447506] [G loss: 1.580053]\n",
            "[Epoch 48/50] [Batch 402/600] [D loss: 0.395183] [G loss: 1.835521]\n",
            "[Epoch 48/50] [Batch 403/600] [D loss: 0.441509] [G loss: 1.703065]\n",
            "[Epoch 48/50] [Batch 404/600] [D loss: 0.459602] [G loss: 1.892870]\n",
            "[Epoch 48/50] [Batch 405/600] [D loss: 0.417012] [G loss: 1.676451]\n",
            "[Epoch 48/50] [Batch 406/600] [D loss: 0.433219] [G loss: 1.578793]\n",
            "[Epoch 48/50] [Batch 407/600] [D loss: 0.370659] [G loss: 1.795737]\n",
            "[Epoch 48/50] [Batch 408/600] [D loss: 0.355534] [G loss: 1.717845]\n",
            "[Epoch 48/50] [Batch 409/600] [D loss: 0.462879] [G loss: 1.865680]\n",
            "[Epoch 48/50] [Batch 410/600] [D loss: 0.424087] [G loss: 1.758723]\n",
            "[Epoch 48/50] [Batch 411/600] [D loss: 0.409173] [G loss: 1.736617]\n",
            "[Epoch 48/50] [Batch 412/600] [D loss: 0.374396] [G loss: 1.801936]\n",
            "[Epoch 48/50] [Batch 413/600] [D loss: 0.396286] [G loss: 1.784734]\n",
            "[Epoch 48/50] [Batch 414/600] [D loss: 0.393099] [G loss: 1.685763]\n",
            "[Epoch 48/50] [Batch 415/600] [D loss: 0.460066] [G loss: 1.859559]\n",
            "[Epoch 48/50] [Batch 416/600] [D loss: 0.459927] [G loss: 1.894617]\n",
            "[Epoch 48/50] [Batch 417/600] [D loss: 0.533997] [G loss: 1.943787]\n",
            "[Epoch 48/50] [Batch 418/600] [D loss: 0.404477] [G loss: 1.665055]\n",
            "[Epoch 48/50] [Batch 419/600] [D loss: 0.472424] [G loss: 1.516259]\n",
            "[Epoch 48/50] [Batch 420/600] [D loss: 0.428633] [G loss: 1.888872]\n",
            "[Epoch 48/50] [Batch 421/600] [D loss: 0.403063] [G loss: 1.656743]\n",
            "[Epoch 48/50] [Batch 422/600] [D loss: 0.364155] [G loss: 1.675361]\n",
            "[Epoch 48/50] [Batch 423/600] [D loss: 0.378460] [G loss: 1.591006]\n",
            "[Epoch 48/50] [Batch 424/600] [D loss: 0.386000] [G loss: 1.743149]\n",
            "[Epoch 48/50] [Batch 425/600] [D loss: 0.489338] [G loss: 1.632214]\n",
            "[Epoch 48/50] [Batch 426/600] [D loss: 0.416817] [G loss: 1.571097]\n",
            "[Epoch 48/50] [Batch 427/600] [D loss: 0.399607] [G loss: 1.755815]\n",
            "[Epoch 48/50] [Batch 428/600] [D loss: 0.382211] [G loss: 1.902913]\n",
            "[Epoch 48/50] [Batch 429/600] [D loss: 0.429137] [G loss: 1.946429]\n",
            "[Epoch 48/50] [Batch 430/600] [D loss: 0.544563] [G loss: 1.839959]\n",
            "[Epoch 48/50] [Batch 431/600] [D loss: 0.443882] [G loss: 1.812452]\n",
            "[Epoch 48/50] [Batch 432/600] [D loss: 0.392696] [G loss: 1.859542]\n",
            "[Epoch 48/50] [Batch 433/600] [D loss: 0.415202] [G loss: 1.645129]\n",
            "[Epoch 48/50] [Batch 434/600] [D loss: 0.429868] [G loss: 1.538241]\n",
            "[Epoch 48/50] [Batch 435/600] [D loss: 0.398619] [G loss: 1.920898]\n",
            "[Epoch 48/50] [Batch 436/600] [D loss: 0.404024] [G loss: 1.820160]\n",
            "[Epoch 48/50] [Batch 437/600] [D loss: 0.476649] [G loss: 1.716758]\n",
            "[Epoch 48/50] [Batch 438/600] [D loss: 0.419266] [G loss: 1.815675]\n",
            "[Epoch 48/50] [Batch 439/600] [D loss: 0.416941] [G loss: 1.801012]\n",
            "[Epoch 48/50] [Batch 440/600] [D loss: 0.423409] [G loss: 1.791065]\n",
            "[Epoch 48/50] [Batch 441/600] [D loss: 0.388688] [G loss: 1.763463]\n",
            "[Epoch 48/50] [Batch 442/600] [D loss: 0.341691] [G loss: 1.640743]\n",
            "[Epoch 48/50] [Batch 443/600] [D loss: 0.384737] [G loss: 1.819607]\n",
            "[Epoch 48/50] [Batch 444/600] [D loss: 0.390980] [G loss: 1.982752]\n",
            "[Epoch 48/50] [Batch 445/600] [D loss: 0.395502] [G loss: 2.088575]\n",
            "[Epoch 48/50] [Batch 446/600] [D loss: 0.475971] [G loss: 1.883315]\n",
            "[Epoch 48/50] [Batch 447/600] [D loss: 0.435651] [G loss: 1.810888]\n",
            "[Epoch 48/50] [Batch 448/600] [D loss: 0.406695] [G loss: 1.635836]\n",
            "[Epoch 48/50] [Batch 449/600] [D loss: 0.465194] [G loss: 1.543235]\n",
            "[Epoch 48/50] [Batch 450/600] [D loss: 0.442396] [G loss: 1.704770]\n",
            "[Epoch 48/50] [Batch 451/600] [D loss: 0.456327] [G loss: 1.510471]\n",
            "[Epoch 48/50] [Batch 452/600] [D loss: 0.353289] [G loss: 1.760555]\n",
            "[Epoch 48/50] [Batch 453/600] [D loss: 0.368820] [G loss: 1.730750]\n",
            "[Epoch 48/50] [Batch 454/600] [D loss: 0.409958] [G loss: 1.657708]\n",
            "[Epoch 48/50] [Batch 455/600] [D loss: 0.391240] [G loss: 1.897537]\n",
            "[Epoch 48/50] [Batch 456/600] [D loss: 0.461158] [G loss: 1.711370]\n",
            "[Epoch 48/50] [Batch 457/600] [D loss: 0.466283] [G loss: 1.713063]\n",
            "[Epoch 48/50] [Batch 458/600] [D loss: 0.450557] [G loss: 1.655506]\n",
            "[Epoch 48/50] [Batch 459/600] [D loss: 0.516965] [G loss: 1.779094]\n",
            "[Epoch 48/50] [Batch 460/600] [D loss: 0.466262] [G loss: 1.684226]\n",
            "[Epoch 48/50] [Batch 461/600] [D loss: 0.482661] [G loss: 1.591520]\n",
            "[Epoch 48/50] [Batch 462/600] [D loss: 0.382432] [G loss: 1.845808]\n",
            "[Epoch 48/50] [Batch 463/600] [D loss: 0.445018] [G loss: 1.650138]\n",
            "[Epoch 48/50] [Batch 464/600] [D loss: 0.388139] [G loss: 1.862392]\n",
            "[Epoch 48/50] [Batch 465/600] [D loss: 0.396030] [G loss: 1.787491]\n",
            "[Epoch 48/50] [Batch 466/600] [D loss: 0.424788] [G loss: 1.691054]\n",
            "[Epoch 48/50] [Batch 467/600] [D loss: 0.388643] [G loss: 1.622921]\n",
            "[Epoch 48/50] [Batch 468/600] [D loss: 0.388103] [G loss: 1.571471]\n",
            "[Epoch 48/50] [Batch 469/600] [D loss: 0.430757] [G loss: 1.630051]\n",
            "[Epoch 48/50] [Batch 470/600] [D loss: 0.370489] [G loss: 1.631342]\n",
            "[Epoch 48/50] [Batch 471/600] [D loss: 0.473768] [G loss: 1.538795]\n",
            "[Epoch 48/50] [Batch 472/600] [D loss: 0.443651] [G loss: 1.656110]\n",
            "[Epoch 48/50] [Batch 473/600] [D loss: 0.505150] [G loss: 1.726433]\n",
            "[Epoch 48/50] [Batch 474/600] [D loss: 0.415742] [G loss: 1.871781]\n",
            "[Epoch 48/50] [Batch 475/600] [D loss: 0.363763] [G loss: 1.637908]\n",
            "[Epoch 48/50] [Batch 476/600] [D loss: 0.438700] [G loss: 1.605809]\n",
            "[Epoch 48/50] [Batch 477/600] [D loss: 0.317319] [G loss: 1.666078]\n",
            "[Epoch 48/50] [Batch 478/600] [D loss: 0.436710] [G loss: 1.721246]\n",
            "[Epoch 48/50] [Batch 479/600] [D loss: 0.361847] [G loss: 1.809749]\n",
            "[Epoch 48/50] [Batch 480/600] [D loss: 0.409528] [G loss: 1.919403]\n",
            "[Epoch 48/50] [Batch 481/600] [D loss: 0.383882] [G loss: 1.742941]\n",
            "[Epoch 48/50] [Batch 482/600] [D loss: 0.416447] [G loss: 1.769966]\n",
            "[Epoch 48/50] [Batch 483/600] [D loss: 0.413677] [G loss: 1.638022]\n",
            "[Epoch 48/50] [Batch 484/600] [D loss: 0.412659] [G loss: 1.627914]\n",
            "[Epoch 48/50] [Batch 485/600] [D loss: 0.410545] [G loss: 1.810142]\n",
            "[Epoch 48/50] [Batch 486/600] [D loss: 0.441302] [G loss: 1.553650]\n",
            "[Epoch 48/50] [Batch 487/600] [D loss: 0.423714] [G loss: 1.708435]\n",
            "[Epoch 48/50] [Batch 488/600] [D loss: 0.385193] [G loss: 1.931900]\n",
            "[Epoch 48/50] [Batch 489/600] [D loss: 0.500138] [G loss: 1.689184]\n",
            "[Epoch 48/50] [Batch 490/600] [D loss: 0.493217] [G loss: 1.601611]\n",
            "[Epoch 48/50] [Batch 491/600] [D loss: 0.442719] [G loss: 1.532311]\n",
            "[Epoch 48/50] [Batch 492/600] [D loss: 0.390021] [G loss: 1.693244]\n",
            "[Epoch 48/50] [Batch 493/600] [D loss: 0.418785] [G loss: 1.842967]\n",
            "[Epoch 48/50] [Batch 494/600] [D loss: 0.444436] [G loss: 1.910568]\n",
            "[Epoch 48/50] [Batch 495/600] [D loss: 0.379358] [G loss: 1.799487]\n",
            "[Epoch 48/50] [Batch 496/600] [D loss: 0.414441] [G loss: 1.772308]\n",
            "[Epoch 48/50] [Batch 497/600] [D loss: 0.339174] [G loss: 1.547269]\n",
            "[Epoch 48/50] [Batch 498/600] [D loss: 0.378946] [G loss: 1.779179]\n",
            "[Epoch 48/50] [Batch 499/600] [D loss: 0.405014] [G loss: 1.844592]\n",
            "[Epoch 48/50] [Batch 500/600] [D loss: 0.422304] [G loss: 1.705525]\n",
            "[Epoch 48/50] [Batch 501/600] [D loss: 0.424720] [G loss: 1.617946]\n",
            "[Epoch 48/50] [Batch 502/600] [D loss: 0.383035] [G loss: 1.864298]\n",
            "[Epoch 48/50] [Batch 503/600] [D loss: 0.478978] [G loss: 1.521820]\n",
            "[Epoch 48/50] [Batch 504/600] [D loss: 0.461311] [G loss: 1.484494]\n",
            "[Epoch 48/50] [Batch 505/600] [D loss: 0.435602] [G loss: 1.614156]\n",
            "[Epoch 48/50] [Batch 506/600] [D loss: 0.368544] [G loss: 1.751527]\n",
            "[Epoch 48/50] [Batch 507/600] [D loss: 0.506418] [G loss: 1.726787]\n",
            "[Epoch 48/50] [Batch 508/600] [D loss: 0.445839] [G loss: 1.568728]\n",
            "[Epoch 48/50] [Batch 509/600] [D loss: 0.399182] [G loss: 1.315931]\n",
            "[Epoch 48/50] [Batch 510/600] [D loss: 0.414910] [G loss: 1.560878]\n",
            "[Epoch 48/50] [Batch 511/600] [D loss: 0.409240] [G loss: 1.575511]\n",
            "[Epoch 48/50] [Batch 512/600] [D loss: 0.405572] [G loss: 1.586950]\n",
            "[Epoch 48/50] [Batch 513/600] [D loss: 0.393765] [G loss: 1.537905]\n",
            "[Epoch 48/50] [Batch 514/600] [D loss: 0.378505] [G loss: 1.822254]\n",
            "[Epoch 48/50] [Batch 515/600] [D loss: 0.367729] [G loss: 1.983356]\n",
            "[Epoch 48/50] [Batch 516/600] [D loss: 0.426407] [G loss: 1.683689]\n",
            "[Epoch 48/50] [Batch 517/600] [D loss: 0.423771] [G loss: 2.141365]\n",
            "[Epoch 48/50] [Batch 518/600] [D loss: 0.420155] [G loss: 2.005171]\n",
            "[Epoch 48/50] [Batch 519/600] [D loss: 0.431370] [G loss: 1.823137]\n",
            "[Epoch 48/50] [Batch 520/600] [D loss: 0.426252] [G loss: 1.644633]\n",
            "[Epoch 48/50] [Batch 521/600] [D loss: 0.399711] [G loss: 1.558551]\n",
            "[Epoch 48/50] [Batch 522/600] [D loss: 0.448005] [G loss: 1.662450]\n",
            "[Epoch 48/50] [Batch 523/600] [D loss: 0.394810] [G loss: 1.629879]\n",
            "[Epoch 48/50] [Batch 524/600] [D loss: 0.371861] [G loss: 1.855272]\n",
            "[Epoch 48/50] [Batch 525/600] [D loss: 0.380005] [G loss: 1.512375]\n",
            "[Epoch 48/50] [Batch 526/600] [D loss: 0.323479] [G loss: 1.972943]\n",
            "[Epoch 48/50] [Batch 527/600] [D loss: 0.403766] [G loss: 1.884799]\n",
            "[Epoch 48/50] [Batch 528/600] [D loss: 0.432915] [G loss: 1.928357]\n",
            "[Epoch 48/50] [Batch 529/600] [D loss: 0.471763] [G loss: 1.649062]\n",
            "[Epoch 48/50] [Batch 530/600] [D loss: 0.430750] [G loss: 1.602791]\n",
            "[Epoch 48/50] [Batch 531/600] [D loss: 0.445039] [G loss: 1.513261]\n",
            "[Epoch 48/50] [Batch 532/600] [D loss: 0.457971] [G loss: 1.678046]\n",
            "[Epoch 48/50] [Batch 533/600] [D loss: 0.423240] [G loss: 1.741236]\n",
            "[Epoch 48/50] [Batch 534/600] [D loss: 0.413142] [G loss: 1.842495]\n",
            "[Epoch 48/50] [Batch 535/600] [D loss: 0.416373] [G loss: 1.845063]\n",
            "[Epoch 48/50] [Batch 536/600] [D loss: 0.448864] [G loss: 1.622308]\n",
            "[Epoch 48/50] [Batch 537/600] [D loss: 0.494881] [G loss: 1.976786]\n",
            "[Epoch 48/50] [Batch 538/600] [D loss: 0.386228] [G loss: 1.533270]\n",
            "[Epoch 48/50] [Batch 539/600] [D loss: 0.452254] [G loss: 1.633353]\n",
            "[Epoch 48/50] [Batch 540/600] [D loss: 0.444541] [G loss: 1.635318]\n",
            "[Epoch 48/50] [Batch 541/600] [D loss: 0.441083] [G loss: 1.463113]\n",
            "[Epoch 48/50] [Batch 542/600] [D loss: 0.434322] [G loss: 1.748961]\n",
            "[Epoch 48/50] [Batch 543/600] [D loss: 0.399836] [G loss: 1.774012]\n",
            "[Epoch 48/50] [Batch 544/600] [D loss: 0.426530] [G loss: 1.689580]\n",
            "[Epoch 48/50] [Batch 545/600] [D loss: 0.520022] [G loss: 1.720450]\n",
            "[Epoch 48/50] [Batch 546/600] [D loss: 0.422099] [G loss: 1.596167]\n",
            "[Epoch 48/50] [Batch 547/600] [D loss: 0.416785] [G loss: 1.655251]\n",
            "[Epoch 48/50] [Batch 548/600] [D loss: 0.460496] [G loss: 1.540282]\n",
            "[Epoch 48/50] [Batch 549/600] [D loss: 0.431589] [G loss: 1.674242]\n",
            "[Epoch 48/50] [Batch 550/600] [D loss: 0.360419] [G loss: 1.645984]\n",
            "[Epoch 48/50] [Batch 551/600] [D loss: 0.392470] [G loss: 1.655996]\n",
            "[Epoch 48/50] [Batch 552/600] [D loss: 0.446848] [G loss: 1.814039]\n",
            "[Epoch 48/50] [Batch 553/600] [D loss: 0.371831] [G loss: 1.796417]\n",
            "[Epoch 48/50] [Batch 554/600] [D loss: 0.462815] [G loss: 1.684918]\n",
            "[Epoch 48/50] [Batch 555/600] [D loss: 0.352042] [G loss: 1.754141]\n",
            "[Epoch 48/50] [Batch 556/600] [D loss: 0.392895] [G loss: 1.669029]\n",
            "[Epoch 48/50] [Batch 557/600] [D loss: 0.401783] [G loss: 1.821785]\n",
            "[Epoch 48/50] [Batch 558/600] [D loss: 0.425878] [G loss: 1.905223]\n",
            "[Epoch 48/50] [Batch 559/600] [D loss: 0.368546] [G loss: 1.638506]\n",
            "[Epoch 48/50] [Batch 560/600] [D loss: 0.444462] [G loss: 1.690071]\n",
            "[Epoch 48/50] [Batch 561/600] [D loss: 0.424842] [G loss: 1.786063]\n",
            "[Epoch 48/50] [Batch 562/600] [D loss: 0.485979] [G loss: 1.747231]\n",
            "[Epoch 48/50] [Batch 563/600] [D loss: 0.494393] [G loss: 1.652079]\n",
            "[Epoch 48/50] [Batch 564/600] [D loss: 0.471590] [G loss: 1.663013]\n",
            "[Epoch 48/50] [Batch 565/600] [D loss: 0.368665] [G loss: 1.658332]\n",
            "[Epoch 48/50] [Batch 566/600] [D loss: 0.413317] [G loss: 1.532155]\n",
            "[Epoch 48/50] [Batch 567/600] [D loss: 0.412294] [G loss: 1.441166]\n",
            "[Epoch 48/50] [Batch 568/600] [D loss: 0.357396] [G loss: 1.785998]\n",
            "[Epoch 48/50] [Batch 569/600] [D loss: 0.363539] [G loss: 1.897874]\n",
            "[Epoch 48/50] [Batch 570/600] [D loss: 0.500725] [G loss: 1.651917]\n",
            "[Epoch 48/50] [Batch 571/600] [D loss: 0.454958] [G loss: 1.663674]\n",
            "[Epoch 48/50] [Batch 572/600] [D loss: 0.463543] [G loss: 1.781105]\n",
            "[Epoch 48/50] [Batch 573/600] [D loss: 0.393502] [G loss: 1.754899]\n",
            "[Epoch 48/50] [Batch 574/600] [D loss: 0.388133] [G loss: 1.929367]\n",
            "[Epoch 48/50] [Batch 575/600] [D loss: 0.385216] [G loss: 1.676905]\n",
            "[Epoch 48/50] [Batch 576/600] [D loss: 0.410353] [G loss: 1.744997]\n",
            "[Epoch 48/50] [Batch 577/600] [D loss: 0.456791] [G loss: 1.715758]\n",
            "[Epoch 48/50] [Batch 578/600] [D loss: 0.417097] [G loss: 1.821959]\n",
            "[Epoch 48/50] [Batch 579/600] [D loss: 0.392904] [G loss: 1.854678]\n",
            "[Epoch 48/50] [Batch 580/600] [D loss: 0.418173] [G loss: 2.202428]\n",
            "[Epoch 48/50] [Batch 581/600] [D loss: 0.383425] [G loss: 1.927255]\n",
            "[Epoch 48/50] [Batch 582/600] [D loss: 0.335728] [G loss: 2.010745]\n",
            "[Epoch 48/50] [Batch 583/600] [D loss: 0.402820] [G loss: 1.955545]\n",
            "[Epoch 48/50] [Batch 584/600] [D loss: 0.407245] [G loss: 1.998090]\n",
            "[Epoch 48/50] [Batch 585/600] [D loss: 0.343299] [G loss: 1.973197]\n",
            "[Epoch 48/50] [Batch 586/600] [D loss: 0.485500] [G loss: 1.919686]\n",
            "[Epoch 48/50] [Batch 587/600] [D loss: 0.467190] [G loss: 1.777972]\n",
            "[Epoch 48/50] [Batch 588/600] [D loss: 0.387484] [G loss: 1.809348]\n",
            "[Epoch 48/50] [Batch 589/600] [D loss: 0.354867] [G loss: 1.856737]\n",
            "[Epoch 48/50] [Batch 590/600] [D loss: 0.381825] [G loss: 1.966851]\n",
            "[Epoch 48/50] [Batch 591/600] [D loss: 0.365155] [G loss: 1.738941]\n",
            "[Epoch 48/50] [Batch 592/600] [D loss: 0.354803] [G loss: 1.982992]\n",
            "[Epoch 48/50] [Batch 593/600] [D loss: 0.406013] [G loss: 1.986666]\n",
            "[Epoch 48/50] [Batch 594/600] [D loss: 0.419893] [G loss: 1.758649]\n",
            "[Epoch 48/50] [Batch 595/600] [D loss: 0.381928] [G loss: 1.544229]\n",
            "[Epoch 48/50] [Batch 596/600] [D loss: 0.387139] [G loss: 1.593643]\n",
            "[Epoch 48/50] [Batch 597/600] [D loss: 0.364308] [G loss: 2.018600]\n",
            "[Epoch 48/50] [Batch 598/600] [D loss: 0.362572] [G loss: 2.016540]\n",
            "[Epoch 48/50] [Batch 599/600] [D loss: 0.395975] [G loss: 1.960816]\n",
            "[Epoch 49/50] [Batch 0/600] [D loss: 0.369344] [G loss: 2.227385]\n",
            "[Epoch 49/50] [Batch 1/600] [D loss: 0.322330] [G loss: 2.117974]\n",
            "[Epoch 49/50] [Batch 2/600] [D loss: 0.440120] [G loss: 2.050423]\n",
            "[Epoch 49/50] [Batch 3/600] [D loss: 0.446638] [G loss: 2.022473]\n",
            "[Epoch 49/50] [Batch 4/600] [D loss: 0.407432] [G loss: 1.779493]\n",
            "[Epoch 49/50] [Batch 5/600] [D loss: 0.402629] [G loss: 1.870380]\n",
            "[Epoch 49/50] [Batch 6/600] [D loss: 0.343679] [G loss: 1.690985]\n",
            "[Epoch 49/50] [Batch 7/600] [D loss: 0.390132] [G loss: 2.063720]\n",
            "[Epoch 49/50] [Batch 8/600] [D loss: 0.310073] [G loss: 1.799860]\n",
            "[Epoch 49/50] [Batch 9/600] [D loss: 0.426722] [G loss: 1.887005]\n",
            "[Epoch 49/50] [Batch 10/600] [D loss: 0.454988] [G loss: 1.799125]\n",
            "[Epoch 49/50] [Batch 11/600] [D loss: 0.469518] [G loss: 1.960351]\n",
            "[Epoch 49/50] [Batch 12/600] [D loss: 0.431197] [G loss: 2.073611]\n",
            "[Epoch 49/50] [Batch 13/600] [D loss: 0.374214] [G loss: 1.685436]\n",
            "[Epoch 49/50] [Batch 14/600] [D loss: 0.374259] [G loss: 1.527573]\n",
            "[Epoch 49/50] [Batch 15/600] [D loss: 0.401222] [G loss: 1.544474]\n",
            "[Epoch 49/50] [Batch 16/600] [D loss: 0.397732] [G loss: 1.655296]\n",
            "[Epoch 49/50] [Batch 17/600] [D loss: 0.372749] [G loss: 1.654454]\n",
            "[Epoch 49/50] [Batch 18/600] [D loss: 0.400033] [G loss: 1.933417]\n",
            "[Epoch 49/50] [Batch 19/600] [D loss: 0.471417] [G loss: 1.855807]\n",
            "[Epoch 49/50] [Batch 20/600] [D loss: 0.398072] [G loss: 1.953109]\n",
            "[Epoch 49/50] [Batch 21/600] [D loss: 0.419708] [G loss: 1.854003]\n",
            "[Epoch 49/50] [Batch 22/600] [D loss: 0.341953] [G loss: 1.888979]\n",
            "[Epoch 49/50] [Batch 23/600] [D loss: 0.394464] [G loss: 1.691473]\n",
            "[Epoch 49/50] [Batch 24/600] [D loss: 0.404270] [G loss: 1.662168]\n",
            "[Epoch 49/50] [Batch 25/600] [D loss: 0.400515] [G loss: 1.887275]\n",
            "[Epoch 49/50] [Batch 26/600] [D loss: 0.384296] [G loss: 1.987803]\n",
            "[Epoch 49/50] [Batch 27/600] [D loss: 0.433875] [G loss: 1.999239]\n",
            "[Epoch 49/50] [Batch 28/600] [D loss: 0.381634] [G loss: 1.889889]\n",
            "[Epoch 49/50] [Batch 29/600] [D loss: 0.480980] [G loss: 1.820256]\n",
            "[Epoch 49/50] [Batch 30/600] [D loss: 0.388462] [G loss: 1.683323]\n",
            "[Epoch 49/50] [Batch 31/600] [D loss: 0.390930] [G loss: 1.813229]\n",
            "[Epoch 49/50] [Batch 32/600] [D loss: 0.430811] [G loss: 1.873471]\n",
            "[Epoch 49/50] [Batch 33/600] [D loss: 0.429518] [G loss: 2.004255]\n",
            "[Epoch 49/50] [Batch 34/600] [D loss: 0.451424] [G loss: 1.815864]\n",
            "[Epoch 49/50] [Batch 35/600] [D loss: 0.437457] [G loss: 1.704914]\n",
            "[Epoch 49/50] [Batch 36/600] [D loss: 0.384226] [G loss: 1.844388]\n",
            "[Epoch 49/50] [Batch 37/600] [D loss: 0.395686] [G loss: 1.844090]\n",
            "[Epoch 49/50] [Batch 38/600] [D loss: 0.412051] [G loss: 2.000993]\n",
            "[Epoch 49/50] [Batch 39/600] [D loss: 0.363788] [G loss: 2.059642]\n",
            "[Epoch 49/50] [Batch 40/600] [D loss: 0.439507] [G loss: 1.843939]\n",
            "[Epoch 49/50] [Batch 41/600] [D loss: 0.401370] [G loss: 1.976164]\n",
            "[Epoch 49/50] [Batch 42/600] [D loss: 0.373497] [G loss: 1.956246]\n",
            "[Epoch 49/50] [Batch 43/600] [D loss: 0.440859] [G loss: 1.892613]\n",
            "[Epoch 49/50] [Batch 44/600] [D loss: 0.374473] [G loss: 1.910923]\n",
            "[Epoch 49/50] [Batch 45/600] [D loss: 0.347724] [G loss: 1.905405]\n",
            "[Epoch 49/50] [Batch 46/600] [D loss: 0.348226] [G loss: 1.853538]\n",
            "[Epoch 49/50] [Batch 47/600] [D loss: 0.339626] [G loss: 1.937104]\n",
            "[Epoch 49/50] [Batch 48/600] [D loss: 0.409016] [G loss: 1.942253]\n",
            "[Epoch 49/50] [Batch 49/600] [D loss: 0.357077] [G loss: 2.078895]\n",
            "[Epoch 49/50] [Batch 50/600] [D loss: 0.397852] [G loss: 1.669397]\n",
            "[Epoch 49/50] [Batch 51/600] [D loss: 0.383594] [G loss: 2.041018]\n",
            "[Epoch 49/50] [Batch 52/600] [D loss: 0.400295] [G loss: 1.884933]\n",
            "[Epoch 49/50] [Batch 53/600] [D loss: 0.357501] [G loss: 2.056152]\n",
            "[Epoch 49/50] [Batch 54/600] [D loss: 0.348806] [G loss: 1.804302]\n",
            "[Epoch 49/50] [Batch 55/600] [D loss: 0.459233] [G loss: 1.848259]\n",
            "[Epoch 49/50] [Batch 56/600] [D loss: 0.383169] [G loss: 2.165962]\n",
            "[Epoch 49/50] [Batch 57/600] [D loss: 0.438522] [G loss: 2.165131]\n",
            "[Epoch 49/50] [Batch 58/600] [D loss: 0.414242] [G loss: 1.774160]\n",
            "[Epoch 49/50] [Batch 59/600] [D loss: 0.421199] [G loss: 1.575632]\n",
            "[Epoch 49/50] [Batch 60/600] [D loss: 0.362960] [G loss: 1.606307]\n",
            "[Epoch 49/50] [Batch 61/600] [D loss: 0.445505] [G loss: 1.701120]\n",
            "[Epoch 49/50] [Batch 62/600] [D loss: 0.389964] [G loss: 1.936381]\n",
            "[Epoch 49/50] [Batch 63/600] [D loss: 0.323461] [G loss: 1.998822]\n",
            "[Epoch 49/50] [Batch 64/600] [D loss: 0.347105] [G loss: 1.781090]\n",
            "[Epoch 49/50] [Batch 65/600] [D loss: 0.369845] [G loss: 1.726100]\n",
            "[Epoch 49/50] [Batch 66/600] [D loss: 0.452245] [G loss: 1.819659]\n",
            "[Epoch 49/50] [Batch 67/600] [D loss: 0.495839] [G loss: 2.062326]\n",
            "[Epoch 49/50] [Batch 68/600] [D loss: 0.431346] [G loss: 1.746992]\n",
            "[Epoch 49/50] [Batch 69/600] [D loss: 0.403345] [G loss: 1.864504]\n",
            "[Epoch 49/50] [Batch 70/600] [D loss: 0.411254] [G loss: 1.808568]\n",
            "[Epoch 49/50] [Batch 71/600] [D loss: 0.435223] [G loss: 1.771275]\n",
            "[Epoch 49/50] [Batch 72/600] [D loss: 0.461461] [G loss: 1.767150]\n",
            "[Epoch 49/50] [Batch 73/600] [D loss: 0.470262] [G loss: 1.703690]\n",
            "[Epoch 49/50] [Batch 74/600] [D loss: 0.465895] [G loss: 1.696308]\n",
            "[Epoch 49/50] [Batch 75/600] [D loss: 0.386997] [G loss: 1.663924]\n",
            "[Epoch 49/50] [Batch 76/600] [D loss: 0.398098] [G loss: 1.656336]\n",
            "[Epoch 49/50] [Batch 77/600] [D loss: 0.416411] [G loss: 1.836909]\n",
            "[Epoch 49/50] [Batch 78/600] [D loss: 0.313560] [G loss: 1.941354]\n",
            "[Epoch 49/50] [Batch 79/600] [D loss: 0.345161] [G loss: 2.043545]\n",
            "[Epoch 49/50] [Batch 80/600] [D loss: 0.344636] [G loss: 1.721734]\n",
            "[Epoch 49/50] [Batch 81/600] [D loss: 0.433373] [G loss: 1.955709]\n",
            "[Epoch 49/50] [Batch 82/600] [D loss: 0.368538] [G loss: 1.681148]\n",
            "[Epoch 49/50] [Batch 83/600] [D loss: 0.405783] [G loss: 1.837761]\n",
            "[Epoch 49/50] [Batch 84/600] [D loss: 0.402334] [G loss: 2.083028]\n",
            "[Epoch 49/50] [Batch 85/600] [D loss: 0.403595] [G loss: 1.996835]\n",
            "[Epoch 49/50] [Batch 86/600] [D loss: 0.397574] [G loss: 1.701340]\n",
            "[Epoch 49/50] [Batch 87/600] [D loss: 0.501075] [G loss: 1.681876]\n",
            "[Epoch 49/50] [Batch 88/600] [D loss: 0.397915] [G loss: 1.599716]\n",
            "[Epoch 49/50] [Batch 89/600] [D loss: 0.372773] [G loss: 1.664770]\n",
            "[Epoch 49/50] [Batch 90/600] [D loss: 0.509194] [G loss: 1.637929]\n",
            "[Epoch 49/50] [Batch 91/600] [D loss: 0.484568] [G loss: 1.495388]\n",
            "[Epoch 49/50] [Batch 92/600] [D loss: 0.491596] [G loss: 1.515298]\n",
            "[Epoch 49/50] [Batch 93/600] [D loss: 0.427514] [G loss: 1.526771]\n",
            "[Epoch 49/50] [Batch 94/600] [D loss: 0.423230] [G loss: 1.737858]\n",
            "[Epoch 49/50] [Batch 95/600] [D loss: 0.420577] [G loss: 1.639113]\n",
            "[Epoch 49/50] [Batch 96/600] [D loss: 0.412844] [G loss: 1.512035]\n",
            "[Epoch 49/50] [Batch 97/600] [D loss: 0.429257] [G loss: 1.835526]\n",
            "[Epoch 49/50] [Batch 98/600] [D loss: 0.385101] [G loss: 1.600487]\n",
            "[Epoch 49/50] [Batch 99/600] [D loss: 0.386181] [G loss: 1.675575]\n",
            "[Epoch 49/50] [Batch 100/600] [D loss: 0.381481] [G loss: 1.701132]\n",
            "[Epoch 49/50] [Batch 101/600] [D loss: 0.475151] [G loss: 1.679561]\n",
            "[Epoch 49/50] [Batch 102/600] [D loss: 0.415000] [G loss: 1.973843]\n",
            "[Epoch 49/50] [Batch 103/600] [D loss: 0.346417] [G loss: 1.669513]\n",
            "[Epoch 49/50] [Batch 104/600] [D loss: 0.398059] [G loss: 1.689427]\n",
            "[Epoch 49/50] [Batch 105/600] [D loss: 0.406046] [G loss: 1.507312]\n",
            "[Epoch 49/50] [Batch 106/600] [D loss: 0.444571] [G loss: 1.594957]\n",
            "[Epoch 49/50] [Batch 107/600] [D loss: 0.438766] [G loss: 1.819938]\n",
            "[Epoch 49/50] [Batch 108/600] [D loss: 0.401140] [G loss: 2.056166]\n",
            "[Epoch 49/50] [Batch 109/600] [D loss: 0.373725] [G loss: 1.711272]\n",
            "[Epoch 49/50] [Batch 110/600] [D loss: 0.441432] [G loss: 1.862413]\n",
            "[Epoch 49/50] [Batch 111/600] [D loss: 0.404553] [G loss: 1.701554]\n",
            "[Epoch 49/50] [Batch 112/600] [D loss: 0.465685] [G loss: 1.695393]\n",
            "[Epoch 49/50] [Batch 113/600] [D loss: 0.406592] [G loss: 1.588741]\n",
            "[Epoch 49/50] [Batch 114/600] [D loss: 0.491004] [G loss: 1.764961]\n",
            "[Epoch 49/50] [Batch 115/600] [D loss: 0.455175] [G loss: 1.644894]\n",
            "[Epoch 49/50] [Batch 116/600] [D loss: 0.426962] [G loss: 1.617362]\n",
            "[Epoch 49/50] [Batch 117/600] [D loss: 0.470182] [G loss: 1.706450]\n",
            "[Epoch 49/50] [Batch 118/600] [D loss: 0.473791] [G loss: 1.618111]\n",
            "[Epoch 49/50] [Batch 119/600] [D loss: 0.505011] [G loss: 1.594282]\n",
            "[Epoch 49/50] [Batch 120/600] [D loss: 0.405056] [G loss: 1.606027]\n",
            "[Epoch 49/50] [Batch 121/600] [D loss: 0.443465] [G loss: 1.588668]\n",
            "[Epoch 49/50] [Batch 122/600] [D loss: 0.329196] [G loss: 1.479719]\n",
            "[Epoch 49/50] [Batch 123/600] [D loss: 0.384700] [G loss: 1.785867]\n",
            "[Epoch 49/50] [Batch 124/600] [D loss: 0.365797] [G loss: 1.662101]\n",
            "[Epoch 49/50] [Batch 125/600] [D loss: 0.368892] [G loss: 1.570595]\n",
            "[Epoch 49/50] [Batch 126/600] [D loss: 0.437642] [G loss: 1.822048]\n",
            "[Epoch 49/50] [Batch 127/600] [D loss: 0.489007] [G loss: 1.777835]\n",
            "[Epoch 49/50] [Batch 128/600] [D loss: 0.537602] [G loss: 1.729832]\n",
            "[Epoch 49/50] [Batch 129/600] [D loss: 0.404981] [G loss: 1.942008]\n",
            "[Epoch 49/50] [Batch 130/600] [D loss: 0.393398] [G loss: 2.028024]\n",
            "[Epoch 49/50] [Batch 131/600] [D loss: 0.407951] [G loss: 1.642307]\n",
            "[Epoch 49/50] [Batch 132/600] [D loss: 0.414418] [G loss: 1.514931]\n",
            "[Epoch 49/50] [Batch 133/600] [D loss: 0.359466] [G loss: 1.661142]\n",
            "[Epoch 49/50] [Batch 134/600] [D loss: 0.451690] [G loss: 1.644249]\n",
            "[Epoch 49/50] [Batch 135/600] [D loss: 0.374239] [G loss: 1.754121]\n",
            "[Epoch 49/50] [Batch 136/600] [D loss: 0.452585] [G loss: 1.808517]\n",
            "[Epoch 49/50] [Batch 137/600] [D loss: 0.505736] [G loss: 1.610496]\n",
            "[Epoch 49/50] [Batch 138/600] [D loss: 0.438741] [G loss: 1.601224]\n",
            "[Epoch 49/50] [Batch 139/600] [D loss: 0.384478] [G loss: 1.741929]\n",
            "[Epoch 49/50] [Batch 140/600] [D loss: 0.437463] [G loss: 1.927199]\n",
            "[Epoch 49/50] [Batch 141/600] [D loss: 0.324252] [G loss: 1.985387]\n",
            "[Epoch 49/50] [Batch 142/600] [D loss: 0.369530] [G loss: 1.796997]\n",
            "[Epoch 49/50] [Batch 143/600] [D loss: 0.401326] [G loss: 1.649221]\n",
            "[Epoch 49/50] [Batch 144/600] [D loss: 0.394975] [G loss: 1.622829]\n",
            "[Epoch 49/50] [Batch 145/600] [D loss: 0.489773] [G loss: 1.844919]\n",
            "[Epoch 49/50] [Batch 146/600] [D loss: 0.422902] [G loss: 1.892009]\n",
            "[Epoch 49/50] [Batch 147/600] [D loss: 0.437671] [G loss: 1.705051]\n",
            "[Epoch 49/50] [Batch 148/600] [D loss: 0.373299] [G loss: 1.821971]\n",
            "[Epoch 49/50] [Batch 149/600] [D loss: 0.438075] [G loss: 1.960364]\n",
            "[Epoch 49/50] [Batch 150/600] [D loss: 0.424851] [G loss: 1.993525]\n",
            "[Epoch 49/50] [Batch 151/600] [D loss: 0.465229] [G loss: 1.788944]\n",
            "[Epoch 49/50] [Batch 152/600] [D loss: 0.409133] [G loss: 1.662343]\n",
            "[Epoch 49/50] [Batch 153/600] [D loss: 0.494179] [G loss: 1.688708]\n",
            "[Epoch 49/50] [Batch 154/600] [D loss: 0.417150] [G loss: 1.766111]\n",
            "[Epoch 49/50] [Batch 155/600] [D loss: 0.393177] [G loss: 1.502936]\n",
            "[Epoch 49/50] [Batch 156/600] [D loss: 0.374338] [G loss: 1.641229]\n",
            "[Epoch 49/50] [Batch 157/600] [D loss: 0.412031] [G loss: 1.928401]\n",
            "[Epoch 49/50] [Batch 158/600] [D loss: 0.425075] [G loss: 1.739847]\n",
            "[Epoch 49/50] [Batch 159/600] [D loss: 0.391761] [G loss: 1.684347]\n",
            "[Epoch 49/50] [Batch 160/600] [D loss: 0.501838] [G loss: 1.615695]\n",
            "[Epoch 49/50] [Batch 161/600] [D loss: 0.418895] [G loss: 1.541938]\n",
            "[Epoch 49/50] [Batch 162/600] [D loss: 0.357615] [G loss: 1.801986]\n",
            "[Epoch 49/50] [Batch 163/600] [D loss: 0.475916] [G loss: 1.693090]\n",
            "[Epoch 49/50] [Batch 164/600] [D loss: 0.494604] [G loss: 1.650519]\n",
            "[Epoch 49/50] [Batch 165/600] [D loss: 0.462612] [G loss: 1.785987]\n",
            "[Epoch 49/50] [Batch 166/600] [D loss: 0.469311] [G loss: 1.446576]\n",
            "[Epoch 49/50] [Batch 167/600] [D loss: 0.424929] [G loss: 1.633106]\n",
            "[Epoch 49/50] [Batch 168/600] [D loss: 0.465483] [G loss: 1.464445]\n",
            "[Epoch 49/50] [Batch 169/600] [D loss: 0.411981] [G loss: 1.564058]\n",
            "[Epoch 49/50] [Batch 170/600] [D loss: 0.476786] [G loss: 1.507586]\n",
            "[Epoch 49/50] [Batch 171/600] [D loss: 0.432738] [G loss: 1.446041]\n",
            "[Epoch 49/50] [Batch 172/600] [D loss: 0.358024] [G loss: 1.588791]\n",
            "[Epoch 49/50] [Batch 173/600] [D loss: 0.448816] [G loss: 1.641615]\n",
            "[Epoch 49/50] [Batch 174/600] [D loss: 0.450225] [G loss: 1.669024]\n",
            "[Epoch 49/50] [Batch 175/600] [D loss: 0.445045] [G loss: 1.875823]\n",
            "[Epoch 49/50] [Batch 176/600] [D loss: 0.469437] [G loss: 1.904665]\n",
            "[Epoch 49/50] [Batch 177/600] [D loss: 0.492733] [G loss: 1.538222]\n",
            "[Epoch 49/50] [Batch 178/600] [D loss: 0.396775] [G loss: 1.490504]\n",
            "[Epoch 49/50] [Batch 179/600] [D loss: 0.453757] [G loss: 1.695125]\n",
            "[Epoch 49/50] [Batch 180/600] [D loss: 0.444600] [G loss: 1.553031]\n",
            "[Epoch 49/50] [Batch 181/600] [D loss: 0.467318] [G loss: 1.598614]\n",
            "[Epoch 49/50] [Batch 182/600] [D loss: 0.414275] [G loss: 1.675328]\n",
            "[Epoch 49/50] [Batch 183/600] [D loss: 0.486803] [G loss: 1.613643]\n",
            "[Epoch 49/50] [Batch 184/600] [D loss: 0.431322] [G loss: 1.541937]\n",
            "[Epoch 49/50] [Batch 185/600] [D loss: 0.388692] [G loss: 1.575861]\n",
            "[Epoch 49/50] [Batch 186/600] [D loss: 0.417472] [G loss: 1.557330]\n",
            "[Epoch 49/50] [Batch 187/600] [D loss: 0.473958] [G loss: 1.726340]\n",
            "[Epoch 49/50] [Batch 188/600] [D loss: 0.375041] [G loss: 1.615483]\n",
            "[Epoch 49/50] [Batch 189/600] [D loss: 0.422636] [G loss: 1.628383]\n",
            "[Epoch 49/50] [Batch 190/600] [D loss: 0.335079] [G loss: 1.732771]\n",
            "[Epoch 49/50] [Batch 191/600] [D loss: 0.443101] [G loss: 1.712635]\n",
            "[Epoch 49/50] [Batch 192/600] [D loss: 0.391516] [G loss: 1.876516]\n",
            "[Epoch 49/50] [Batch 193/600] [D loss: 0.407849] [G loss: 1.614115]\n",
            "[Epoch 49/50] [Batch 194/600] [D loss: 0.340594] [G loss: 1.552063]\n",
            "[Epoch 49/50] [Batch 195/600] [D loss: 0.340496] [G loss: 1.825348]\n",
            "[Epoch 49/50] [Batch 196/600] [D loss: 0.371181] [G loss: 2.000247]\n",
            "[Epoch 49/50] [Batch 197/600] [D loss: 0.388989] [G loss: 2.040236]\n",
            "[Epoch 49/50] [Batch 198/600] [D loss: 0.404262] [G loss: 1.896196]\n",
            "[Epoch 49/50] [Batch 199/600] [D loss: 0.355084] [G loss: 1.847277]\n",
            "[Epoch 49/50] [Batch 200/600] [D loss: 0.390466] [G loss: 1.808607]\n",
            "[Epoch 49/50] [Batch 201/600] [D loss: 0.416160] [G loss: 2.021199]\n",
            "[Epoch 49/50] [Batch 202/600] [D loss: 0.500024] [G loss: 2.039108]\n",
            "[Epoch 49/50] [Batch 203/600] [D loss: 0.381115] [G loss: 1.902715]\n",
            "[Epoch 49/50] [Batch 204/600] [D loss: 0.452092] [G loss: 1.702180]\n",
            "[Epoch 49/50] [Batch 205/600] [D loss: 0.350235] [G loss: 1.604799]\n",
            "[Epoch 49/50] [Batch 206/600] [D loss: 0.400903] [G loss: 1.720390]\n",
            "[Epoch 49/50] [Batch 207/600] [D loss: 0.387562] [G loss: 1.604506]\n",
            "[Epoch 49/50] [Batch 208/600] [D loss: 0.377870] [G loss: 1.872368]\n",
            "[Epoch 49/50] [Batch 209/600] [D loss: 0.383288] [G loss: 2.043960]\n",
            "[Epoch 49/50] [Batch 210/600] [D loss: 0.388984] [G loss: 1.999034]\n",
            "[Epoch 49/50] [Batch 211/600] [D loss: 0.449098] [G loss: 1.978417]\n",
            "[Epoch 49/50] [Batch 212/600] [D loss: 0.362125] [G loss: 1.974097]\n",
            "[Epoch 49/50] [Batch 213/600] [D loss: 0.416244] [G loss: 1.826559]\n",
            "[Epoch 49/50] [Batch 214/600] [D loss: 0.404185] [G loss: 1.949598]\n",
            "[Epoch 49/50] [Batch 215/600] [D loss: 0.408398] [G loss: 1.991036]\n",
            "[Epoch 49/50] [Batch 216/600] [D loss: 0.409781] [G loss: 1.704087]\n",
            "[Epoch 49/50] [Batch 217/600] [D loss: 0.340631] [G loss: 1.902480]\n",
            "[Epoch 49/50] [Batch 218/600] [D loss: 0.442202] [G loss: 1.728902]\n",
            "[Epoch 49/50] [Batch 219/600] [D loss: 0.345796] [G loss: 1.684461]\n",
            "[Epoch 49/50] [Batch 220/600] [D loss: 0.354583] [G loss: 1.841970]\n",
            "[Epoch 49/50] [Batch 221/600] [D loss: 0.430310] [G loss: 1.918183]\n",
            "[Epoch 49/50] [Batch 222/600] [D loss: 0.425524] [G loss: 2.322742]\n",
            "[Epoch 49/50] [Batch 223/600] [D loss: 0.467358] [G loss: 1.757078]\n",
            "[Epoch 49/50] [Batch 224/600] [D loss: 0.455648] [G loss: 1.643734]\n",
            "[Epoch 49/50] [Batch 225/600] [D loss: 0.454540] [G loss: 1.497598]\n",
            "[Epoch 49/50] [Batch 226/600] [D loss: 0.418049] [G loss: 1.511200]\n",
            "[Epoch 49/50] [Batch 227/600] [D loss: 0.469539] [G loss: 1.481040]\n",
            "[Epoch 49/50] [Batch 228/600] [D loss: 0.329862] [G loss: 1.583422]\n",
            "[Epoch 49/50] [Batch 229/600] [D loss: 0.310982] [G loss: 1.708275]\n",
            "[Epoch 49/50] [Batch 230/600] [D loss: 0.355339] [G loss: 1.670258]\n",
            "[Epoch 49/50] [Batch 231/600] [D loss: 0.354553] [G loss: 2.020866]\n",
            "[Epoch 49/50] [Batch 232/600] [D loss: 0.404109] [G loss: 1.798814]\n",
            "[Epoch 49/50] [Batch 233/600] [D loss: 0.492452] [G loss: 1.873430]\n",
            "[Epoch 49/50] [Batch 234/600] [D loss: 0.441514] [G loss: 1.942752]\n",
            "[Epoch 49/50] [Batch 235/600] [D loss: 0.384994] [G loss: 1.873976]\n",
            "[Epoch 49/50] [Batch 236/600] [D loss: 0.447344] [G loss: 1.581007]\n",
            "[Epoch 49/50] [Batch 237/600] [D loss: 0.430876] [G loss: 1.772560]\n",
            "[Epoch 49/50] [Batch 238/600] [D loss: 0.480010] [G loss: 1.720348]\n",
            "[Epoch 49/50] [Batch 239/600] [D loss: 0.382380] [G loss: 1.590891]\n",
            "[Epoch 49/50] [Batch 240/600] [D loss: 0.481313] [G loss: 1.724886]\n",
            "[Epoch 49/50] [Batch 241/600] [D loss: 0.455311] [G loss: 1.550182]\n",
            "[Epoch 49/50] [Batch 242/600] [D loss: 0.391122] [G loss: 1.550347]\n",
            "[Epoch 49/50] [Batch 243/600] [D loss: 0.374739] [G loss: 1.601272]\n",
            "[Epoch 49/50] [Batch 244/600] [D loss: 0.426853] [G loss: 1.592227]\n",
            "[Epoch 49/50] [Batch 245/600] [D loss: 0.470414] [G loss: 1.754351]\n",
            "[Epoch 49/50] [Batch 246/600] [D loss: 0.341351] [G loss: 1.693928]\n",
            "[Epoch 49/50] [Batch 247/600] [D loss: 0.381726] [G loss: 1.990719]\n",
            "[Epoch 49/50] [Batch 248/600] [D loss: 0.438891] [G loss: 1.940373]\n",
            "[Epoch 49/50] [Batch 249/600] [D loss: 0.472393] [G loss: 1.955739]\n",
            "[Epoch 49/50] [Batch 250/600] [D loss: 0.380185] [G loss: 1.841008]\n",
            "[Epoch 49/50] [Batch 251/600] [D loss: 0.396764] [G loss: 1.577862]\n",
            "[Epoch 49/50] [Batch 252/600] [D loss: 0.515106] [G loss: 1.564039]\n",
            "[Epoch 49/50] [Batch 253/600] [D loss: 0.377134] [G loss: 1.627687]\n",
            "[Epoch 49/50] [Batch 254/600] [D loss: 0.381503] [G loss: 1.838369]\n",
            "[Epoch 49/50] [Batch 255/600] [D loss: 0.439062] [G loss: 1.834356]\n",
            "[Epoch 49/50] [Batch 256/600] [D loss: 0.438729] [G loss: 1.860149]\n",
            "[Epoch 49/50] [Batch 257/600] [D loss: 0.414971] [G loss: 1.655345]\n",
            "[Epoch 49/50] [Batch 258/600] [D loss: 0.475125] [G loss: 1.766381]\n",
            "[Epoch 49/50] [Batch 259/600] [D loss: 0.394714] [G loss: 2.146110]\n",
            "[Epoch 49/50] [Batch 260/600] [D loss: 0.369525] [G loss: 1.810109]\n",
            "[Epoch 49/50] [Batch 261/600] [D loss: 0.461311] [G loss: 1.524530]\n",
            "[Epoch 49/50] [Batch 262/600] [D loss: 0.492173] [G loss: 1.718611]\n",
            "[Epoch 49/50] [Batch 263/600] [D loss: 0.470204] [G loss: 1.802720]\n",
            "[Epoch 49/50] [Batch 264/600] [D loss: 0.477829] [G loss: 1.679879]\n",
            "[Epoch 49/50] [Batch 265/600] [D loss: 0.422004] [G loss: 1.743074]\n",
            "[Epoch 49/50] [Batch 266/600] [D loss: 0.416070] [G loss: 1.529115]\n",
            "[Epoch 49/50] [Batch 267/600] [D loss: 0.491403] [G loss: 1.348972]\n",
            "[Epoch 49/50] [Batch 268/600] [D loss: 0.451932] [G loss: 1.490387]\n",
            "[Epoch 49/50] [Batch 269/600] [D loss: 0.443593] [G loss: 1.465819]\n",
            "[Epoch 49/50] [Batch 270/600] [D loss: 0.423363] [G loss: 1.547782]\n",
            "[Epoch 49/50] [Batch 271/600] [D loss: 0.373026] [G loss: 1.773312]\n",
            "[Epoch 49/50] [Batch 272/600] [D loss: 0.425290] [G loss: 1.850217]\n",
            "[Epoch 49/50] [Batch 273/600] [D loss: 0.384424] [G loss: 1.900480]\n",
            "[Epoch 49/50] [Batch 274/600] [D loss: 0.458433] [G loss: 1.935742]\n",
            "[Epoch 49/50] [Batch 275/600] [D loss: 0.430758] [G loss: 1.767608]\n",
            "[Epoch 49/50] [Batch 276/600] [D loss: 0.494222] [G loss: 2.009469]\n",
            "[Epoch 49/50] [Batch 277/600] [D loss: 0.387599] [G loss: 1.933807]\n",
            "[Epoch 49/50] [Batch 278/600] [D loss: 0.457719] [G loss: 1.729240]\n",
            "[Epoch 49/50] [Batch 279/600] [D loss: 0.476194] [G loss: 1.556017]\n",
            "[Epoch 49/50] [Batch 280/600] [D loss: 0.393188] [G loss: 1.683687]\n",
            "[Epoch 49/50] [Batch 281/600] [D loss: 0.355458] [G loss: 1.597570]\n",
            "[Epoch 49/50] [Batch 282/600] [D loss: 0.468522] [G loss: 1.466280]\n",
            "[Epoch 49/50] [Batch 283/600] [D loss: 0.395001] [G loss: 1.665865]\n",
            "[Epoch 49/50] [Batch 284/600] [D loss: 0.384308] [G loss: 1.706410]\n",
            "[Epoch 49/50] [Batch 285/600] [D loss: 0.395814] [G loss: 1.698394]\n",
            "[Epoch 49/50] [Batch 286/600] [D loss: 0.430087] [G loss: 1.728697]\n",
            "[Epoch 49/50] [Batch 287/600] [D loss: 0.431667] [G loss: 1.730115]\n",
            "[Epoch 49/50] [Batch 288/600] [D loss: 0.357571] [G loss: 1.716711]\n",
            "[Epoch 49/50] [Batch 289/600] [D loss: 0.314604] [G loss: 1.895795]\n",
            "[Epoch 49/50] [Batch 290/600] [D loss: 0.430769] [G loss: 1.744867]\n",
            "[Epoch 49/50] [Batch 291/600] [D loss: 0.453254] [G loss: 1.823948]\n",
            "[Epoch 49/50] [Batch 292/600] [D loss: 0.488885] [G loss: 1.443333]\n",
            "[Epoch 49/50] [Batch 293/600] [D loss: 0.407297] [G loss: 1.766201]\n",
            "[Epoch 49/50] [Batch 294/600] [D loss: 0.451675] [G loss: 1.756941]\n",
            "[Epoch 49/50] [Batch 295/600] [D loss: 0.426465] [G loss: 1.592705]\n",
            "[Epoch 49/50] [Batch 296/600] [D loss: 0.413255] [G loss: 1.794990]\n",
            "[Epoch 49/50] [Batch 297/600] [D loss: 0.464461] [G loss: 1.870008]\n",
            "[Epoch 49/50] [Batch 298/600] [D loss: 0.468347] [G loss: 1.708500]\n",
            "[Epoch 49/50] [Batch 299/600] [D loss: 0.418160] [G loss: 1.747502]\n",
            "[Epoch 49/50] [Batch 300/600] [D loss: 0.420122] [G loss: 1.463303]\n",
            "[Epoch 49/50] [Batch 301/600] [D loss: 0.428123] [G loss: 1.555841]\n",
            "[Epoch 49/50] [Batch 302/600] [D loss: 0.443134] [G loss: 1.741819]\n",
            "[Epoch 49/50] [Batch 303/600] [D loss: 0.458030] [G loss: 1.796487]\n",
            "[Epoch 49/50] [Batch 304/600] [D loss: 0.404820] [G loss: 1.743844]\n",
            "[Epoch 49/50] [Batch 305/600] [D loss: 0.394300] [G loss: 1.694686]\n",
            "[Epoch 49/50] [Batch 306/600] [D loss: 0.490504] [G loss: 1.538965]\n",
            "[Epoch 49/50] [Batch 307/600] [D loss: 0.427079] [G loss: 1.443337]\n",
            "[Epoch 49/50] [Batch 308/600] [D loss: 0.478352] [G loss: 1.711978]\n",
            "[Epoch 49/50] [Batch 309/600] [D loss: 0.436742] [G loss: 1.539697]\n",
            "[Epoch 49/50] [Batch 310/600] [D loss: 0.453501] [G loss: 1.406832]\n",
            "[Epoch 49/50] [Batch 311/600] [D loss: 0.420749] [G loss: 1.550863]\n",
            "[Epoch 49/50] [Batch 312/600] [D loss: 0.479151] [G loss: 1.378899]\n",
            "[Epoch 49/50] [Batch 313/600] [D loss: 0.467405] [G loss: 1.545808]\n",
            "[Epoch 49/50] [Batch 314/600] [D loss: 0.423222] [G loss: 1.433279]\n",
            "[Epoch 49/50] [Batch 315/600] [D loss: 0.512491] [G loss: 1.422488]\n",
            "[Epoch 49/50] [Batch 316/600] [D loss: 0.404178] [G loss: 1.412849]\n",
            "[Epoch 49/50] [Batch 317/600] [D loss: 0.451949] [G loss: 1.710131]\n",
            "[Epoch 49/50] [Batch 318/600] [D loss: 0.439245] [G loss: 1.651479]\n",
            "[Epoch 49/50] [Batch 319/600] [D loss: 0.423014] [G loss: 1.684665]\n",
            "[Epoch 49/50] [Batch 320/600] [D loss: 0.460667] [G loss: 1.693896]\n",
            "[Epoch 49/50] [Batch 321/600] [D loss: 0.399336] [G loss: 1.458667]\n",
            "[Epoch 49/50] [Batch 322/600] [D loss: 0.399330] [G loss: 1.712171]\n",
            "[Epoch 49/50] [Batch 323/600] [D loss: 0.432353] [G loss: 1.847377]\n",
            "[Epoch 49/50] [Batch 324/600] [D loss: 0.366427] [G loss: 1.684727]\n",
            "[Epoch 49/50] [Batch 325/600] [D loss: 0.399511] [G loss: 1.812568]\n",
            "[Epoch 49/50] [Batch 326/600] [D loss: 0.456717] [G loss: 1.849494]\n",
            "[Epoch 49/50] [Batch 327/600] [D loss: 0.496928] [G loss: 1.539769]\n",
            "[Epoch 49/50] [Batch 328/600] [D loss: 0.409679] [G loss: 1.810441]\n",
            "[Epoch 49/50] [Batch 329/600] [D loss: 0.401540] [G loss: 1.730284]\n",
            "[Epoch 49/50] [Batch 330/600] [D loss: 0.318005] [G loss: 1.776064]\n",
            "[Epoch 49/50] [Batch 331/600] [D loss: 0.498703] [G loss: 1.692812]\n",
            "[Epoch 49/50] [Batch 332/600] [D loss: 0.339445] [G loss: 1.754482]\n",
            "[Epoch 49/50] [Batch 333/600] [D loss: 0.410525] [G loss: 1.764261]\n",
            "[Epoch 49/50] [Batch 334/600] [D loss: 0.364585] [G loss: 1.890622]\n",
            "[Epoch 49/50] [Batch 335/600] [D loss: 0.448005] [G loss: 1.933217]\n",
            "[Epoch 49/50] [Batch 336/600] [D loss: 0.446082] [G loss: 1.933270]\n",
            "[Epoch 49/50] [Batch 337/600] [D loss: 0.454780] [G loss: 1.772008]\n",
            "[Epoch 49/50] [Batch 338/600] [D loss: 0.437849] [G loss: 1.743000]\n",
            "[Epoch 49/50] [Batch 339/600] [D loss: 0.387162] [G loss: 1.660602]\n",
            "[Epoch 49/50] [Batch 340/600] [D loss: 0.409966] [G loss: 1.566615]\n",
            "[Epoch 49/50] [Batch 341/600] [D loss: 0.403684] [G loss: 1.565339]\n",
            "[Epoch 49/50] [Batch 342/600] [D loss: 0.389088] [G loss: 1.630065]\n",
            "[Epoch 49/50] [Batch 343/600] [D loss: 0.462817] [G loss: 1.600415]\n",
            "[Epoch 49/50] [Batch 344/600] [D loss: 0.349085] [G loss: 1.687740]\n",
            "[Epoch 49/50] [Batch 345/600] [D loss: 0.450697] [G loss: 1.825782]\n",
            "[Epoch 49/50] [Batch 346/600] [D loss: 0.395530] [G loss: 1.782214]\n",
            "[Epoch 49/50] [Batch 347/600] [D loss: 0.372588] [G loss: 1.654376]\n",
            "[Epoch 49/50] [Batch 348/600] [D loss: 0.467763] [G loss: 1.617845]\n",
            "[Epoch 49/50] [Batch 349/600] [D loss: 0.372204] [G loss: 1.778677]\n",
            "[Epoch 49/50] [Batch 350/600] [D loss: 0.387739] [G loss: 2.045759]\n",
            "[Epoch 49/50] [Batch 351/600] [D loss: 0.417202] [G loss: 1.937864]\n",
            "[Epoch 49/50] [Batch 352/600] [D loss: 0.443491] [G loss: 1.826395]\n",
            "[Epoch 49/50] [Batch 353/600] [D loss: 0.395236] [G loss: 1.667672]\n",
            "[Epoch 49/50] [Batch 354/600] [D loss: 0.374572] [G loss: 1.658632]\n",
            "[Epoch 49/50] [Batch 355/600] [D loss: 0.399404] [G loss: 1.555380]\n",
            "[Epoch 49/50] [Batch 356/600] [D loss: 0.495125] [G loss: 1.953229]\n",
            "[Epoch 49/50] [Batch 357/600] [D loss: 0.458701] [G loss: 1.765090]\n",
            "[Epoch 49/50] [Batch 358/600] [D loss: 0.480707] [G loss: 1.554477]\n",
            "[Epoch 49/50] [Batch 359/600] [D loss: 0.502946] [G loss: 1.419937]\n",
            "[Epoch 49/50] [Batch 360/600] [D loss: 0.438725] [G loss: 1.563717]\n",
            "[Epoch 49/50] [Batch 361/600] [D loss: 0.425441] [G loss: 1.386402]\n",
            "[Epoch 49/50] [Batch 362/600] [D loss: 0.407513] [G loss: 1.724164]\n",
            "[Epoch 49/50] [Batch 363/600] [D loss: 0.366982] [G loss: 1.750183]\n",
            "[Epoch 49/50] [Batch 364/600] [D loss: 0.409534] [G loss: 1.641290]\n",
            "[Epoch 49/50] [Batch 365/600] [D loss: 0.418566] [G loss: 1.569379]\n",
            "[Epoch 49/50] [Batch 366/600] [D loss: 0.393154] [G loss: 1.702525]\n",
            "[Epoch 49/50] [Batch 367/600] [D loss: 0.328933] [G loss: 1.825277]\n",
            "[Epoch 49/50] [Batch 368/600] [D loss: 0.442537] [G loss: 1.800304]\n",
            "[Epoch 49/50] [Batch 369/600] [D loss: 0.484642] [G loss: 1.756155]\n",
            "[Epoch 49/50] [Batch 370/600] [D loss: 0.417974] [G loss: 1.599429]\n",
            "[Epoch 49/50] [Batch 371/600] [D loss: 0.450988] [G loss: 1.697987]\n",
            "[Epoch 49/50] [Batch 372/600] [D loss: 0.317297] [G loss: 1.613256]\n",
            "[Epoch 49/50] [Batch 373/600] [D loss: 0.453174] [G loss: 1.732115]\n",
            "[Epoch 49/50] [Batch 374/600] [D loss: 0.434122] [G loss: 1.512594]\n",
            "[Epoch 49/50] [Batch 375/600] [D loss: 0.441180] [G loss: 1.538055]\n",
            "[Epoch 49/50] [Batch 376/600] [D loss: 0.447602] [G loss: 1.719937]\n",
            "[Epoch 49/50] [Batch 377/600] [D loss: 0.401670] [G loss: 1.557216]\n",
            "[Epoch 49/50] [Batch 378/600] [D loss: 0.426751] [G loss: 1.630183]\n",
            "[Epoch 49/50] [Batch 379/600] [D loss: 0.384938] [G loss: 1.764109]\n",
            "[Epoch 49/50] [Batch 380/600] [D loss: 0.447176] [G loss: 1.638715]\n",
            "[Epoch 49/50] [Batch 381/600] [D loss: 0.356117] [G loss: 1.667534]\n",
            "[Epoch 49/50] [Batch 382/600] [D loss: 0.381831] [G loss: 1.769791]\n",
            "[Epoch 49/50] [Batch 383/600] [D loss: 0.470428] [G loss: 1.678813]\n",
            "[Epoch 49/50] [Batch 384/600] [D loss: 0.311159] [G loss: 1.846226]\n",
            "[Epoch 49/50] [Batch 385/600] [D loss: 0.403988] [G loss: 1.712224]\n",
            "[Epoch 49/50] [Batch 386/600] [D loss: 0.399270] [G loss: 1.660441]\n",
            "[Epoch 49/50] [Batch 387/600] [D loss: 0.477395] [G loss: 1.980939]\n",
            "[Epoch 49/50] [Batch 388/600] [D loss: 0.347210] [G loss: 1.985922]\n",
            "[Epoch 49/50] [Batch 389/600] [D loss: 0.434500] [G loss: 2.009651]\n",
            "[Epoch 49/50] [Batch 390/600] [D loss: 0.344096] [G loss: 1.938480]\n",
            "[Epoch 49/50] [Batch 391/600] [D loss: 0.318679] [G loss: 1.858769]\n",
            "[Epoch 49/50] [Batch 392/600] [D loss: 0.405753] [G loss: 1.706197]\n",
            "[Epoch 49/50] [Batch 393/600] [D loss: 0.432836] [G loss: 1.658271]\n",
            "[Epoch 49/50] [Batch 394/600] [D loss: 0.367751] [G loss: 1.650750]\n",
            "[Epoch 49/50] [Batch 395/600] [D loss: 0.413655] [G loss: 2.019122]\n",
            "[Epoch 49/50] [Batch 396/600] [D loss: 0.469858] [G loss: 2.016657]\n",
            "[Epoch 49/50] [Batch 397/600] [D loss: 0.450696] [G loss: 1.712581]\n",
            "[Epoch 49/50] [Batch 398/600] [D loss: 0.426996] [G loss: 1.882154]\n",
            "[Epoch 49/50] [Batch 399/600] [D loss: 0.402715] [G loss: 1.736466]\n",
            "[Epoch 49/50] [Batch 400/600] [D loss: 0.361750] [G loss: 1.760883]\n",
            "[Epoch 49/50] [Batch 401/600] [D loss: 0.421963] [G loss: 1.532602]\n",
            "[Epoch 49/50] [Batch 402/600] [D loss: 0.450045] [G loss: 1.673433]\n",
            "[Epoch 49/50] [Batch 403/600] [D loss: 0.437604] [G loss: 1.536405]\n",
            "[Epoch 49/50] [Batch 404/600] [D loss: 0.394332] [G loss: 1.832473]\n",
            "[Epoch 49/50] [Batch 405/600] [D loss: 0.374537] [G loss: 1.637930]\n",
            "[Epoch 49/50] [Batch 406/600] [D loss: 0.436286] [G loss: 1.958969]\n",
            "[Epoch 49/50] [Batch 407/600] [D loss: 0.415333] [G loss: 2.015421]\n",
            "[Epoch 49/50] [Batch 408/600] [D loss: 0.384487] [G loss: 1.601881]\n",
            "[Epoch 49/50] [Batch 409/600] [D loss: 0.464429] [G loss: 1.715383]\n",
            "[Epoch 49/50] [Batch 410/600] [D loss: 0.463523] [G loss: 1.744139]\n",
            "[Epoch 49/50] [Batch 411/600] [D loss: 0.477671] [G loss: 1.692877]\n",
            "[Epoch 49/50] [Batch 412/600] [D loss: 0.372864] [G loss: 1.768430]\n",
            "[Epoch 49/50] [Batch 413/600] [D loss: 0.392601] [G loss: 1.762459]\n",
            "[Epoch 49/50] [Batch 414/600] [D loss: 0.437139] [G loss: 1.715889]\n",
            "[Epoch 49/50] [Batch 415/600] [D loss: 0.404087] [G loss: 1.673230]\n",
            "[Epoch 49/50] [Batch 416/600] [D loss: 0.458914] [G loss: 1.695953]\n",
            "[Epoch 49/50] [Batch 417/600] [D loss: 0.451486] [G loss: 1.793865]\n",
            "[Epoch 49/50] [Batch 418/600] [D loss: 0.437811] [G loss: 1.656161]\n",
            "[Epoch 49/50] [Batch 419/600] [D loss: 0.426458] [G loss: 1.602594]\n",
            "[Epoch 49/50] [Batch 420/600] [D loss: 0.350904] [G loss: 1.595464]\n",
            "[Epoch 49/50] [Batch 421/600] [D loss: 0.370715] [G loss: 1.616005]\n",
            "[Epoch 49/50] [Batch 422/600] [D loss: 0.379921] [G loss: 1.926606]\n",
            "[Epoch 49/50] [Batch 423/600] [D loss: 0.430421] [G loss: 1.666578]\n",
            "[Epoch 49/50] [Batch 424/600] [D loss: 0.466481] [G loss: 1.818751]\n",
            "[Epoch 49/50] [Batch 425/600] [D loss: 0.430006] [G loss: 1.772561]\n",
            "[Epoch 49/50] [Batch 426/600] [D loss: 0.354876] [G loss: 1.814387]\n",
            "[Epoch 49/50] [Batch 427/600] [D loss: 0.403554] [G loss: 1.566804]\n",
            "[Epoch 49/50] [Batch 428/600] [D loss: 0.401501] [G loss: 1.712806]\n",
            "[Epoch 49/50] [Batch 429/600] [D loss: 0.396990] [G loss: 1.678891]\n",
            "[Epoch 49/50] [Batch 430/600] [D loss: 0.538165] [G loss: 1.836506]\n",
            "[Epoch 49/50] [Batch 431/600] [D loss: 0.430805] [G loss: 1.680083]\n",
            "[Epoch 49/50] [Batch 432/600] [D loss: 0.411106] [G loss: 1.539713]\n",
            "[Epoch 49/50] [Batch 433/600] [D loss: 0.381965] [G loss: 1.636803]\n",
            "[Epoch 49/50] [Batch 434/600] [D loss: 0.357855] [G loss: 1.651030]\n",
            "[Epoch 49/50] [Batch 435/600] [D loss: 0.401295] [G loss: 1.777717]\n",
            "[Epoch 49/50] [Batch 436/600] [D loss: 0.392357] [G loss: 1.736335]\n",
            "[Epoch 49/50] [Batch 437/600] [D loss: 0.399071] [G loss: 2.061602]\n",
            "[Epoch 49/50] [Batch 438/600] [D loss: 0.489235] [G loss: 1.719185]\n",
            "[Epoch 49/50] [Batch 439/600] [D loss: 0.474348] [G loss: 1.775672]\n",
            "[Epoch 49/50] [Batch 440/600] [D loss: 0.421669] [G loss: 1.618126]\n",
            "[Epoch 49/50] [Batch 441/600] [D loss: 0.428865] [G loss: 1.608136]\n",
            "[Epoch 49/50] [Batch 442/600] [D loss: 0.391047] [G loss: 1.720038]\n",
            "[Epoch 49/50] [Batch 443/600] [D loss: 0.352605] [G loss: 1.911259]\n",
            "[Epoch 49/50] [Batch 444/600] [D loss: 0.399763] [G loss: 1.729682]\n",
            "[Epoch 49/50] [Batch 445/600] [D loss: 0.464452] [G loss: 1.795272]\n",
            "[Epoch 49/50] [Batch 446/600] [D loss: 0.340990] [G loss: 1.899860]\n",
            "[Epoch 49/50] [Batch 447/600] [D loss: 0.366952] [G loss: 1.761078]\n",
            "[Epoch 49/50] [Batch 448/600] [D loss: 0.421010] [G loss: 1.676501]\n",
            "[Epoch 49/50] [Batch 449/600] [D loss: 0.467638] [G loss: 1.782047]\n",
            "[Epoch 49/50] [Batch 450/600] [D loss: 0.387124] [G loss: 1.848280]\n",
            "[Epoch 49/50] [Batch 451/600] [D loss: 0.403598] [G loss: 1.755209]\n",
            "[Epoch 49/50] [Batch 452/600] [D loss: 0.478274] [G loss: 1.758677]\n",
            "[Epoch 49/50] [Batch 453/600] [D loss: 0.401990] [G loss: 1.929103]\n",
            "[Epoch 49/50] [Batch 454/600] [D loss: 0.458312] [G loss: 1.811408]\n",
            "[Epoch 49/50] [Batch 455/600] [D loss: 0.406767] [G loss: 1.711354]\n",
            "[Epoch 49/50] [Batch 456/600] [D loss: 0.502984] [G loss: 1.810122]\n",
            "[Epoch 49/50] [Batch 457/600] [D loss: 0.457955] [G loss: 1.845139]\n",
            "[Epoch 49/50] [Batch 458/600] [D loss: 0.450296] [G loss: 1.675824]\n",
            "[Epoch 49/50] [Batch 459/600] [D loss: 0.475771] [G loss: 1.496904]\n",
            "[Epoch 49/50] [Batch 460/600] [D loss: 0.505115] [G loss: 1.496700]\n",
            "[Epoch 49/50] [Batch 461/600] [D loss: 0.424675] [G loss: 1.782046]\n",
            "[Epoch 49/50] [Batch 462/600] [D loss: 0.380544] [G loss: 1.611367]\n",
            "[Epoch 49/50] [Batch 463/600] [D loss: 0.435952] [G loss: 1.392586]\n",
            "[Epoch 49/50] [Batch 464/600] [D loss: 0.367495] [G loss: 1.753756]\n",
            "[Epoch 49/50] [Batch 465/600] [D loss: 0.365621] [G loss: 1.858939]\n",
            "[Epoch 49/50] [Batch 466/600] [D loss: 0.462963] [G loss: 2.068898]\n",
            "[Epoch 49/50] [Batch 467/600] [D loss: 0.379597] [G loss: 1.770034]\n",
            "[Epoch 49/50] [Batch 468/600] [D loss: 0.442170] [G loss: 1.867490]\n",
            "[Epoch 49/50] [Batch 469/600] [D loss: 0.386210] [G loss: 1.788719]\n",
            "[Epoch 49/50] [Batch 470/600] [D loss: 0.401246] [G loss: 1.502155]\n",
            "[Epoch 49/50] [Batch 471/600] [D loss: 0.379724] [G loss: 1.800280]\n",
            "[Epoch 49/50] [Batch 472/600] [D loss: 0.483427] [G loss: 1.917730]\n",
            "[Epoch 49/50] [Batch 473/600] [D loss: 0.418795] [G loss: 1.763825]\n",
            "[Epoch 49/50] [Batch 474/600] [D loss: 0.461980] [G loss: 1.824301]\n",
            "[Epoch 49/50] [Batch 475/600] [D loss: 0.409229] [G loss: 1.518309]\n",
            "[Epoch 49/50] [Batch 476/600] [D loss: 0.411158] [G loss: 1.338399]\n",
            "[Epoch 49/50] [Batch 477/600] [D loss: 0.316863] [G loss: 1.560746]\n",
            "[Epoch 49/50] [Batch 478/600] [D loss: 0.369193] [G loss: 1.561864]\n",
            "[Epoch 49/50] [Batch 479/600] [D loss: 0.374947] [G loss: 2.091052]\n",
            "[Epoch 49/50] [Batch 480/600] [D loss: 0.365913] [G loss: 1.907268]\n",
            "[Epoch 49/50] [Batch 481/600] [D loss: 0.397890] [G loss: 1.777154]\n",
            "[Epoch 49/50] [Batch 482/600] [D loss: 0.426381] [G loss: 1.919057]\n",
            "[Epoch 49/50] [Batch 483/600] [D loss: 0.409300] [G loss: 1.602996]\n",
            "[Epoch 49/50] [Batch 484/600] [D loss: 0.394828] [G loss: 1.744058]\n",
            "[Epoch 49/50] [Batch 485/600] [D loss: 0.392222] [G loss: 1.842141]\n",
            "[Epoch 49/50] [Batch 486/600] [D loss: 0.381851] [G loss: 1.860089]\n",
            "[Epoch 49/50] [Batch 487/600] [D loss: 0.461911] [G loss: 1.870586]\n",
            "[Epoch 49/50] [Batch 488/600] [D loss: 0.392102] [G loss: 1.666064]\n",
            "[Epoch 49/50] [Batch 489/600] [D loss: 0.484261] [G loss: 1.924741]\n",
            "[Epoch 49/50] [Batch 490/600] [D loss: 0.480836] [G loss: 1.777500]\n",
            "[Epoch 49/50] [Batch 491/600] [D loss: 0.385752] [G loss: 1.612205]\n",
            "[Epoch 49/50] [Batch 492/600] [D loss: 0.403012] [G loss: 1.477102]\n",
            "[Epoch 49/50] [Batch 493/600] [D loss: 0.439170] [G loss: 1.592195]\n",
            "[Epoch 49/50] [Batch 494/600] [D loss: 0.435345] [G loss: 1.698896]\n",
            "[Epoch 49/50] [Batch 495/600] [D loss: 0.418059] [G loss: 1.657547]\n",
            "[Epoch 49/50] [Batch 496/600] [D loss: 0.449468] [G loss: 1.780013]\n",
            "[Epoch 49/50] [Batch 497/600] [D loss: 0.394294] [G loss: 1.937251]\n",
            "[Epoch 49/50] [Batch 498/600] [D loss: 0.460853] [G loss: 2.059174]\n",
            "[Epoch 49/50] [Batch 499/600] [D loss: 0.401346] [G loss: 1.913409]\n",
            "[Epoch 49/50] [Batch 500/600] [D loss: 0.434673] [G loss: 1.935529]\n",
            "[Epoch 49/50] [Batch 501/600] [D loss: 0.373984] [G loss: 1.771253]\n",
            "[Epoch 49/50] [Batch 502/600] [D loss: 0.487744] [G loss: 1.610941]\n",
            "[Epoch 49/50] [Batch 503/600] [D loss: 0.472082] [G loss: 1.609682]\n",
            "[Epoch 49/50] [Batch 504/600] [D loss: 0.462996] [G loss: 1.786352]\n",
            "[Epoch 49/50] [Batch 505/600] [D loss: 0.376372] [G loss: 1.562227]\n",
            "[Epoch 49/50] [Batch 506/600] [D loss: 0.462605] [G loss: 1.567084]\n",
            "[Epoch 49/50] [Batch 507/600] [D loss: 0.536883] [G loss: 1.495775]\n",
            "[Epoch 49/50] [Batch 508/600] [D loss: 0.458536] [G loss: 1.575238]\n",
            "[Epoch 49/50] [Batch 509/600] [D loss: 0.374310] [G loss: 1.669310]\n",
            "[Epoch 49/50] [Batch 510/600] [D loss: 0.437170] [G loss: 1.641825]\n",
            "[Epoch 49/50] [Batch 511/600] [D loss: 0.377055] [G loss: 1.758359]\n",
            "[Epoch 49/50] [Batch 512/600] [D loss: 0.380493] [G loss: 1.717536]\n",
            "[Epoch 49/50] [Batch 513/600] [D loss: 0.397469] [G loss: 1.520513]\n",
            "[Epoch 49/50] [Batch 514/600] [D loss: 0.379414] [G loss: 1.813071]\n",
            "[Epoch 49/50] [Batch 515/600] [D loss: 0.416965] [G loss: 1.963834]\n",
            "[Epoch 49/50] [Batch 516/600] [D loss: 0.400247] [G loss: 2.042846]\n",
            "[Epoch 49/50] [Batch 517/600] [D loss: 0.453431] [G loss: 1.863028]\n",
            "[Epoch 49/50] [Batch 518/600] [D loss: 0.473543] [G loss: 1.672441]\n",
            "[Epoch 49/50] [Batch 519/600] [D loss: 0.460878] [G loss: 1.651304]\n",
            "[Epoch 49/50] [Batch 520/600] [D loss: 0.448392] [G loss: 1.682041]\n",
            "[Epoch 49/50] [Batch 521/600] [D loss: 0.400957] [G loss: 1.659471]\n",
            "[Epoch 49/50] [Batch 522/600] [D loss: 0.494498] [G loss: 1.684650]\n",
            "[Epoch 49/50] [Batch 523/600] [D loss: 0.493784] [G loss: 1.540190]\n",
            "[Epoch 49/50] [Batch 524/600] [D loss: 0.397466] [G loss: 1.838042]\n",
            "[Epoch 49/50] [Batch 525/600] [D loss: 0.372007] [G loss: 1.718351]\n",
            "[Epoch 49/50] [Batch 526/600] [D loss: 0.336931] [G loss: 1.686028]\n",
            "[Epoch 49/50] [Batch 527/600] [D loss: 0.383565] [G loss: 1.832749]\n",
            "[Epoch 49/50] [Batch 528/600] [D loss: 0.417914] [G loss: 1.840827]\n",
            "[Epoch 49/50] [Batch 529/600] [D loss: 0.449708] [G loss: 1.916857]\n",
            "[Epoch 49/50] [Batch 530/600] [D loss: 0.338474] [G loss: 1.686113]\n",
            "[Epoch 49/50] [Batch 531/600] [D loss: 0.399951] [G loss: 1.676558]\n",
            "[Epoch 49/50] [Batch 532/600] [D loss: 0.415923] [G loss: 1.747626]\n",
            "[Epoch 49/50] [Batch 533/600] [D loss: 0.376457] [G loss: 1.705633]\n",
            "[Epoch 49/50] [Batch 534/600] [D loss: 0.379205] [G loss: 2.094552]\n",
            "[Epoch 49/50] [Batch 535/600] [D loss: 0.397320] [G loss: 1.884499]\n",
            "[Epoch 49/50] [Batch 536/600] [D loss: 0.428178] [G loss: 1.732543]\n",
            "[Epoch 49/50] [Batch 537/600] [D loss: 0.431320] [G loss: 1.713833]\n",
            "[Epoch 49/50] [Batch 538/600] [D loss: 0.398457] [G loss: 1.748101]\n",
            "[Epoch 49/50] [Batch 539/600] [D loss: 0.415631] [G loss: 1.610752]\n",
            "[Epoch 49/50] [Batch 540/600] [D loss: 0.518242] [G loss: 1.591095]\n",
            "[Epoch 49/50] [Batch 541/600] [D loss: 0.435512] [G loss: 1.779119]\n",
            "[Epoch 49/50] [Batch 542/600] [D loss: 0.420084] [G loss: 1.783184]\n",
            "[Epoch 49/50] [Batch 543/600] [D loss: 0.432209] [G loss: 1.756104]\n",
            "[Epoch 49/50] [Batch 544/600] [D loss: 0.439042] [G loss: 1.873735]\n",
            "[Epoch 49/50] [Batch 545/600] [D loss: 0.395267] [G loss: 1.689430]\n",
            "[Epoch 49/50] [Batch 546/600] [D loss: 0.373433] [G loss: 1.745949]\n",
            "[Epoch 49/50] [Batch 547/600] [D loss: 0.403925] [G loss: 1.678750]\n",
            "[Epoch 49/50] [Batch 548/600] [D loss: 0.412438] [G loss: 1.542464]\n",
            "[Epoch 49/50] [Batch 549/600] [D loss: 0.525083] [G loss: 1.667318]\n",
            "[Epoch 49/50] [Batch 550/600] [D loss: 0.414522] [G loss: 2.082532]\n",
            "[Epoch 49/50] [Batch 551/600] [D loss: 0.347441] [G loss: 1.588721]\n",
            "[Epoch 49/50] [Batch 552/600] [D loss: 0.458753] [G loss: 1.732285]\n",
            "[Epoch 49/50] [Batch 553/600] [D loss: 0.435582] [G loss: 1.752962]\n",
            "[Epoch 49/50] [Batch 554/600] [D loss: 0.484983] [G loss: 1.612798]\n",
            "[Epoch 49/50] [Batch 555/600] [D loss: 0.360004] [G loss: 1.693541]\n",
            "[Epoch 49/50] [Batch 556/600] [D loss: 0.385851] [G loss: 1.892865]\n",
            "[Epoch 49/50] [Batch 557/600] [D loss: 0.310851] [G loss: 1.963386]\n",
            "[Epoch 49/50] [Batch 558/600] [D loss: 0.468946] [G loss: 1.828533]\n",
            "[Epoch 49/50] [Batch 559/600] [D loss: 0.385537] [G loss: 1.727075]\n",
            "[Epoch 49/50] [Batch 560/600] [D loss: 0.343402] [G loss: 1.866958]\n",
            "[Epoch 49/50] [Batch 561/600] [D loss: 0.366312] [G loss: 1.767122]\n",
            "[Epoch 49/50] [Batch 562/600] [D loss: 0.435595] [G loss: 1.757536]\n",
            "[Epoch 49/50] [Batch 563/600] [D loss: 0.446696] [G loss: 1.558155]\n",
            "[Epoch 49/50] [Batch 564/600] [D loss: 0.525610] [G loss: 1.583672]\n",
            "[Epoch 49/50] [Batch 565/600] [D loss: 0.404461] [G loss: 1.814685]\n",
            "[Epoch 49/50] [Batch 566/600] [D loss: 0.397859] [G loss: 1.678705]\n",
            "[Epoch 49/50] [Batch 567/600] [D loss: 0.424490] [G loss: 1.453593]\n",
            "[Epoch 49/50] [Batch 568/600] [D loss: 0.374592] [G loss: 1.737837]\n",
            "[Epoch 49/50] [Batch 569/600] [D loss: 0.435847] [G loss: 1.676793]\n",
            "[Epoch 49/50] [Batch 570/600] [D loss: 0.485121] [G loss: 1.990214]\n",
            "[Epoch 49/50] [Batch 571/600] [D loss: 0.457642] [G loss: 1.807220]\n",
            "[Epoch 49/50] [Batch 572/600] [D loss: 0.422299] [G loss: 1.776816]\n",
            "[Epoch 49/50] [Batch 573/600] [D loss: 0.358803] [G loss: 1.552206]\n",
            "[Epoch 49/50] [Batch 574/600] [D loss: 0.433873] [G loss: 1.708594]\n",
            "[Epoch 49/50] [Batch 575/600] [D loss: 0.370541] [G loss: 1.703055]\n",
            "[Epoch 49/50] [Batch 576/600] [D loss: 0.440685] [G loss: 1.662981]\n",
            "[Epoch 49/50] [Batch 577/600] [D loss: 0.418911] [G loss: 1.515507]\n",
            "[Epoch 49/50] [Batch 578/600] [D loss: 0.466407] [G loss: 1.645833]\n",
            "[Epoch 49/50] [Batch 579/600] [D loss: 0.356072] [G loss: 1.655400]\n",
            "[Epoch 49/50] [Batch 580/600] [D loss: 0.440883] [G loss: 1.854788]\n",
            "[Epoch 49/50] [Batch 581/600] [D loss: 0.389362] [G loss: 1.860185]\n",
            "[Epoch 49/50] [Batch 582/600] [D loss: 0.376709] [G loss: 1.764537]\n",
            "[Epoch 49/50] [Batch 583/600] [D loss: 0.399450] [G loss: 2.023815]\n",
            "[Epoch 49/50] [Batch 584/600] [D loss: 0.434299] [G loss: 1.824178]\n",
            "[Epoch 49/50] [Batch 585/600] [D loss: 0.402594] [G loss: 1.626011]\n",
            "[Epoch 49/50] [Batch 586/600] [D loss: 0.542365] [G loss: 1.604618]\n",
            "[Epoch 49/50] [Batch 587/600] [D loss: 0.376977] [G loss: 1.602448]\n",
            "[Epoch 49/50] [Batch 588/600] [D loss: 0.361219] [G loss: 1.945366]\n",
            "[Epoch 49/50] [Batch 589/600] [D loss: 0.373847] [G loss: 1.802065]\n",
            "[Epoch 49/50] [Batch 590/600] [D loss: 0.385638] [G loss: 2.150621]\n",
            "[Epoch 49/50] [Batch 591/600] [D loss: 0.370988] [G loss: 1.953045]\n",
            "[Epoch 49/50] [Batch 592/600] [D loss: 0.351362] [G loss: 2.244658]\n",
            "[Epoch 49/50] [Batch 593/600] [D loss: 0.483249] [G loss: 2.069720]\n",
            "[Epoch 49/50] [Batch 594/600] [D loss: 0.387923] [G loss: 1.830341]\n",
            "[Epoch 49/50] [Batch 595/600] [D loss: 0.429097] [G loss: 1.456668]\n",
            "[Epoch 49/50] [Batch 596/600] [D loss: 0.347854] [G loss: 1.591003]\n",
            "[Epoch 49/50] [Batch 597/600] [D loss: 0.393952] [G loss: 1.903748]\n",
            "[Epoch 49/50] [Batch 598/600] [D loss: 0.344431] [G loss: 2.213032]\n",
            "[Epoch 49/50] [Batch 599/600] [D loss: 0.378182] [G loss: 1.924884]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1WhG4Fysnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}